{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  üì¶ Installing EDSL\n",
    "\n",
    "### 1. In a venv through pip\n",
    "Install the package and its requirements through pip (preferrably in a venv)\n",
    "```bash\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install edsl\n",
    "```\n",
    "\n",
    "### 2. In a venv through GitHub\n",
    "You can install the latest version of the package through GitHub\n",
    "```bash\n",
    "git clone https://github.com/goemeritus/edsl\n",
    "cd edsl\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "### 3. Globally through pip\n",
    "You can install the package globally through pip. We recommend using a venv (see A. and B. above) to avoid conflicts with other packages.\n",
    "```bash\n",
    "pip install edsl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üîë Adding your API Keys\n",
    "\n",
    "Before we start, note that *you do not* have to provide all three keys. However, we recommend that you add your OPENAI key. This is the LLM that the package will use by default -- unless you specify otherwise.\n",
    "\n",
    "There are three ways to provide your API keys to EDSL:\n",
    "\n",
    "### 1. Setting the environment variables directly\n",
    "In your script, start with the following lines before importing EDSL:\n",
    "```python\n",
    "import os\n",
    "os.environ[\"OPEN_AI_API_KEY\"] = \"your-key-here\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"your-key-here\"\n",
    "os.environ[\"DEEP_INFRA_API_KEY\"] = \"your-key-here\" \n",
    "```\n",
    "Note that when using this method, you will have to provide your API keys every time you run your script.\n",
    "\n",
    "### 2. Using a .env file\n",
    "In your current working directory, create a file called `.env` and add the following lines:\n",
    "```bash\n",
    "OPEN_AI_API_KEY=your-key-here\n",
    "GOOGLE_API_KEY=your-key-here\n",
    "DEEP_INFRA_API_KEY=your-key-here\n",
    "```\n",
    "Using this method will allow you to run your script without having to provide your API keys every time. However, be careful to not accidentally share your `.env` file.\n",
    "\n",
    "\n",
    "### 3. Provide your keys to EDSL directly\n",
    "Upon importing any of the EDSL modules, you will be asked to provide your API keys. You will be asked for all three keys, but you can skip any of them by pressing enter.\n",
    "\n",
    "Note that when using this method, you will have to provide your API keys every time you run your script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üê£ A simple example\n",
    "\n",
    "Here is the simplest way to run an LLM survey!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionMultipleChoice(question_text = 'How are you?', question_options = ['Good', 'Great', 'OK', 'Bad'], question_name = 'how_feeling', short_names_dict = {'Good': 'g', 'Great': 'gr', 'OK': 'ok', 'Bad': 'b'})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import QuestionMultipleChoice\n",
    "\n",
    "# this will create an example question\n",
    "q = QuestionMultipleChoice.example()\n",
    "\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results(data = [Result(agent=Agent(traits = {}), scenario={}, model=LanguageModelOpenAIThreeFiveTurbo(model = 'gpt-3.5-turbo', parameters={'temperature': 0.5, 'max_tokens': 1000, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'use_cache': True}), iteration=0, answer={'how_feeling': 'Great', 'how_feeling_comment': \"I'm feeling great today!\"}, prompt={'how_feeling_user_prompt': Prompt(text='You are being asked the following question: How are you?\n",
       "The options are\n",
       "\n",
       "0: Good\n",
       "\n",
       "1: Great\n",
       "\n",
       "2: OK\n",
       "\n",
       "3: Bad\n",
       "\n",
       "Return a valid JSON formatted like this, selecting only the number of the option:\n",
       "{\"answer\": <put answer code here>, \"comment\": \"<put explanation here>\"}\n",
       "Only 1 option may be selected.'), 'how_feeling_system_prompt': Prompt(text='You are playing the role of a human answering survey questions.\n",
       "Do not break character.\n",
       "Your traits are: ')}], survey = Survey(questions=[QuestionMultipleChoice(question_text = 'How are you?', question_options = ['Good', 'Great', 'OK', 'Bad'], question_name = 'how_feeling', short_names_dict = {'Good': 'g', 'Great': 'gr', 'OK': 'ok', 'Bad': 'b'})], name=None), created_columns = [])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will answer the question using OpenAI's LLM\n",
    "result = q.run()\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Making your own survey\n",
    "\n",
    "To be added"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
