{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d4d5c2583fc14fdb895e689f40ba6737",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Comparing model responses\n",
    "This notebook provides sample [EDSL](https://docs.expectedparrot.com/en/latest/) code for comparing content created by different language models and examining how models rate their own content versus content created by other models. \n",
    "\n",
    "In a series of steps we select some models, prompt them to generate some content, then prompt them to evaluate each piece of content that was generated, and then analyze the results in datasets.\n",
    "\n",
    "Before running this notebook please see details on [installing EDSL](https://docs.expectedparrot.com/en/latest/installation.html) and [getting started](https://docs.expectedparrot.com/en/latest/tutorial_getting_started.html) using the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "83ac608cf73d49f2a35d9cf45c2b7c75",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# ! pip install edsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting language models\n",
    "EDSL works with many popular models. (Please send us a request for a model you like that's missing!) We can see a current list of available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "4fa4d5aa948642b1972b84993e35f685",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 205,
    "execution_start": 1709310900433,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['01-ai/Yi-34B-Chat', 'deep_infra', 0],\n",
       " ['Austism/chronos-hermes-13b-v2', 'deep_infra', 1],\n",
       " ['Gryphe/MythoMax-L2-13b', 'deep_infra', 2],\n",
       " ['Gryphe/MythoMax-L2-13b-turbo', 'deep_infra', 3],\n",
       " ['HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1', 'deep_infra', 4],\n",
       " ['Phind/Phind-CodeLlama-34B-v2', 'deep_infra', 5],\n",
       " ['bigcode/starcoder2-15b', 'deep_infra', 6],\n",
       " ['bigcode/starcoder2-15b-instruct-v0.1', 'deep_infra', 7],\n",
       " ['claude-3-haiku-20240307', 'anthropic', 8],\n",
       " ['claude-3-opus-20240229', 'anthropic', 9],\n",
       " ['claude-3-sonnet-20240229', 'anthropic', 10],\n",
       " ['codellama/CodeLlama-34b-Instruct-hf', 'deep_infra', 11],\n",
       " ['codellama/CodeLlama-70b-Instruct-hf', 'deep_infra', 12],\n",
       " ['cognitivecomputations/dolphin-2.6-mixtral-8x7b', 'deep_infra', 13],\n",
       " ['databricks/dbrx-instruct', 'deep_infra', 14],\n",
       " ['deepinfra/airoboros-70b', 'deep_infra', 15],\n",
       " ['gemini-pro', 'google', 16],\n",
       " ['google/codegemma-7b-it', 'deep_infra', 17],\n",
       " ['google/gemma-1.1-7b-it', 'deep_infra', 18],\n",
       " ['gpt-3.5-turbo', 'openai', 19],\n",
       " ['gpt-3.5-turbo-0125', 'openai', 20],\n",
       " ['gpt-3.5-turbo-0301', 'openai', 21],\n",
       " ['gpt-3.5-turbo-0613', 'openai', 22],\n",
       " ['gpt-3.5-turbo-1106', 'openai', 23],\n",
       " ['gpt-3.5-turbo-16k', 'openai', 24],\n",
       " ['gpt-3.5-turbo-16k-0613', 'openai', 25],\n",
       " ['gpt-3.5-turbo-instruct', 'openai', 26],\n",
       " ['gpt-3.5-turbo-instruct-0914', 'openai', 27],\n",
       " ['gpt-4', 'openai', 28],\n",
       " ['gpt-4-0125-preview', 'openai', 29],\n",
       " ['gpt-4-0613', 'openai', 30],\n",
       " ['gpt-4-1106-preview', 'openai', 31],\n",
       " ['gpt-4-1106-vision-preview', 'openai', 32],\n",
       " ['gpt-4-turbo', 'openai', 33],\n",
       " ['gpt-4-turbo-2024-04-09', 'openai', 34],\n",
       " ['gpt-4-turbo-preview', 'openai', 35],\n",
       " ['gpt-4-vision-preview', 'openai', 36],\n",
       " ['gpt-4o', 'openai', 37],\n",
       " ['gpt-4o-2024-05-13', 'openai', 38],\n",
       " ['lizpreciatior/lzlv_70b_fp16_hf', 'deep_infra', 39],\n",
       " ['llava-hf/llava-1.5-7b-hf', 'deep_infra', 40],\n",
       " ['meta-llama/Llama-2-13b-chat-hf', 'deep_infra', 41],\n",
       " ['meta-llama/Llama-2-70b-chat-hf', 'deep_infra', 42],\n",
       " ['meta-llama/Llama-2-7b-chat-hf', 'deep_infra', 43],\n",
       " ['meta-llama/Meta-Llama-3-70B-Instruct', 'deep_infra', 44],\n",
       " ['meta-llama/Meta-Llama-3-8B-Instruct', 'deep_infra', 45],\n",
       " ['microsoft/WizardLM-2-7B', 'deep_infra', 46],\n",
       " ['microsoft/WizardLM-2-8x22B', 'deep_infra', 47],\n",
       " ['mistralai/Mistral-7B-Instruct-v0.1', 'deep_infra', 48],\n",
       " ['mistralai/Mistral-7B-Instruct-v0.2', 'deep_infra', 49],\n",
       " ['mistralai/Mixtral-8x22B-Instruct-v0.1', 'deep_infra', 50],\n",
       " ['mistralai/Mixtral-8x22B-v0.1', 'deep_infra', 51],\n",
       " ['mistralai/Mixtral-8x7B-Instruct-v0.1', 'deep_infra', 52],\n",
       " ['openchat/openchat_3.5', 'deep_infra', 53]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Model\n",
    "\n",
    "Model.available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cc1f7bddab344d378e8ce81dfea70a69",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We select models to use by creating `Model` objects that we will add to our survey when we run it. (If we do not specify a model, GPT 4 preview will be used by default.) Here we select 4 models and store them as a list in order to use them all together with our survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "747d40bea4eb41b5a89d8b374216837e",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    Model(m)\n",
    "    for m in (\n",
    "        \"gpt-3.5-turbo\",\n",
    "        \"gpt-4-1106-preview\",\n",
    "        \"gemini-pro\",\n",
    "        \"claude-3-opus-20240229\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating content\n",
    "EDSL comes with a variety of standard survey question types (multiple choice, free text, etc.) that we can select to use based on the desired format of the response (e.g., a selection from a list of options, unstructured text, etc.). [See examples of all question types](https://docs.expectedparrot.com/en/latest/questions.html#question-type-classes). Here we use `QuestionList` in order to prompt the model to provide its response in the form of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "1325605571cc41a194255b80b2fb2f87",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from edsl.questions import QuestionList, QuestionLinearScale\n",
    "\n",
    "q_content = QuestionList(\n",
    "    question_name=\"content\",\n",
    "    question_text=\"What are recommended steps for conducting research with large language models?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a response by passing the question to a `Survey` object, adding the models, and then calling the `run` method. This will generate a `Results` object with a `Result` for each survey response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "724ca2c7a38f4164a225ed4a8dcc2b1f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from edsl import Survey\n",
    "\n",
    "# Pass a list of one ore more questions to be administered together in the survey\n",
    "survey = Survey([q_content])\n",
    "\n",
    "# Run the survey with the models\n",
    "results = survey.by(models).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect components of the results individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "c68d3be8bada402ea17184b978abfa70",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> model                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> answer                                                                                 </span>┃\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .model                 </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .content                                                                               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Select appropriate language model', 'Collect and       </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> preprocess data', 'Train the language model', 'Evaluate model performance', 'Iterate   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> and refine model as needed']                                                           </span>│\n",
       "├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Choose a suitable large language model', 'Prepare a    </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> dataset', 'Fine-tune the model (if necessary)', 'Develop a set of prompts or queries', </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Run the model to generate responses', 'Analyze the responses', 'Validate findings',   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Document the methodology and results', 'Publish or share the findings']               </span>│\n",
       "├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research question', 'Gather and prepare data', 'Select and train model',      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Evaluate model', 'Interpret and communicate results']                                 </span>│\n",
       "├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research questions and hypotheses', 'Choose appropriate language model(s)',   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Collect or generate datasets', 'Fine-tune models if needed', 'Develop evaluation      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> metrics', 'Run experiments and collect results', 'Analyze and interpret findings',     </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Document methodology and results', 'Publish and share research']                      </span>│\n",
       "└────────────────────────┴────────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mmodel                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35manswer                                                                                \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m.model                \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m.content                                                                              \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Select appropriate language model', 'Collect and      \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mpreprocess data', 'Train the language model', 'Evaluate model performance', 'Iterate  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mand refine model as needed']                                                          \u001b[0m\u001b[2m \u001b[0m│\n",
       "├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Choose a suitable large language model', 'Prepare a   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdataset', 'Fine-tune the model (if necessary)', 'Develop a set of prompts or queries',\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Run the model to generate responses', 'Analyze the responses', 'Validate findings',  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Document the methodology and results', 'Publish or share the findings']              \u001b[0m\u001b[2m \u001b[0m│\n",
       "├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research question', 'Gather and prepare data', 'Select and train model',     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Evaluate model', 'Interpret and communicate results']                                \u001b[0m\u001b[2m \u001b[0m│\n",
       "├────────────────────────┼────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research questions and hypotheses', 'Choose appropriate language model(s)',  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Collect or generate datasets', 'Fine-tune models if needed', 'Develop evaluation     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mmetrics', 'Run experiments and collect results', 'Analyze and interpret findings',    \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Document methodology and results', 'Publish and share research']                     \u001b[0m\u001b[2m \u001b[0m│\n",
       "└────────────────────────┴────────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.select(\"model\", \"content\").print(format=\"rich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see a list of all components of results we can call the `columns` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent.agent_instruction',\n",
       " 'agent.agent_name',\n",
       " 'answer.content',\n",
       " 'comment.content_comment',\n",
       " 'iteration.iteration',\n",
       " 'model.frequency_penalty',\n",
       " 'model.logprobs',\n",
       " 'model.maxOutputTokens',\n",
       " 'model.max_tokens',\n",
       " 'model.model',\n",
       " 'model.presence_penalty',\n",
       " 'model.stopSequences',\n",
       " 'model.temperature',\n",
       " 'model.topK',\n",
       " 'model.topP',\n",
       " 'model.top_logprobs',\n",
       " 'model.top_p',\n",
       " 'prompt.content_system_prompt',\n",
       " 'prompt.content_user_prompt',\n",
       " 'question_options.content_question_options',\n",
       " 'question_text.content_question_text',\n",
       " 'question_type.content_question_type',\n",
       " 'raw_model_response.content_raw_model_response']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing results\n",
    "EDSL comes with a variety of built-in methods for working with results. [See details on methods](https://docs.expectedparrot.com/en/latest/results.html). For example, we can turn the results into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_instruction</th>\n",
       "      <th>agent_name</th>\n",
       "      <th>content</th>\n",
       "      <th>content_comment</th>\n",
       "      <th>content_question_options</th>\n",
       "      <th>content_question_text</th>\n",
       "      <th>content_question_type</th>\n",
       "      <th>content_raw_model_response</th>\n",
       "      <th>content_system_prompt</th>\n",
       "      <th>content_user_prompt</th>\n",
       "      <th>...</th>\n",
       "      <th>maxOutputTokens</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>model</th>\n",
       "      <th>presence_penalty</th>\n",
       "      <th>stopSequences</th>\n",
       "      <th>temperature</th>\n",
       "      <th>topK</th>\n",
       "      <th>topP</th>\n",
       "      <th>top_logprobs</th>\n",
       "      <th>top_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are answering questions as if you were a h...</td>\n",
       "      <td>Agent_0</td>\n",
       "      <td>['Define research objectives', 'Select appropr...</td>\n",
       "      <td>Conducting research with large language models...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are recommended steps for conducting rese...</td>\n",
       "      <td>list</td>\n",
       "      <td>{'id': 'chatcmpl-9OmKwsgaBy670dlrE1Am7HdysUOPd...</td>\n",
       "      <td>You are answering questions as if you were a h...</td>\n",
       "      <td>What are recommended steps for conducting rese...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are answering questions as if you were a h...</td>\n",
       "      <td>Agent_0</td>\n",
       "      <td>['Define research objectives', 'Choose a suita...</td>\n",
       "      <td>The steps listed provide a structured approach...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are recommended steps for conducting rese...</td>\n",
       "      <td>list</td>\n",
       "      <td>{'id': 'chatcmpl-9OmKwjgCqIQxkG3B3CiMOkvh1S8dV...</td>\n",
       "      <td>You are answering questions as if you were a h...</td>\n",
       "      <td>What are recommended steps for conducting rese...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are answering questions as if you were a h...</td>\n",
       "      <td>Agent_0</td>\n",
       "      <td>['Define research question', 'Gather and prepa...</td>\n",
       "      <td>These steps provide a general framework for co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are recommended steps for conducting rese...</td>\n",
       "      <td>list</td>\n",
       "      <td>{'candidates': [{'content': {'parts': [{'text'...</td>\n",
       "      <td>You are answering questions as if you were a h...</td>\n",
       "      <td>What are recommended steps for conducting rese...</td>\n",
       "      <td>...</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are answering questions as if you were a h...</td>\n",
       "      <td>Agent_0</td>\n",
       "      <td>['Define research questions and hypotheses', '...</td>\n",
       "      <td>Conducting research with large language models...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are recommended steps for conducting rese...</td>\n",
       "      <td>list</td>\n",
       "      <td>{'id': 'msg_01WWtPxke2Ez3W8oydFyqthb', 'conten...</td>\n",
       "      <td>You are answering questions as if you were a h...</td>\n",
       "      <td>What are recommended steps for conducting rese...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   agent_instruction agent_name  \\\n",
       "0  You are answering questions as if you were a h...    Agent_0   \n",
       "1  You are answering questions as if you were a h...    Agent_0   \n",
       "2  You are answering questions as if you were a h...    Agent_0   \n",
       "3  You are answering questions as if you were a h...    Agent_0   \n",
       "\n",
       "                                             content  \\\n",
       "0  ['Define research objectives', 'Select appropr...   \n",
       "1  ['Define research objectives', 'Choose a suita...   \n",
       "2  ['Define research question', 'Gather and prepa...   \n",
       "3  ['Define research questions and hypotheses', '...   \n",
       "\n",
       "                                     content_comment  \\\n",
       "0  Conducting research with large language models...   \n",
       "1  The steps listed provide a structured approach...   \n",
       "2  These steps provide a general framework for co...   \n",
       "3  Conducting research with large language models...   \n",
       "\n",
       "   content_question_options  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3                       NaN   \n",
       "\n",
       "                               content_question_text content_question_type  \\\n",
       "0  What are recommended steps for conducting rese...                  list   \n",
       "1  What are recommended steps for conducting rese...                  list   \n",
       "2  What are recommended steps for conducting rese...                  list   \n",
       "3  What are recommended steps for conducting rese...                  list   \n",
       "\n",
       "                          content_raw_model_response  \\\n",
       "0  {'id': 'chatcmpl-9OmKwsgaBy670dlrE1Am7HdysUOPd...   \n",
       "1  {'id': 'chatcmpl-9OmKwjgCqIQxkG3B3CiMOkvh1S8dV...   \n",
       "2  {'candidates': [{'content': {'parts': [{'text'...   \n",
       "3  {'id': 'msg_01WWtPxke2Ez3W8oydFyqthb', 'conten...   \n",
       "\n",
       "                               content_system_prompt  \\\n",
       "0  You are answering questions as if you were a h...   \n",
       "1  You are answering questions as if you were a h...   \n",
       "2  You are answering questions as if you were a h...   \n",
       "3  You are answering questions as if you were a h...   \n",
       "\n",
       "                                 content_user_prompt  ...  maxOutputTokens  \\\n",
       "0  What are recommended steps for conducting rese...  ...              NaN   \n",
       "1  What are recommended steps for conducting rese...  ...              NaN   \n",
       "2  What are recommended steps for conducting rese...  ...           2048.0   \n",
       "3  What are recommended steps for conducting rese...  ...              NaN   \n",
       "\n",
       "   max_tokens                   model  presence_penalty  stopSequences  \\\n",
       "0      1000.0           gpt-3.5-turbo               0.0            NaN   \n",
       "1      1000.0      gpt-4-1106-preview               0.0            NaN   \n",
       "2         NaN              gemini-pro               NaN             []   \n",
       "3      1000.0  claude-3-opus-20240229               0.0            NaN   \n",
       "\n",
       "  temperature  topK topP  top_logprobs  top_p  \n",
       "0         0.5   NaN  NaN           3.0    1.0  \n",
       "1         0.5   NaN  NaN           3.0    1.0  \n",
       "2         0.5   1.0  1.0           NaN    NaN  \n",
       "3         0.5   NaN  NaN           3.0    1.0  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = results.to_pandas(remove_prefix=True)  # We can drop the column prefixes if we want\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract components of the results that we'll use to conduct our by-model review of the content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-3.5-turbo': \"['Define research objectives', 'Select appropriate language model', 'Collect and preprocess data', 'Train the language model', 'Evaluate model performance', 'Iterate and refine model as needed']\",\n",
       " 'gpt-4-1106-preview': \"['Define research objectives', 'Choose a suitable large language model', 'Prepare a dataset', 'Fine-tune the model (if necessary)', 'Develop a set of prompts or queries', 'Run the model to generate responses', 'Analyze the responses', 'Validate findings', 'Document the methodology and results', 'Publish or share the findings']\",\n",
       " 'gemini-pro': \"['Define research question', 'Gather and prepare data', 'Select and train model', 'Evaluate model', 'Interpret and communicate results']\",\n",
       " 'claude-3-opus-20240229': \"['Define research questions and hypotheses', 'Choose appropriate language model(s)', 'Collect or generate datasets', 'Fine-tune models if needed', 'Develop evaluation metrics', 'Run experiments and collect results', 'Analyze and interpret findings', 'Document methodology and results', 'Publish and share research']\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_dict = dict(zip(df[\"model\"], df[\"content\"]))\n",
    "content_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "09c51c4a264248d3a6ca865d70844279",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Conducting a review\n",
    "Next we create a new question (in another appropriate question type) to have the models evaluate each piece of content that was generated. We do this by parameterizing a question with different \"scenarios\" of the content to be evaluated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl.questions import QuestionLinearScale\n",
    "\n",
    "q_score = QuestionLinearScale(\n",
    "    question_name=\"score\",\n",
    "    question_text=\"\"\"Consider the following response to the question\n",
    "    'What are recommended steps for conducting research with large language models?'\n",
    "    Response: {{ content }}\n",
    "    Score this response in terms of accuracy and completeness.\n",
    "    (Drafting model: {{ drafting_model }})\"\"\",\n",
    "    question_options=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    option_labels={0: \"Terrible\", 10: \"Amazing\"},\n",
    ")\n",
    "\n",
    "survey = Survey([q_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `Scenario` object for each piece of content that we will add to the question when we run it (a generalizable data labeling task). We also track the model that drafted the content for analysis of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Scenario({'drafting_model': 'gpt-3.5-turbo', 'content': \"['Define research objectives', 'Select appropriate language model', 'Collect and preprocess data', 'Train the language model', 'Evaluate model performance', 'Iterate and refine model as needed']\"}),\n",
       " Scenario({'drafting_model': 'gpt-4-1106-preview', 'content': \"['Define research objectives', 'Choose a suitable large language model', 'Prepare a dataset', 'Fine-tune the model (if necessary)', 'Develop a set of prompts or queries', 'Run the model to generate responses', 'Analyze the responses', 'Validate findings', 'Document the methodology and results', 'Publish or share the findings']\"}),\n",
       " Scenario({'drafting_model': 'gemini-pro', 'content': \"['Define research question', 'Gather and prepare data', 'Select and train model', 'Evaluate model', 'Interpret and communicate results']\"}),\n",
       " Scenario({'drafting_model': 'claude-3-opus-20240229', 'content': \"['Define research questions and hypotheses', 'Choose appropriate language model(s)', 'Collect or generate datasets', 'Fine-tune models if needed', 'Develop evaluation metrics', 'Run experiments and collect results', 'Analyze and interpret findings', 'Document methodology and results', 'Publish and share research']\"})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Scenario\n",
    "\n",
    "scenarios = [\n",
    "    Scenario({\"drafting_model\": m, \"content\": c}) for m, c in content_dict.items()\n",
    "]\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add the scenarios and models to the survey and run it, generating a dataset of results that we can begin analyzing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = survey.by(scenarios).by(models).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select components to inspect in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> model                  </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> scenario               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> scenario                                             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> answer </span>┃\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .model                 </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .drafting_model        </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .content                                             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .score </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research questions and hypotheses', 'Choose </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> appropriate language model(s)', 'Collect or generate </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> datasets', 'Fine-tune models if needed', 'Develop    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> evaluation metrics', 'Run experiments and collect    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> results', 'Analyze and interpret findings',          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Document methodology and results', 'Publish and     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> share research']                                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research question', 'Gather and prepare     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> data', 'Select and train model', 'Evaluate model',   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Interpret and communicate results']                 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Select appropriate   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> language model', 'Collect and preprocess data',      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Train the language model', 'Evaluate model          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> performance', 'Iterate and refine model as needed']  </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Choose a suitable    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> large language model', 'Prepare a dataset',          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Fine-tune the model (if necessary)', 'Develop a set </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> of prompts or queries', 'Run the model to generate   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> responses', 'Analyze the responses', 'Validate       </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> findings', 'Document the methodology and results',   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Publish or share the findings']                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research questions and hypotheses', 'Choose </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> appropriate language model(s)', 'Collect or generate </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> datasets', 'Fine-tune models if needed', 'Develop    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> evaluation metrics', 'Run experiments and collect    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> results', 'Analyze and interpret findings',          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Document methodology and results', 'Publish and     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> share research']                                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research question', 'Gather and prepare     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> data', 'Select and train model', 'Evaluate model',   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Interpret and communicate results']                 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Select appropriate   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10     </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> language model', 'Collect and preprocess data',      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Train the language model', 'Evaluate model          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> performance', 'Iterate and refine model as needed']  </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Choose a suitable    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> large language model', 'Prepare a dataset',          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Fine-tune the model (if necessary)', 'Develop a set </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> of prompts or queries', 'Run the model to generate   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> responses', 'Analyze the responses', 'Validate       </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> findings', 'Document the methodology and results',   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Publish or share the findings']                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research questions and hypotheses', 'Choose </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> appropriate language model(s)', 'Collect or generate </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> datasets', 'Fine-tune models if needed', 'Develop    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> evaluation metrics', 'Run experiments and collect    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> results', 'Analyze and interpret findings',          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Document methodology and results', 'Publish and     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> share research']                                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research question', 'Gather and prepare     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10     </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> data', 'Select and train model', 'Evaluate model',   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Interpret and communicate results']                 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Select appropriate   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> language model', 'Collect and preprocess data',      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Train the language model', 'Evaluate model          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> performance', 'Iterate and refine model as needed']  </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Choose a suitable    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> large language model', 'Prepare a dataset',          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Fine-tune the model (if necessary)', 'Develop a set </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> of prompts or queries', 'Run the model to generate   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> responses', 'Analyze the responses', 'Validate       </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> findings', 'Document the methodology and results',   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Publish or share the findings']                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-opus-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research questions and hypotheses', 'Choose </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> appropriate language model(s)', 'Collect or generate </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> datasets', 'Fine-tune models if needed', 'Develop    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> evaluation metrics', 'Run experiments and collect    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> results', 'Analyze and interpret findings',          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Document methodology and results', 'Publish and     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> share research']                                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro             </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research question', 'Gather and prepare     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> data', 'Select and train model', 'Evaluate model',   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Interpret and communicate results']                 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Select appropriate   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> language model', 'Collect and preprocess data',      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Train the language model', 'Evaluate model          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> performance', 'Iterate and refine model as needed']  </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> ['Define research objectives', 'Choose a suitable    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> large language model', 'Prepare a dataset',          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Fine-tune the model (if necessary)', 'Develop a set </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> of prompts or queries', 'Run the model to generate   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> responses', 'Analyze the responses', 'Validate       </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> findings', 'Document the methodology and results',   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                        </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 'Publish or share the findings']                     </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">        </span>│\n",
       "└────────────────────────┴────────────────────────┴──────────────────────────────────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mmodel                 \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mscenario              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mscenario                                            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35manswer\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m.model                \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m.drafting_model       \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m.content                                            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m.score\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research questions and hypotheses', 'Choose\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m9     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mappropriate language model(s)', 'Collect or generate\u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdatasets', 'Fine-tune models if needed', 'Develop   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mevaluation metrics', 'Run experiments and collect   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresults', 'Analyze and interpret findings',         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Document methodology and results', 'Publish and    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mshare research']                                    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research question', 'Gather and prepare    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m8     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdata', 'Select and train model', 'Evaluate model',  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Interpret and communicate results']                \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Select appropriate  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m8     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mlanguage model', 'Collect and preprocess data',     \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Train the language model', 'Evaluate model         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mperformance', 'Iterate and refine model as needed'] \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Choose a suitable   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m9     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mlarge language model', 'Prepare a dataset',         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Fine-tune the model (if necessary)', 'Develop a set\u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mof prompts or queries', 'Run the model to generate  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresponses', 'Analyze the responses', 'Validate      \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mfindings', 'Document the methodology and results',  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Publish or share the findings']                    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research questions and hypotheses', 'Choose\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m8     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mappropriate language model(s)', 'Collect or generate\u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdatasets', 'Fine-tune models if needed', 'Develop   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mevaluation metrics', 'Run experiments and collect   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresults', 'Analyze and interpret findings',         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Document methodology and results', 'Publish and    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mshare research']                                    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research question', 'Gather and prepare    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m4     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdata', 'Select and train model', 'Evaluate model',  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Interpret and communicate results']                \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Select appropriate  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m10    \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mlanguage model', 'Collect and preprocess data',     \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Train the language model', 'Evaluate model         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mperformance', 'Iterate and refine model as needed'] \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Choose a suitable   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m9     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mlarge language model', 'Prepare a dataset',         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Fine-tune the model (if necessary)', 'Develop a set\u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mof prompts or queries', 'Run the model to generate  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresponses', 'Analyze the responses', 'Validate      \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mfindings', 'Document the methodology and results',  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Publish or share the findings']                    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research questions and hypotheses', 'Choose\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m8     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mappropriate language model(s)', 'Collect or generate\u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdatasets', 'Fine-tune models if needed', 'Develop   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mevaluation metrics', 'Run experiments and collect   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresults', 'Analyze and interpret findings',         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Document methodology and results', 'Publish and    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mshare research']                                    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research question', 'Gather and prepare    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m10    \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdata', 'Select and train model', 'Evaluate model',  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Interpret and communicate results']                \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Select appropriate  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m9     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mlanguage model', 'Collect and preprocess data',     \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Train the language model', 'Evaluate model         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mperformance', 'Iterate and refine model as needed'] \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Choose a suitable   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m9     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mlarge language model', 'Prepare a dataset',         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Fine-tune the model (if necessary)', 'Develop a set\u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mof prompts or queries', 'Run the model to generate  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresponses', 'Analyze the responses', 'Validate      \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mfindings', 'Document the methodology and results',  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Publish or share the findings']                    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mclaude-3-opus-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research questions and hypotheses', 'Choose\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m9     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mappropriate language model(s)', 'Collect or generate\u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdatasets', 'Fine-tune models if needed', 'Develop   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mevaluation metrics', 'Run experiments and collect   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresults', 'Analyze and interpret findings',         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Document methodology and results', 'Publish and    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mshare research']                                    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgemini-pro            \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research question', 'Gather and prepare    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m7     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdata', 'Select and train model', 'Evaluate model',  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Interpret and communicate results']                \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Select appropriate  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m8     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mlanguage model', 'Collect and preprocess data',     \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Train the language model', 'Evaluate model         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mperformance', 'Iterate and refine model as needed'] \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "├────────────────────────┼────────────────────────┼──────────────────────────────────────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m['Define research objectives', 'Choose a suitable   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2m9     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mlarge language model', 'Prepare a dataset',         \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Fine-tune the model (if necessary)', 'Develop a set\u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mof prompts or queries', 'Run the model to generate  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mresponses', 'Analyze the responses', 'Validate      \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2mfindings', 'Document the methodology and results',  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "│\u001b[2m                        \u001b[0m│\u001b[2m                        \u001b[0m│\u001b[2m \u001b[0m\u001b[2m'Publish or share the findings']                    \u001b[0m\u001b[2m \u001b[0m│\u001b[2m        \u001b[0m│\n",
       "└────────────────────────┴────────────────────────┴──────────────────────────────────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    results.sort_by(\"drafting_model\")\n",
    "    .sort_by(\"model\")\n",
    "    .select(\"model\", \"drafting_model\", \"content\", \"score\")\n",
    "    .print(\n",
    "        pretty_labels={\n",
    "            \"model\": \"Critiquing model\",\n",
    "            \"drafting_model\": \"Drafing model\",\n",
    "            \"content\": \"Content\",\n",
    "            \"score\": \"Score\",\n",
    "        },\n",
    "        format=\"rich\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing results as datasets\n",
    "EDSL allows us to immediately begin analyzing model responses as datasets. Here we compare each model's score of its own content versus its scores for other models' content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compare(df):\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Extract the models' self scores\n",
    "    self_scores = df[df[\"model\"] == df[\"drafting_model\"]][[\"model\", \"score\"]]\n",
    "    self_scores = self_scores.rename(columns={\"score\": \"self_score\"}).drop_duplicates()\n",
    "\n",
    "    # Merge the self scores\n",
    "    df_copy = df_copy.merge(self_scores, on=\"model\", how=\"left\")\n",
    "\n",
    "    # Compare the scores and self scores\n",
    "    conditions = [\n",
    "        df_copy[\"model\"] == df_copy[\"drafting_model\"],  # Self scoring\n",
    "        df_copy[\"score\"] < df_copy[\"self_score\"],  # Score lower than self score\n",
    "        df_copy[\"score\"] > df_copy[\"self_score\"],  # Score higher than self score\n",
    "    ]\n",
    "    choices = [\"Self score\", \"Lower\", \"Higher\"]\n",
    "\n",
    "    df_copy[\"comparison\"] = np.select(conditions, choices, default=\"Equal\")\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>drafting_model</th>\n",
       "      <th>score</th>\n",
       "      <th>comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>9</td>\n",
       "      <td>Self score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>8</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>8</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>9</td>\n",
       "      <td>Equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>8</td>\n",
       "      <td>Higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>4</td>\n",
       "      <td>Self score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>10</td>\n",
       "      <td>Higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>9</td>\n",
       "      <td>Higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>8</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>10</td>\n",
       "      <td>Higher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>9</td>\n",
       "      <td>Self score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>9</td>\n",
       "      <td>Equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>9</td>\n",
       "      <td>Equal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>7</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>8</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>9</td>\n",
       "      <td>Self score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model          drafting_model  score  comparison\n",
       "14  claude-3-opus-20240229  claude-3-opus-20240229      9  Self score\n",
       "13  claude-3-opus-20240229              gemini-pro      8       Lower\n",
       "12  claude-3-opus-20240229           gpt-3.5-turbo      8       Lower\n",
       "15  claude-3-opus-20240229      gpt-4-1106-preview      9       Equal\n",
       "11              gemini-pro  claude-3-opus-20240229      8      Higher\n",
       "8               gemini-pro              gemini-pro      4  Self score\n",
       "2               gemini-pro           gpt-3.5-turbo     10      Higher\n",
       "5               gemini-pro      gpt-4-1106-preview      9      Higher\n",
       "9            gpt-3.5-turbo  claude-3-opus-20240229      8       Lower\n",
       "6            gpt-3.5-turbo              gemini-pro     10      Higher\n",
       "0            gpt-3.5-turbo           gpt-3.5-turbo      9  Self score\n",
       "3            gpt-3.5-turbo      gpt-4-1106-preview      9       Equal\n",
       "10      gpt-4-1106-preview  claude-3-opus-20240229      9       Equal\n",
       "7       gpt-4-1106-preview              gemini-pro      7       Lower\n",
       "1       gpt-4-1106-preview           gpt-3.5-turbo      8       Lower\n",
       "4       gpt-4-1106-preview      gpt-4-1106-preview      9  Self score"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = results.to_pandas(remove_prefix=True)\n",
    "compare_df = compare(df)\n",
    "\n",
    "compare_df[[\"model\", \"drafting_model\", \"score\", \"comparison\"]].sort_values(\n",
    "    by=[\"model\", \"drafting_model\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def summarize(df):\n",
    "    # Merge the self scores\n",
    "    df_self_scores = (\n",
    "        df[df[\"model\"] == df[\"drafting_model\"]]\n",
    "        .set_index(\"model\")[\"score\"]\n",
    "        .rename(\"self_score\")\n",
    "    )\n",
    "    df = df.merge(df_self_scores, on=\"model\", how=\"left\")\n",
    "\n",
    "    # Define the comparison logic\n",
    "    conditions = [\n",
    "        df[\"score\"] > df[\"self_score\"],\n",
    "        df[\"score\"] < df[\"self_score\"],\n",
    "        df[\"score\"] == df[\"self_score\"],\n",
    "    ]\n",
    "    choices = [\"better_models\", \"worse_models\", \"equal\"]\n",
    "    df[\"category\"] = np.select(conditions, choices)\n",
    "\n",
    "    # Create a df to summarize better, worse, and equal models for each model\n",
    "    summary_data = {\"model\": [], \"better_models\": [], \"worse_models\": [], \"equal\": []}\n",
    "\n",
    "    for model in df[\"model\"].unique():\n",
    "        model_data = df[df[\"model\"] == model]\n",
    "        summary_data[\"model\"].append(model)\n",
    "        summary_data[\"better_models\"].append(\n",
    "            model_data[model_data[\"category\"] == \"better_models\"][\n",
    "                \"drafting_model\"\n",
    "            ].tolist()\n",
    "        )\n",
    "        summary_data[\"worse_models\"].append(\n",
    "            model_data[model_data[\"category\"] == \"worse_models\"][\n",
    "                \"drafting_model\"\n",
    "            ].tolist()\n",
    "        )\n",
    "        summary_data[\"equal\"].append(\n",
    "            model_data[model_data[\"category\"] == \"equal\"][\"drafting_model\"].tolist()\n",
    "        )\n",
    "\n",
    "    # Convert the dictionary to a df\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>better_models</th>\n",
       "      <th>worse_models</th>\n",
       "      <th>equal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>[gemini-pro]</td>\n",
       "      <td>[claude-3-opus-20240229]</td>\n",
       "      <td>[gpt-3.5-turbo, gpt-4-1106-preview]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[]</td>\n",
       "      <td>[gpt-3.5-turbo, gemini-pro]</td>\n",
       "      <td>[gpt-4-1106-preview, claude-3-opus-20240229]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>[gpt-3.5-turbo, gpt-4-1106-preview, claude-3-o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[gemini-pro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-3-opus-20240229</td>\n",
       "      <td>[]</td>\n",
       "      <td>[gpt-3.5-turbo, gemini-pro]</td>\n",
       "      <td>[claude-3-opus-20240229, gpt-4-1106-preview]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                      better_models  \\\n",
       "0           gpt-3.5-turbo                                       [gemini-pro]   \n",
       "1      gpt-4-1106-preview                                                 []   \n",
       "2              gemini-pro  [gpt-3.5-turbo, gpt-4-1106-preview, claude-3-o...   \n",
       "3  claude-3-opus-20240229                                                 []   \n",
       "\n",
       "                  worse_models                                         equal  \n",
       "0     [claude-3-opus-20240229]           [gpt-3.5-turbo, gpt-4-1106-preview]  \n",
       "1  [gpt-3.5-turbo, gemini-pro]  [gpt-4-1106-preview, claude-3-opus-20240229]  \n",
       "2                           []                                  [gemini-pro]  \n",
       "3  [gpt-3.5-turbo, gemini-pro]  [claude-3-opus-20240229, gpt-4-1106-preview]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = results.to_pandas(remove_prefix=True)\n",
    "summary_df = summarize(df)\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further analysis\n",
    "This code is readily editable to compare results for other models and questions. It can also be expanded to compare responses among AI agents with different traits and personas that we prompt the models to use to answer the questions. Please see our docs for [details on designing AI agents](https://docs.expectedparrot.com/en/latest/agents.html) and using them to simulate responses for audiences of interest."
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6d1e666ba52649708894044c2a755567",
  "deepnote_persisted_session": {
   "createdAt": "2024-03-01T17:07:23.650Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
