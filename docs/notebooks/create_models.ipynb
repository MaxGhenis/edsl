{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4869f015fbd2464fa99ffad22babb931",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Creating Models\n",
    "This notebook contains code for specifying large language models to use with `edsl`. It shows how to see available models, create `Model` objects and use them to survey responses for AI agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/expectedparrot/edsl/blob/main/examples/create_models.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "ebe0f3ec65f64852b35502d630b0dafe",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# ! pip install edsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "allow_embed": "code",
    "cell_id": "c61044bce98f494b9a70101124ef073b",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 146,
    "execution_start": 1711554910003,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['claude-3-haiku-20240307',\n",
       " 'claude-3-opus-20240229',\n",
       " 'claude-3-sonnet-20240229',\n",
       " 'dbrx-instruct',\n",
       " 'gemini_pro',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-4-1106-preview',\n",
       " 'llama-2-13b-chat-hf',\n",
       " 'llama-2-70b-chat-hf',\n",
       " 'mixtral-8x7B-instruct-v0.1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Model\n",
    "\n",
    "# Show availble models \n",
    "Model.available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "ccfbb04932974aceb100e0dc0bc62930",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 76,
    "execution_start": 1709213594331,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Available models: ['claude-3-haiku-20240307', 'claude-3-opus-20240229', 'claude-3-sonnet-20240229', 'dbrx-instruct', 'gemini_pro', 'gpt-3.5-turbo', 'gpt-4-1106-preview', 'llama-2-13b-chat-hf', 'llama-2-70b-chat-hf', 'mixtral-8x7B-instruct-v0.1']\n",
       "\n",
       "To create an instance, you can do: \n",
       ">>> m = Model('gpt-4-1106-preview', temperature=0.5, ...)\n",
       "\n",
       "To get the default model, you can leave out the model name. \n",
       "To see the available models, you can do:\n",
       ">>> Model.available()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show components of a Model object\n",
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model name provided, using default model: gpt-4-1106-preview\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LanguageModelOpenAIFour(model = 'gpt-4-1106-preview', parameters={'temperature': 0.5, 'max_tokens': 1000, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'logprobs': False, 'top_logprobs': 3})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the default Model\n",
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "allow_embed": false,
    "cell_id": "bbb8241aad324836b0eec36b7fcb50ba",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 71,
    "execution_start": 1709213629294,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "# Create a Model object\n",
    "model = Model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "allow_embed": false,
    "cell_id": "81b2e8eb8fd948109611e11bca3ae962",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3262,
    "execution_start": 1709213768482,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> model              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> answer </span>┃\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .model             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .q0    </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo      </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> yes    </span>│\n",
       "├────────────────────┼────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4-1106-preview </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> yes    </span>│\n",
       "└────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mmodel             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35manswer\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m.model            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m.q0   \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo     \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2myes   \u001b[0m\u001b[2m \u001b[0m│\n",
       "├────────────────────┼────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4-1106-preview\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2myes   \u001b[0m\u001b[2m \u001b[0m│\n",
       "└────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify models to use in running a survey\n",
    "from edsl import Survey\n",
    "survey = Survey.example()\n",
    "\n",
    "models = [Model(m) for m in [\"gpt-3.5-turbo\", \"gpt-4-1106-preview\"]]\n",
    "\n",
    "results = survey.by(models).run()\n",
    "\n",
    "# Inspect the results for each model\n",
    "results.select(\"model.model\", \"answer.q0\").print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "03d02641b4554fe8a0600ee0c6612edf",
    "deepnote_app_block_visible": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "---\n",
    "<p style=\"font-size: 14px;\">Copyright © 2024 Expected Parrot, Inc. All rights reserved.   <a href=\"www.expectedparrot.com\" style=\"color:#130061\">www.expectedparrot.com</a></p>"
   ]
  }
 ],
 "metadata": {
  "deepnote_app_clear_outputs": false,
  "deepnote_app_layout": "powerful-article",
  "deepnote_app_reactivity_enabled": true,
  "deepnote_app_width": "full-width",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf5f11d7b5074908a40fda9c81b18f93",
  "deepnote_persisted_session": {
   "createdAt": "2024-03-27T16:16:10.512Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
