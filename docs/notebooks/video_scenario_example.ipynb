{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4804ef28-73f7-4998-a1a9-7fcd090d639b",
   "metadata": {},
   "source": [
    "# Using video scenarios\n",
    "*Note:* Before adding video scenarios to your survey you must install the `ffmpeg` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32819f18-c5ce-4bd8-831b-f915a7582388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e45311-c41d-47c7-979f-79eb6f2bf0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import FileStore, QuestionFreeText, Scenario, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe27920-c963-4b1c-8d9a-de763dc85c21",
   "metadata": {},
   "source": [
    "Here we add a video stored locally to Coop using the `FileStore` module.\n",
    "This allows us to retrieve it later and share it with others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4724fefe-ec76-42c4-8de5-cd862175e8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'EP landing page video showing the Models pricing and performance page',\n",
       " 'object_type': 'scenario',\n",
       " 'url': 'https://www.expectedparrot.com/content/78bc3ef9-8e08-41a0-80c9-519f214c5eb6',\n",
       " 'alias_url': 'https://www.expectedparrot.com/content/RobinHorton/models-page-video',\n",
       " 'uuid': '78bc3ef9-8e08-41a0-80c9-519f214c5eb6',\n",
       " 'version': '0.1.56.dev1',\n",
       " 'visibility': 'public'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = FileStore(\"models_page.mp4\")\n",
    "\n",
    "fs.push(\n",
    "    description = \"EP landing page video showing the Models pricing and performance page\",\n",
    "    alias = \"models-page-video\",\n",
    "    visibility = \"public\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683b3cb-0d00-46a4-87b4-c64f6431b0c9",
   "metadata": {},
   "source": [
    "Here we retrieve the video from Coop and create a `Scenario` for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb5dea9-ec51-4cad-b117-28244c027388",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FileStore.pull(\"https://www.expectedparrot.com/content/RobinHorton/models-page-video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7198c40-736d-495f-b06c-c12df98923ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Scenario({\"video\":fs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47a00a0-4af4-4273-94cb-def33a0a28da",
   "metadata": {},
   "source": [
    "Next we create a `Question` that uses the scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6706942b-73ec-41c0-b5ce-024966c7b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = QuestionFreeText(\n",
    "    question_name = \"test\",\n",
    "    question_text = \"Describe what's happening in this video: {{ scenario.video }}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8394c4-76ef-4ea1-a8d2-af38843c092f",
   "metadata": {},
   "source": [
    "Here we select an appropriate `Model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56029224-dd9d-47c1-90bf-d3438f44e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(\"gemini-2.5-flash-preview-04-17\", service_name=\"google\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46e4d42-919b-4c0c-b91b-f95e9548ab3c",
   "metadata": {},
   "source": [
    "We run the question by adding the scenario and model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de99a227-8713-48f4-bd93-faf42e8f5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = q.by(s).by(m).run(disable_remote_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bcaaff-7667-4601-953e-21ad3c0031ef",
   "metadata": {},
   "source": [
    "Here we inspect the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0afd1df-341b-4726-95b9-b57f5d347567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_1441e_row0_col0, #T_1441e_row0_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  max-width: 300px;\n",
       "  word-wrap: break-word;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1441e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1441e_level0_col0\" class=\"col_heading level0 col0\" >model.model</th>\n",
       "      <th id=\"T_1441e_level0_col1\" class=\"col_heading level0 col1\" >answer.test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1441e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1441e_row0_col0\" class=\"data row0 col0\" >gemini-2.5-flash-preview-04-17</td>\n",
       "      <td id=\"T_1441e_row0_col1\" class=\"data row0 col1\" >The video shows a screen recording of a webpage displaying a table of AI models. The table lists models from various services like Anthropic, Bedrock, deep_infra, Google, Groq, Mistral, OpenAI, Perplexity, Together, and Xai.\n",
       "\n",
       "The table has the following columns:\n",
       "- #: Row number\n",
       "- Service: The provider of the model (e.g., anthropic, bedrock, google)\n",
       "- Model: The name of the specific AI model (e.g., claude-2.0, gemini-1.5-pro, gpt-4)\n",
       "- Text Support: Indicates whether the model supports text input, shown with a green checkmark (\"Works\") or a red cross (\"Doesn't work\").\n",
       "- Image Support: Indicates whether the model supports image input, shown with a green checkmark (\"Works\") or a red cross (\"Doesn't work\").\n",
       "\n",
       "The video scrolls down through the table, showing a long list of models and their text and image support status. Most models show \"Works\" for text support, while image support varies, with many showing \"Doesn't work\". The webpage also has a header with navigation links including \"Models\" which is highlighted.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "Dataset([{'model.model': ['gemini-2.5-flash-preview-04-17']}, {'answer.test': ['The video shows a screen recording of a webpage displaying a table of AI models. The table lists models from various services like Anthropic, Bedrock, deep_infra, Google, Groq, Mistral, OpenAI, Perplexity, Together, and Xai.\\n\\nThe table has the following columns:\\n- #: Row number\\n- Service: The provider of the model (e.g., anthropic, bedrock, google)\\n- Model: The name of the specific AI model (e.g., claude-2.0, gemini-1.5-pro, gpt-4)\\n- Text Support: Indicates whether the model supports text input, shown with a green checkmark (\"Works\") or a red cross (\"Doesn\\'t work\").\\n- Image Support: Indicates whether the model supports image input, shown with a green checkmark (\"Works\") or a red cross (\"Doesn\\'t work\").\\n\\nThe video scrolls down through the table, showing a long list of models and their text and image support status. Most models show \"Works\" for text support, while image support varies, with many showing \"Doesn\\'t work\". The webpage also has a header with navigation links including \"Models\" which is highlighted.']}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.select(\"model\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d392cb-bea2-4940-93b8-b6ee1a96221b",
   "metadata": {},
   "source": [
    "We can post this notebook to Coop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08f12a5e-113b-497c-8f51-a415e42a33d4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'How to create video scenarios',\n",
       " 'object_type': 'notebook',\n",
       " 'url': 'https://www.expectedparrot.com/content/e1da761d-0899-4e7b-b574-38b9adb6d2cd',\n",
       " 'alias_url': 'https://www.expectedparrot.com/content/RobinHorton/video-scenarios-notebook',\n",
       " 'uuid': 'e1da761d-0899-4e7b-b574-38b9adb6d2cd',\n",
       " 'version': '0.1.56.dev1',\n",
       " 'visibility': 'public'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Notebook\n",
    "\n",
    "nb = Notebook(\"video_scenario_example.ipynb\")\n",
    "nb.push(\n",
    "    description = \"How to create video scenarios\",\n",
    "    alias = \"video-scenarios-notebook\",\n",
    "    visibility = \"public\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
