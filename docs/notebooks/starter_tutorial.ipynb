{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20e93c0-943f-46fb-8382-ca6f1eb48810",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Starter Tutorial\n",
    "This tutorial provides example code for getting started using **EDSL**, an open-source Python library for simulating surveys, experiments and other research tasks with AI agents and large language models. EDSL is available under the MIT License at [PyPI](https://pypi.org/project/edsl/) and [GitHub](https://github.com/expectedparrot/edsl). \n",
    "\n",
    "In the steps below we show how to construct and run a simple question in EDSL, and then how to design more complex surveys with AI agent personas and multiple language models.\n",
    "We also demonstrate methods for applying logic and rules to surveys, piping answers into questions, adding data to questions and analyzing survey results as datasets.\n",
    "\n",
    "We also show how to post and share content that you create at **Coop**, a platform for creating, storing and collaborating on AI-based research. Coop is fully integrated with EDSL and free to use. Create an account [here](https://www.expectedparrot.com/login).\n",
    "\n",
    "Please also see our [documentation page](https://docs.expectedparrot.com) for more details on the topics covered in this notebook.\n",
    "If you encounter any issues or have questions, please email us at info@expectedparrot.com or post a question at our [Discord channel](https://discord.com/invite/mxAYkjfy9m)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8fd10f-8925-4c58-8559-2339125d6875",
   "metadata": {},
   "source": [
    "## Technical setup\n",
    "To run the examples below you first need to install the EDSL library and choose how you want to access language models.\n",
    "\n",
    "*Note: If you are using EDSL in Google Colab, please see the [Colab setup](https://docs.expectedparrot.com/en/latest/colab_setup.html) page for additional instructions.*\n",
    "\n",
    "\n",
    "### Install EDSL\n",
    "Uncomment and run the following code to install the EDSL library. \n",
    "See installation [instructions](https://docs.expectedparrot.com/en/latest/installation.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd3c2a9-1ddf-4dc5-840e-64708092c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install edsl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e8637-0e1b-42ef-a43c-e3eceba536c8",
   "metadata": {},
   "source": [
    "If you have already installed EDSL, you can uncomment and run the following code to check that your version is up to date (compare it to the version at [PyPI](https://pypi.org/project/edsl/)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5006fd6-bff1-4206-95bf-14fb686d9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip show edsl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90097b-8314-44b5-95f4-a55f2dbfb8bb",
   "metadata": {},
   "source": [
    "If your version of EDSL is not up to date, uncomment and run the following code to update it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168e3b18-9bf8-4703-b405-6c1143df9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade edsl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f66434e-2777-45ae-9807-e283d9bdb593",
   "metadata": {},
   "source": [
    "### Choose how to access language models\n",
    "Next, decide how you want to access language models with EDSL and obtain the required API keys:\n",
    "\n",
    "* *Remote inference:* This method allows you to run surveys at the Expected Parrot server and access all available language models at once with your Expected Parrot API key. [Learn more](https://docs.expectedparrot.com/en/latest/remote_inference.html).\n",
    "  \n",
    "* *Local inference:* Alternatively, you can obtain your own API keys for service providers to run EDSL on your own machine. \n",
    "\n",
    "Your Expected Parrot API key can be found at the Settings page of your [Coop account](https://www.expectedparrot.com/login), where you can select the option to [activate remote inference](https://docs.expectedparrot.com/en/latest/remote_inference.html).\n",
    "This key also allows you to [post and share content at the Coop](https://www.expectedparrot.com/content/explore) that you create using either remote or local inference. \n",
    "\n",
    "### Store your API keys\n",
    "Make your keys available to EDSL by storing then in a file named \"**.env**\" in your working directory. \n",
    "\n",
    "***Note: Your API keys should be treated like passwords and deleted from notebooks or content that you share with others. We recommend deleting your keys from the code below after your .env file has been created.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40633ca6-c73d-4ad4-aadb-82914e74f7d8",
   "metadata": {},
   "source": [
    "## Example: Running a simple question\n",
    "EDSL comes with a [variety of question types](https://docs.expectedparrot.com/en/latest/questions.html) that we can choose from based on the form of the response that we want to get back from a model.\n",
    "To see a list of all question types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f61057-dc99-4952-bb43-ad8563118d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_5e09c_row0_col0, #T_5e09c_row0_col1, #T_5e09c_row0_col2, #T_5e09c_row1_col0, #T_5e09c_row1_col1, #T_5e09c_row1_col2, #T_5e09c_row2_col0, #T_5e09c_row2_col1, #T_5e09c_row2_col2, #T_5e09c_row3_col0, #T_5e09c_row3_col1, #T_5e09c_row3_col2, #T_5e09c_row4_col0, #T_5e09c_row4_col1, #T_5e09c_row4_col2, #T_5e09c_row5_col0, #T_5e09c_row5_col1, #T_5e09c_row5_col2, #T_5e09c_row6_col0, #T_5e09c_row6_col1, #T_5e09c_row6_col2, #T_5e09c_row7_col0, #T_5e09c_row7_col1, #T_5e09c_row7_col2, #T_5e09c_row8_col0, #T_5e09c_row8_col1, #T_5e09c_row8_col2, #T_5e09c_row9_col0, #T_5e09c_row9_col1, #T_5e09c_row9_col2, #T_5e09c_row10_col0, #T_5e09c_row10_col1, #T_5e09c_row10_col2, #T_5e09c_row11_col0, #T_5e09c_row11_col1, #T_5e09c_row11_col2, #T_5e09c_row12_col0, #T_5e09c_row12_col1, #T_5e09c_row12_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5e09c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5e09c_level0_col0\" class=\"col_heading level0 col0\" >question_type</th>\n",
       "      <th id=\"T_5e09c_level0_col1\" class=\"col_heading level0 col1\" >question_class</th>\n",
       "      <th id=\"T_5e09c_level0_col2\" class=\"col_heading level0 col2\" >example_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5e09c_row0_col0\" class=\"data row0 col0\" >checkbox</td>\n",
       "      <td id=\"T_5e09c_row0_col1\" class=\"data row0 col1\" >QuestionCheckBox</td>\n",
       "      <td id=\"T_5e09c_row0_col2\" class=\"data row0 col2\" >Question('checkbox', question_name = \"\"\"never_eat\"\"\", question_text = \"\"\"Which of the following foods would you eat if you had to?\"\"\", min_selections = 2, max_selections = 5, question_options = ['soggy meatpie', 'rare snails', 'mouldy bread', 'panda milk custard', 'McDonalds'], include_comment = False, use_code = True)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5e09c_row1_col0\" class=\"data row1 col0\" >extract</td>\n",
       "      <td id=\"T_5e09c_row1_col1\" class=\"data row1 col1\" >QuestionExtract</td>\n",
       "      <td id=\"T_5e09c_row1_col2\" class=\"data row1 col2\" >Question('extract', question_name = \"\"\"extract_name\"\"\", question_text = \"\"\"My name is Moby Dick. I have a PhD in astrology, but I'm actually a truck driver\"\"\", answer_template = {'name': 'John Doe', 'profession': 'Carpenter'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5e09c_row2_col0\" class=\"data row2 col0\" >free_text</td>\n",
       "      <td id=\"T_5e09c_row2_col1\" class=\"data row2 col1\" >QuestionFreeText</td>\n",
       "      <td id=\"T_5e09c_row2_col2\" class=\"data row2 col2\" >Question('free_text', question_name = \"\"\"how_are_you\"\"\", question_text = \"\"\"How are you?\"\"\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5e09c_row3_col0\" class=\"data row3 col0\" >functional</td>\n",
       "      <td id=\"T_5e09c_row3_col1\" class=\"data row3 col1\" >QuestionFunctional</td>\n",
       "      <td id=\"T_5e09c_row3_col2\" class=\"data row3 col2\" >Question('functional', question_name = \"\"\"sum_and_multiply\"\"\", question_text = \"\"\"Calculate the sum of the list and multiply it by the agent trait multiplier.\"\"\")</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5e09c_row4_col0\" class=\"data row4 col0\" >likert_five</td>\n",
       "      <td id=\"T_5e09c_row4_col1\" class=\"data row4 col1\" >QuestionLikertFive</td>\n",
       "      <td id=\"T_5e09c_row4_col2\" class=\"data row4 col2\" >Question('likert_five', question_name = \"\"\"happy_raining\"\"\", question_text = \"\"\"I'm only happy when it rains.\"\"\", question_options = ['Strongly disagree', 'Disagree', 'Neutral', 'Agree', 'Strongly agree'])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5e09c_row5_col0\" class=\"data row5 col0\" >linear_scale</td>\n",
       "      <td id=\"T_5e09c_row5_col1\" class=\"data row5 col1\" >QuestionLinearScale</td>\n",
       "      <td id=\"T_5e09c_row5_col2\" class=\"data row5 col2\" >Question('linear_scale', question_name = \"\"\"ice_cream\"\"\", question_text = \"\"\"How much do you like ice cream?\"\"\", question_options = [1, 2, 3, 4, 5], option_labels = {1: 'I hate it', 5: 'I love it'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5e09c_row6_col0\" class=\"data row6 col0\" >list</td>\n",
       "      <td id=\"T_5e09c_row6_col1\" class=\"data row6 col1\" >QuestionList</td>\n",
       "      <td id=\"T_5e09c_row6_col2\" class=\"data row6 col2\" >Question('list', question_name = \"\"\"list_of_foods\"\"\", question_text = \"\"\"What are your favorite foods?\"\"\", max_list_items = None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5e09c_row7_col0\" class=\"data row7 col0\" >matrix</td>\n",
       "      <td id=\"T_5e09c_row7_col1\" class=\"data row7 col1\" >QuestionMatrix</td>\n",
       "      <td id=\"T_5e09c_row7_col2\" class=\"data row7 col2\" >Question('matrix', question_name = \"\"\"child_happiness\"\"\", question_text = \"\"\"How happy would you be with different numbers of children?\"\"\", question_items = ['No children', '1 child', '2 children', '3 or more children'], question_options = [1, 2, 3, 4, 5], option_labels = {1: 'Very sad', 3: 'Neutral', 5: 'Extremely happy'})</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5e09c_row8_col0\" class=\"data row8 col0\" >multiple_choice</td>\n",
       "      <td id=\"T_5e09c_row8_col1\" class=\"data row8 col1\" >QuestionMultipleChoice</td>\n",
       "      <td id=\"T_5e09c_row8_col2\" class=\"data row8 col2\" >Question('multiple_choice', question_name = \"\"\"how_feeling\"\"\", question_text = \"\"\"How are you?\"\"\", question_options = ['Good', 'Great', 'OK', 'Bad'], include_comment = False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5e09c_row9_col0\" class=\"data row9 col0\" >numerical</td>\n",
       "      <td id=\"T_5e09c_row9_col1\" class=\"data row9 col1\" >QuestionNumerical</td>\n",
       "      <td id=\"T_5e09c_row9_col2\" class=\"data row9 col2\" >Question('numerical', question_name = \"\"\"age\"\"\", question_text = \"\"\"You are a 45 year old man. How old are you in years?\"\"\", min_value = 0, max_value = 86.7, include_comment = False)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_5e09c_row10_col0\" class=\"data row10 col0\" >rank</td>\n",
       "      <td id=\"T_5e09c_row10_col1\" class=\"data row10 col1\" >QuestionRank</td>\n",
       "      <td id=\"T_5e09c_row10_col2\" class=\"data row10 col2\" >Question('rank', question_name = \"\"\"rank_foods\"\"\", question_text = \"\"\"Rank your favorite foods.\"\"\", question_options = ['Pizza', 'Pasta', 'Salad', 'Soup'], num_selections = 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_5e09c_row11_col0\" class=\"data row11 col0\" >top_k</td>\n",
       "      <td id=\"T_5e09c_row11_col1\" class=\"data row11 col1\" >QuestionTopK</td>\n",
       "      <td id=\"T_5e09c_row11_col2\" class=\"data row11 col2\" >Question('top_k', question_name = \"\"\"two_fruits\"\"\", question_text = \"\"\"Which of the following fruits do you prefer?\"\"\", min_selections = 2, max_selections = 2, question_options = ['apple', 'banana', 'carrot', 'durian'], use_code = True)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5e09c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_5e09c_row12_col0\" class=\"data row12 col0\" >yes_no</td>\n",
       "      <td id=\"T_5e09c_row12_col1\" class=\"data row12 col1\" >QuestionYesNo</td>\n",
       "      <td id=\"T_5e09c_row12_col2\" class=\"data row12 col2\" >Question('yes_no', question_name = \"\"\"is_it_equal\"\"\", question_text = \"\"\"Is 5 + 5 equal to 11?\"\"\", question_options = ['No', 'Yes'])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "Dataset([{'question_type': ['checkbox', 'extract', 'free_text', 'functional', 'likert_five', 'linear_scale', 'list', 'matrix', 'multiple_choice', 'numerical', 'rank', 'top_k', 'yes_no']}, {'question_class': ['QuestionCheckBox', 'QuestionExtract', 'QuestionFreeText', 'QuestionFunctional', 'QuestionLikertFive', 'QuestionLinearScale', 'QuestionList', 'QuestionMatrix', 'QuestionMultipleChoice', 'QuestionNumerical', 'QuestionRank', 'QuestionTopK', 'QuestionYesNo']}, {'example_question': ['Question(\\'checkbox\\', question_name = \"\"\"never_eat\"\"\", question_text = \"\"\"Which of the following foods would you eat if you had to?\"\"\", min_selections = 2, max_selections = 5, question_options = [\\'soggy meatpie\\', \\'rare snails\\', \\'mouldy bread\\', \\'panda milk custard\\', \\'McDonalds\\'], include_comment = False, use_code = True)', 'Question(\\'extract\\', question_name = \"\"\"extract_name\"\"\", question_text = \"\"\"My name is Moby Dick. I have a PhD in astrology, but I\\'m actually a truck driver\"\"\", answer_template = {\\'name\\': \\'John Doe\\', \\'profession\\': \\'Carpenter\\'})', 'Question(\\'free_text\\', question_name = \"\"\"how_are_you\"\"\", question_text = \"\"\"How are you?\"\"\")', 'Question(\\'functional\\', question_name = \"\"\"sum_and_multiply\"\"\", question_text = \"\"\"Calculate the sum of the list and multiply it by the agent trait multiplier.\"\"\")', 'Question(\\'likert_five\\', question_name = \"\"\"happy_raining\"\"\", question_text = \"\"\"I\\'m only happy when it rains.\"\"\", question_options = [\\'Strongly disagree\\', \\'Disagree\\', \\'Neutral\\', \\'Agree\\', \\'Strongly agree\\'])', 'Question(\\'linear_scale\\', question_name = \"\"\"ice_cream\"\"\", question_text = \"\"\"How much do you like ice cream?\"\"\", question_options = [1, 2, 3, 4, 5], option_labels = {1: \\'I hate it\\', 5: \\'I love it\\'})', 'Question(\\'list\\', question_name = \"\"\"list_of_foods\"\"\", question_text = \"\"\"What are your favorite foods?\"\"\", max_list_items = None)', 'Question(\\'matrix\\', question_name = \"\"\"child_happiness\"\"\", question_text = \"\"\"How happy would you be with different numbers of children?\"\"\", question_items = [\\'No children\\', \\'1 child\\', \\'2 children\\', \\'3 or more children\\'], question_options = [1, 2, 3, 4, 5], option_labels = {1: \\'Very sad\\', 3: \\'Neutral\\', 5: \\'Extremely happy\\'})', 'Question(\\'multiple_choice\\', question_name = \"\"\"how_feeling\"\"\", question_text = \"\"\"How are you?\"\"\", question_options = [\\'Good\\', \\'Great\\', \\'OK\\', \\'Bad\\'], include_comment = False)', 'Question(\\'numerical\\', question_name = \"\"\"age\"\"\", question_text = \"\"\"You are a 45 year old man. How old are you in years?\"\"\", min_value = 0, max_value = 86.7, include_comment = False)', 'Question(\\'rank\\', question_name = \"\"\"rank_foods\"\"\", question_text = \"\"\"Rank your favorite foods.\"\"\", question_options = [\\'Pizza\\', \\'Pasta\\', \\'Salad\\', \\'Soup\\'], num_selections = 2)', 'Question(\\'top_k\\', question_name = \"\"\"two_fruits\"\"\", question_text = \"\"\"Which of the following fruits do you prefer?\"\"\", min_selections = 2, max_selections = 2, question_options = [\\'apple\\', \\'banana\\', \\'carrot\\', \\'durian\\'], use_code = True)', 'Question(\\'yes_no\\', question_name = \"\"\"is_it_equal\"\"\", question_text = \"\"\"Is 5 + 5 equal to 11?\"\"\", question_options = [\\'No\\', \\'Yes\\'])']}])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Question\n",
    "\n",
    "Question.available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185af5d1-beba-40cd-8c29-2a212fcc4e5a",
   "metadata": {},
   "source": [
    "We can see the components of a particular question type by importing the question type class and calling the `example` method on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "572f6614-de5b-44a1-a5fc-81eba360282f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><a href=''>QuestionMultipleChoice</a></p>\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_6cd71_row0_col0, #T_6cd71_row0_col1, #T_6cd71_row1_col0, #T_6cd71_row1_col1, #T_6cd71_row2_col0, #T_6cd71_row2_col1, #T_6cd71_row3_col0, #T_6cd71_row3_col1, #T_6cd71_row4_col0, #T_6cd71_row4_col1, #T_6cd71_row5_col0, #T_6cd71_row5_col1, #T_6cd71_row6_col0, #T_6cd71_row6_col1, #T_6cd71_row7_col0, #T_6cd71_row7_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6cd71\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6cd71_level0_col0\" class=\"col_heading level0 col0\" >key</th>\n",
       "      <th id=\"T_6cd71_level0_col1\" class=\"col_heading level0 col1\" >value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd71_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6cd71_row0_col0\" class=\"data row0 col0\" >question_name</td>\n",
       "      <td id=\"T_6cd71_row0_col1\" class=\"data row0 col1\" >how_feeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd71_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6cd71_row1_col0\" class=\"data row1 col0\" >question_text</td>\n",
       "      <td id=\"T_6cd71_row1_col1\" class=\"data row1 col1\" >How are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd71_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6cd71_row2_col0\" class=\"data row2 col0\" >question_options:0</td>\n",
       "      <td id=\"T_6cd71_row2_col1\" class=\"data row2 col1\" >Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd71_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6cd71_row3_col0\" class=\"data row3 col0\" >question_options:1</td>\n",
       "      <td id=\"T_6cd71_row3_col1\" class=\"data row3 col1\" >Great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd71_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6cd71_row4_col0\" class=\"data row4 col0\" >question_options:2</td>\n",
       "      <td id=\"T_6cd71_row4_col1\" class=\"data row4 col1\" >OK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd71_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6cd71_row5_col0\" class=\"data row5 col0\" >question_options:3</td>\n",
       "      <td id=\"T_6cd71_row5_col1\" class=\"data row5 col1\" >Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd71_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6cd71_row6_col0\" class=\"data row6 col0\" >include_comment</td>\n",
       "      <td id=\"T_6cd71_row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cd71_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6cd71_row7_col0\" class=\"data row7 col0\" >question_type</td>\n",
       "      <td id=\"T_6cd71_row7_col1\" class=\"data row7 col1\" >multiple_choice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "Question('multiple_choice', question_name = \"\"\"how_feeling\"\"\", question_text = \"\"\"How are you?\"\"\", question_options = ['Good', 'Great', 'OK', 'Bad'], include_comment = False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import (\n",
    "    # QuestionCheckBox,\n",
    "    # QuestionExtract,\n",
    "    # QuestionFreeText,\n",
    "    # QuestionFunctional,\n",
    "    # QuestionLikertFive,\n",
    "    # QuestionLinearScale,\n",
    "    # QuestionList,\n",
    "    QuestionMultipleChoice,\n",
    "    # QuestionNumerical,\n",
    "    # QuestionRank,\n",
    "    # QuestionTopK,\n",
    "    # QuestionYesNo\n",
    ")\n",
    "\n",
    "q = QuestionMultipleChoice.example() # substitute any question type class name\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34704ae3-b643-4a6e-a721-b6208c19adda",
   "metadata": {},
   "source": [
    "Here we create a simple multiple choice question of our own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa14cb3-d81f-47dc-96c8-90fba2a1460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import QuestionMultipleChoice\n",
    "\n",
    "q = QuestionMultipleChoice(\n",
    "    question_name = \"smallest_prime\",\n",
    "    question_text = \"Which is the smallest prime number?\",\n",
    "    question_options = [0, 1, 2, 3]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235fc4a0-0cd4-4930-92b9-e39734a70a2c",
   "metadata": {},
   "source": [
    "We can administer the question to a language model by calling the `run` method on it. \n",
    "If you have activated remote inference and stored your Expected Parrot API key (see instructions above), the question will be run remotely at the Expected Parrot server.\n",
    "Results are stored at an unlisted Coop page by default; we can also set the visibility to `public` or `private` either when we run it or by updating the object (demonstrated in later examples).\n",
    "We can also view a progress report for the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b314a755-4209-4223-9b99-041ef2774871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnhorton/tools/edsl/edsl/coop/ExpectedParrotKeyHandler.py:92: UserWarning: WARNING: The Expected Parrot API key from the environment variable differs from the one stored in the config directory. Using the one from the environment variable.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <!-- #region Remove Inference Info -->\n",
       "            <div id=\"logger-595f740e-494a-4bb4-b7f1-56b476e4beae\" class=\"job-logger\">\n",
       "                <div class=\"job-logger-header\">\n",
       "                    <span>\n",
       "                        <span id=\"arrow-595f740e-494a-4bb4-b7f1-56b476e4beae\">▼</span> \n",
       "                        Job Status (2024-12-31 11:24:46)\n",
       "                    </span>\n",
       "                </div>\n",
       "                <div id=\"content-595f740e-494a-4bb4-b7f1-56b476e4beae\" style=\"display: block;\">\n",
       "                    <table class=\"job-logger-table\">\n",
       "                        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Job UUID</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\">2df5e752-2ec5-46d8-9504-7889c2aab69c</td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Progress Bar URL</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\"><a href=\"https://www.expectedparrot.com/home/remote-job-progress/2df5e752-2ec5-46d8-9504-7889c2aab69c\" target=\"_blank\" class=\"job-logger-link\">https://www.expectedparrot.com/home/remote-job-progress/2df5e752-2ec5-46d8-9504-7889c2aab69c</a></td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Error Report URL</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\">None</td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Results UUID</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\">c7714eca-a7cd-4478-945f-e4feb94ed2fa</td>\n",
       "            </tr>\n",
       "        \n",
       "            <tr>\n",
       "                <td class=\"job-logger-cell job-logger-label\">Results URL</td>\n",
       "                <td class=\"job-logger-cell job-logger-value\">None</td>\n",
       "            </tr>\n",
       "        \n",
       "                    </table>\n",
       "                    \n",
       "                <div class=\"job-logger-status\">\n",
       "                    <span style=\"margin-right: 8px;\" class=\"job-logger-success\">✓</span><strong>Current Status:</strong> Job completed and Results stored on Coop: <a href=\"https://www.expectedparrot.com/content/c7714eca-a7cd-4478-945f-e4feb94ed2fa\" target=\"_blank\" class=\"job-logger-link\">https://www.expectedparrot.com/content/c7714eca-a7cd-4478-945f-e4feb94ed2fa</a>\n",
       "                </div>\n",
       "            \n",
       "                </div>\n",
       "            </div>\n",
       "            <!-- # endregion -->\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            /* Base theme variables */\n",
       "            :root {\n",
       "                --jl-bg-primary: #ffffff;\n",
       "                --jl-bg-secondary: #f5f5f5;\n",
       "                --jl-border-color: #e0e0e0;\n",
       "                --jl-text-primary: #24292e;\n",
       "                --jl-text-secondary: #586069;\n",
       "                --jl-link-color: #0366d6;\n",
       "                --jl-success-color: #28a745;\n",
       "                --jl-error-color: #d73a49;\n",
       "                --jl-header-bg: #f1f1f1;\n",
       "            }\n",
       "            \n",
       "            /* Dark theme variables */\n",
       "            .theme-dark {\n",
       "                --jl-bg-primary: #1e1e1e;\n",
       "                --jl-bg-secondary: #252526;\n",
       "                --jl-border-color: #2d2d2d;\n",
       "                --jl-text-primary: #cccccc;\n",
       "                --jl-text-secondary: #999999;\n",
       "                --jl-link-color: #4e94ce;\n",
       "                --jl-success-color: #89d185;\n",
       "                --jl-error-color: #f14c4c;\n",
       "                --jl-header-bg: #333333;\n",
       "            }\n",
       "\n",
       "            /* High contrast theme variables */\n",
       "            .theme-high-contrast {\n",
       "                --jl-bg-primary: #000000;\n",
       "                --jl-bg-secondary: #1a1a1a;\n",
       "                --jl-border-color: #404040;\n",
       "                --jl-text-primary: #ffffff;\n",
       "                --jl-text-secondary: #cccccc;\n",
       "                --jl-link-color: #66b3ff;\n",
       "                --jl-success-color: #00ff00;\n",
       "                --jl-error-color: #ff0000;\n",
       "                --jl-header-bg: #262626;\n",
       "            }\n",
       "            \n",
       "            .job-logger {\n",
       "                font-family: system-ui, -apple-system, sans-serif;\n",
       "                max-width: 800px;\n",
       "                margin: 10px 0;\n",
       "                color: var(--jl-text-primary);\n",
       "                box-shadow: 0 1px 3px rgba(0,0,0,0.12);\n",
       "                border-radius: 4px;\n",
       "                overflow: hidden;\n",
       "            }\n",
       "            \n",
       "            .job-logger-header {\n",
       "                padding: 12px 16px;\n",
       "                background: var(--jl-header-bg);\n",
       "                border: none;\n",
       "                border-radius: 4px 4px 0 0;\n",
       "                cursor: pointer;\n",
       "                color: var(--jl-text-primary);\n",
       "                user-select: none;\n",
       "                font-weight: 500;\n",
       "                letter-spacing: 0.3px;\n",
       "                display: flex;\n",
       "                justify-content: space-between;\n",
       "                align-items: center;\n",
       "            }\n",
       "            \n",
       "            .theme-select {\n",
       "                padding: 4px 8px;\n",
       "                border-radius: 4px;\n",
       "                border: 1px solid var(--jl-border-color);\n",
       "                background: var(--jl-bg-primary);\n",
       "                color: var(--jl-text-primary);\n",
       "                font-size: 0.9em;\n",
       "            }\n",
       "            \n",
       "            .job-logger-table {\n",
       "                width: 100%;\n",
       "                border-collapse: separate;\n",
       "                border-spacing: 0;\n",
       "                background: var(--jl-bg-primary);\n",
       "                border: 1px solid var(--jl-border-color);\n",
       "                margin-top: -1px;\n",
       "            }\n",
       "            \n",
       "            .job-logger-cell {\n",
       "                padding: 12px 16px;\n",
       "                border-bottom: 1px solid var(--jl-border-color);\n",
       "                line-height: 1.4;\n",
       "            }\n",
       "            \n",
       "            .job-logger-label {\n",
       "                font-weight: 500;\n",
       "                color: var(--jl-text-primary);\n",
       "                width: 25%;\n",
       "                background: var(--jl-bg-secondary);\n",
       "            }\n",
       "            \n",
       "            .job-logger-value {\n",
       "                color: var(--jl-text-secondary);\n",
       "                word-break: break-word;\n",
       "            }\n",
       "            \n",
       "            .job-logger-status {\n",
       "                margin: 0;\n",
       "                padding: 12px 16px;\n",
       "                background-color: var(--jl-bg-secondary);\n",
       "                border: 1px solid var(--jl-border-color);\n",
       "                border-top: none;\n",
       "                border-radius: 0 0 4px 4px;\n",
       "                color: var(--jl-text-primary);\n",
       "                font-size: 0.95em;\n",
       "            }\n",
       "        </style>\n",
       "        \n",
       "        <script>\n",
       "            class ThemeManager {\n",
       "                constructor(logId, initialTheme = 'auto') {\n",
       "                    this.logId = logId;\n",
       "                    this.currentTheme = initialTheme;\n",
       "                    this.darkModeMediaQuery = window.matchMedia('(prefers-color-scheme: dark)');\n",
       "                    this.init();\n",
       "                }\n",
       "                \n",
       "                init() {\n",
       "                    this.setupThemeSwitcher();\n",
       "                    this.updateTheme(this.currentTheme);\n",
       "                    \n",
       "                    this.darkModeMediaQuery.addListener(() => {\n",
       "                        if (this.currentTheme === 'auto') {\n",
       "                            this.updateTheme('auto');\n",
       "                        }\n",
       "                    });\n",
       "                }\n",
       "                \n",
       "                setupThemeSwitcher() {\n",
       "                    const logger = document.querySelector(`#logger-${this.logId}`);\n",
       "                    if (!logger) return;\n",
       "                    \n",
       "                    const switcher = document.createElement('div');\n",
       "                    switcher.className = 'theme-switcher';\n",
       "                    switcher.innerHTML = `\n",
       "                        <select id=\"theme-select-${this.logId}\" class=\"theme-select\">\n",
       "                            <option value=\"auto\">Auto</option>\n",
       "                            <option value=\"light\">Light</option>\n",
       "                            <option value=\"dark\">Dark</option>\n",
       "                            <option value=\"high-contrast\">High Contrast</option>\n",
       "                        </select>\n",
       "                    `;\n",
       "                    \n",
       "                    const header = logger.querySelector('.job-logger-header');\n",
       "                    header.appendChild(switcher);\n",
       "                    \n",
       "                    const select = switcher.querySelector('select');\n",
       "                    select.value = this.currentTheme;\n",
       "                    select.addEventListener('change', (e) => {\n",
       "                        this.updateTheme(e.target.value);\n",
       "                    });\n",
       "                }\n",
       "                \n",
       "                updateTheme(theme) {\n",
       "                    const logger = document.querySelector(`#logger-${this.logId}`);\n",
       "                    if (!logger) return;\n",
       "                    \n",
       "                    this.currentTheme = theme;\n",
       "                    \n",
       "                    logger.classList.remove('theme-light', 'theme-dark', 'theme-high-contrast');\n",
       "                    \n",
       "                    if (theme === 'auto') {\n",
       "                        const isDark = this.darkModeMediaQuery.matches;\n",
       "                        logger.classList.add(isDark ? 'theme-dark' : 'theme-light');\n",
       "                    } else {\n",
       "                        logger.classList.add(`theme-${theme}`);\n",
       "                    }\n",
       "                    \n",
       "                    try {\n",
       "                        localStorage.setItem('jobLoggerTheme', theme);\n",
       "                    } catch (e) {\n",
       "                        console.warn('Unable to save theme preference:', e);\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            \n",
       "            window.initThemeManager = (logId, initialTheme) => {\n",
       "                new ThemeManager(logId, initialTheme);\n",
       "            };\n",
       "        </script>\n",
       "        \n",
       "        <script>\n",
       "            document.addEventListener('DOMContentLoaded', () => {\n",
       "                window.initThemeManager('595f740e-494a-4bb4-b7f1-56b476e4beae', 'auto');\n",
       "            });\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating local cache with 21 new entries from remote...\n",
      "Local cache updated!\n",
      "No new entries to add to remote cache.\n",
      "There are 10,145 entries in the local cache.\n"
     ]
    }
   ],
   "source": [
    "results = q.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e78cb-54f2-4227-b69c-c916b3222b8d",
   "metadata": {},
   "source": [
    "### Inspecting results\n",
    "This generates a dataset of `Results` that we can readily access with [built-in methods for analysis](https://docs.expectedparrot.com/en/latest/results.html). \n",
    "Here we `select()` the response to inspect it, together with the model that was used and the model's \"comment\" about its response--a field that is automatically added to all question types other than free text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cce12c20-180a-46ed-bc54-4305999eeeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_9bc25_row0_col0, #T_9bc25_row0_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9bc25_row0_col1 {\n",
       "  text-align: left;\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9bc25\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9bc25_level0_col0\" class=\"col_heading level0 col0\" >model.model</th>\n",
       "      <th id=\"T_9bc25_level0_col1\" class=\"col_heading level0 col1\" >answer.smallest_prime</th>\n",
       "      <th id=\"T_9bc25_level0_col2\" class=\"col_heading level0 col2\" >comment.smallest_prime_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9bc25_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9bc25_row0_col0\" class=\"data row0 col0\" >gpt-4o</td>\n",
       "      <td id=\"T_9bc25_row0_col1\" class=\"data row0 col1\" >2</td>\n",
       "      <td id=\"T_9bc25_row0_col2\" class=\"data row0 col2\" >2 is the smallest prime number because it is greater than 1 and has no divisors other than 1 and itself.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "Dataset([{'model.model': ['gpt-4o']}, {'answer.smallest_prime': [2]}, {'comment.smallest_prime_comment': ['2 is the smallest prime number because it is greater than 1 and has no divisors other than 1 and itself.']}])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.select(\"model\", \"smallest_prime\", \"smallest_prime_comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb61d06-ad9f-42c5-856b-2a6000989eb4",
   "metadata": {},
   "source": [
    "The `Results` also include information about the question, model parameters, prompts, generated tokens and raw responses. \n",
    "To see a list of all the components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34340f65-9453-46a2-a0de-92e7c2d52a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_0e9d0_row0_col0, #T_0e9d0_row1_col0, #T_0e9d0_row2_col0, #T_0e9d0_row3_col0, #T_0e9d0_row4_col0, #T_0e9d0_row5_col0, #T_0e9d0_row6_col0, #T_0e9d0_row7_col0, #T_0e9d0_row8_col0, #T_0e9d0_row9_col0, #T_0e9d0_row10_col0, #T_0e9d0_row11_col0, #T_0e9d0_row12_col0, #T_0e9d0_row13_col0, #T_0e9d0_row14_col0, #T_0e9d0_row15_col0, #T_0e9d0_row16_col0, #T_0e9d0_row17_col0, #T_0e9d0_row18_col0, #T_0e9d0_row19_col0, #T_0e9d0_row20_col0, #T_0e9d0_row21_col0, #T_0e9d0_row22_col0, #T_0e9d0_row23_col0, #T_0e9d0_row24_col0, #T_0e9d0_row25_col0 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e9d0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0e9d0_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0e9d0_row0_col0\" class=\"data row0 col0\" >agent.agent_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0e9d0_row1_col0\" class=\"data row1 col0\" >agent.agent_instruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0e9d0_row2_col0\" class=\"data row2 col0\" >agent.agent_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0e9d0_row3_col0\" class=\"data row3 col0\" >answer.smallest_prime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0e9d0_row4_col0\" class=\"data row4 col0\" >cache_used.smallest_prime_cache_used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_0e9d0_row5_col0\" class=\"data row5 col0\" >comment.smallest_prime_comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_0e9d0_row6_col0\" class=\"data row6 col0\" >generated_tokens.smallest_prime_generated_tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_0e9d0_row7_col0\" class=\"data row7 col0\" >iteration.iteration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_0e9d0_row8_col0\" class=\"data row8 col0\" >model.frequency_penalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_0e9d0_row9_col0\" class=\"data row9 col0\" >model.logprobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_0e9d0_row10_col0\" class=\"data row10 col0\" >model.max_tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_0e9d0_row11_col0\" class=\"data row11 col0\" >model.model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_0e9d0_row12_col0\" class=\"data row12 col0\" >model.model_index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_0e9d0_row13_col0\" class=\"data row13 col0\" >model.presence_penalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_0e9d0_row14_col0\" class=\"data row14 col0\" >model.temperature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_0e9d0_row15_col0\" class=\"data row15 col0\" >model.top_logprobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_0e9d0_row16_col0\" class=\"data row16 col0\" >model.top_p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_0e9d0_row17_col0\" class=\"data row17 col0\" >prompt.smallest_prime_system_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_0e9d0_row18_col0\" class=\"data row18 col0\" >prompt.smallest_prime_user_prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_0e9d0_row19_col0\" class=\"data row19 col0\" >question_options.smallest_prime_question_options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_0e9d0_row20_col0\" class=\"data row20 col0\" >question_text.smallest_prime_question_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_0e9d0_row21_col0\" class=\"data row21 col0\" >question_type.smallest_prime_question_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_0e9d0_row22_col0\" class=\"data row22 col0\" >raw_model_response.smallest_prime_cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_0e9d0_row23_col0\" class=\"data row23 col0\" >raw_model_response.smallest_prime_one_usd_buys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_0e9d0_row24_col0\" class=\"data row24 col0\" >raw_model_response.smallest_prime_raw_model_response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e9d0_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_0e9d0_row25_col0\" class=\"data row25 col0\" >scenario.scenario_index</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "PrettyList(['agent.agent_index',\n",
       "            'agent.agent_instruction',\n",
       "            'agent.agent_name',\n",
       "            'answer.smallest_prime',\n",
       "            'cache_used.smallest_prime_cache_used',\n",
       "            'comment.smallest_prime_comment',\n",
       "            'generated_tokens.smallest_prime_generated_tokens',\n",
       "            'iteration.iteration',\n",
       "            'model.frequency_penalty',\n",
       "            'model.logprobs',\n",
       "            'model.max_tokens',\n",
       "            'model.model',\n",
       "            'model.model_index',\n",
       "            'model.presence_penalty',\n",
       "            'model.temperature',\n",
       "            'model.top_logprobs',\n",
       "            'model.top_p',\n",
       "            'prompt.smallest_prime_system_prompt',\n",
       "            'prompt.smallest_prime_user_prompt',\n",
       "            'question_options.smallest_prime_question_options',\n",
       "            'question_text.smallest_prime_question_text',\n",
       "            'question_type.smallest_prime_question_type',\n",
       "            'raw_model_response.smallest_prime_cost',\n",
       "            'raw_model_response.smallest_prime_one_usd_buys',\n",
       "            'raw_model_response.smallest_prime_raw_model_response',\n",
       "            'scenario.scenario_index'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe1860-7f6d-4b5e-932c-4f02a096d54f",
   "metadata": {},
   "source": [
    "## Example: Conducting a survey with agents and models\n",
    "In the next example we construct a more complex survey consisting of multiple questions, and design personas for AI agents to answer the survey.\n",
    "Then we select specific language models to generate the answers.\n",
    "\n",
    "We start by creating questions in different types and passing them to a `Survey`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3d7bec4-7f00-4007-af7b-86cd93b89e5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from edsl import QuestionLinearScale, QuestionFreeText\n",
    "\n",
    "q_enjoy = QuestionLinearScale(\n",
    "    question_name = \"enjoy\",\n",
    "    question_text = \"On a scale from 1 to 5, how much do you enjoy reading?\",\n",
    "    question_options = [1, 2, 3, 4, 5],\n",
    "    option_labels = {1:\"Not at all\", 5:\"Very much\"}\n",
    ")\n",
    "\n",
    "q_favorite_place = QuestionFreeText(\n",
    "    question_name = \"favorite_place\",\n",
    "    question_text = \"Describe your favorite place for reading.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ff6781-b491-4439-b84a-30bf50cdd47d",
   "metadata": {},
   "source": [
    "We construct a `Survey` by passing a list of questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f1d6f80-1fab-4754-b4a6-f9599accfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import Survey\n",
    "\n",
    "survey = Survey(questions = [q_enjoy, q_favorite_place])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01320feb-86ad-43ad-a6a0-b2b94482dff5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Agents\n",
    "An important feature of EDSL is the ability to create AI agents to answer questions.\n",
    "This is done by passing dictionaries of relevant \"traits\" to `Agent` objects that are used by language models to generate responses.\n",
    "Learn more about [designing agents](https://docs.expectedparrot.com/en/latest/agents.html).\n",
    "\n",
    "Here we construct several simple agent personas to use with our survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8125cd8-f320-4dcd-8dd2-4a1a3fd5fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import AgentList, Agent\n",
    "\n",
    "agents = AgentList(\n",
    "    Agent(traits = {\"persona\":p}) for p in [\"artist\", \"mechanic\", \"sailor\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c2db76-390e-4ac2-aef8-443ca07ababb",
   "metadata": {},
   "source": [
    "### Language models\n",
    "EDSL works with many popular large language models that we can select to use with a survey.\n",
    "This makes it easy to compare responses among models in the results that are generated.\n",
    "\n",
    "To see a current list of available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a55a4dd2-a7b7-4156-9c51-140ed7de15db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnhorton/tools/edsl/edsl/inference_services/AvailableModelFetcher.py:139: UserWarning: No models found for service ollama\n",
      "  warnings.warn(f\"No models found for service {service_name}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_4c0be_row0_col0, #T_4c0be_row0_col1, #T_4c0be_row1_col0, #T_4c0be_row1_col1, #T_4c0be_row2_col0, #T_4c0be_row2_col1, #T_4c0be_row3_col0, #T_4c0be_row3_col1, #T_4c0be_row4_col0, #T_4c0be_row4_col1, #T_4c0be_row5_col0, #T_4c0be_row5_col1, #T_4c0be_row6_col0, #T_4c0be_row6_col1, #T_4c0be_row7_col0, #T_4c0be_row7_col1, #T_4c0be_row8_col0, #T_4c0be_row8_col1, #T_4c0be_row9_col0, #T_4c0be_row9_col1, #T_4c0be_row10_col0, #T_4c0be_row10_col1, #T_4c0be_row11_col0, #T_4c0be_row11_col1, #T_4c0be_row12_col0, #T_4c0be_row12_col1, #T_4c0be_row13_col0, #T_4c0be_row13_col1, #T_4c0be_row14_col0, #T_4c0be_row14_col1, #T_4c0be_row15_col0, #T_4c0be_row15_col1, #T_4c0be_row16_col0, #T_4c0be_row16_col1, #T_4c0be_row17_col0, #T_4c0be_row17_col1, #T_4c0be_row18_col0, #T_4c0be_row18_col1, #T_4c0be_row19_col0, #T_4c0be_row19_col1, #T_4c0be_row20_col0, #T_4c0be_row20_col1, #T_4c0be_row21_col0, #T_4c0be_row21_col1, #T_4c0be_row22_col0, #T_4c0be_row22_col1, #T_4c0be_row23_col0, #T_4c0be_row23_col1, #T_4c0be_row24_col0, #T_4c0be_row24_col1, #T_4c0be_row25_col0, #T_4c0be_row25_col1, #T_4c0be_row26_col0, #T_4c0be_row26_col1, #T_4c0be_row27_col0, #T_4c0be_row27_col1, #T_4c0be_row28_col0, #T_4c0be_row28_col1, #T_4c0be_row29_col0, #T_4c0be_row29_col1, #T_4c0be_row30_col0, #T_4c0be_row30_col1, #T_4c0be_row31_col0, #T_4c0be_row31_col1, #T_4c0be_row32_col0, #T_4c0be_row32_col1, #T_4c0be_row33_col0, #T_4c0be_row33_col1, #T_4c0be_row34_col0, #T_4c0be_row34_col1, #T_4c0be_row35_col0, #T_4c0be_row35_col1, #T_4c0be_row36_col0, #T_4c0be_row36_col1, #T_4c0be_row37_col0, #T_4c0be_row37_col1, #T_4c0be_row38_col0, #T_4c0be_row38_col1, #T_4c0be_row39_col0, #T_4c0be_row39_col1, #T_4c0be_row40_col0, #T_4c0be_row40_col1, #T_4c0be_row41_col0, #T_4c0be_row41_col1, #T_4c0be_row42_col0, #T_4c0be_row42_col1, #T_4c0be_row43_col0, #T_4c0be_row43_col1, #T_4c0be_row44_col0, #T_4c0be_row44_col1, #T_4c0be_row45_col0, #T_4c0be_row45_col1, #T_4c0be_row46_col0, #T_4c0be_row46_col1, #T_4c0be_row47_col0, #T_4c0be_row47_col1, #T_4c0be_row48_col0, #T_4c0be_row48_col1, #T_4c0be_row49_col0, #T_4c0be_row49_col1, #T_4c0be_row50_col0, #T_4c0be_row50_col1, #T_4c0be_row51_col0, #T_4c0be_row51_col1, #T_4c0be_row52_col0, #T_4c0be_row52_col1, #T_4c0be_row53_col0, #T_4c0be_row53_col1, #T_4c0be_row54_col0, #T_4c0be_row54_col1, #T_4c0be_row55_col0, #T_4c0be_row55_col1, #T_4c0be_row56_col0, #T_4c0be_row56_col1, #T_4c0be_row57_col0, #T_4c0be_row57_col1, #T_4c0be_row58_col0, #T_4c0be_row58_col1, #T_4c0be_row59_col0, #T_4c0be_row59_col1, #T_4c0be_row60_col0, #T_4c0be_row60_col1, #T_4c0be_row61_col0, #T_4c0be_row61_col1, #T_4c0be_row62_col0, #T_4c0be_row62_col1, #T_4c0be_row63_col0, #T_4c0be_row63_col1, #T_4c0be_row64_col0, #T_4c0be_row64_col1, #T_4c0be_row65_col0, #T_4c0be_row65_col1, #T_4c0be_row66_col0, #T_4c0be_row66_col1, #T_4c0be_row67_col0, #T_4c0be_row67_col1, #T_4c0be_row68_col0, #T_4c0be_row68_col1, #T_4c0be_row69_col0, #T_4c0be_row69_col1, #T_4c0be_row70_col0, #T_4c0be_row70_col1, #T_4c0be_row71_col0, #T_4c0be_row71_col1, #T_4c0be_row72_col0, #T_4c0be_row72_col1, #T_4c0be_row73_col0, #T_4c0be_row73_col1, #T_4c0be_row74_col0, #T_4c0be_row74_col1, #T_4c0be_row75_col0, #T_4c0be_row75_col1, #T_4c0be_row76_col0, #T_4c0be_row76_col1, #T_4c0be_row77_col0, #T_4c0be_row77_col1, #T_4c0be_row78_col0, #T_4c0be_row78_col1, #T_4c0be_row79_col0, #T_4c0be_row79_col1, #T_4c0be_row80_col0, #T_4c0be_row80_col1, #T_4c0be_row81_col0, #T_4c0be_row81_col1, #T_4c0be_row82_col0, #T_4c0be_row82_col1, #T_4c0be_row83_col0, #T_4c0be_row83_col1, #T_4c0be_row84_col0, #T_4c0be_row84_col1, #T_4c0be_row85_col0, #T_4c0be_row85_col1, #T_4c0be_row86_col0, #T_4c0be_row86_col1, #T_4c0be_row87_col0, #T_4c0be_row87_col1, #T_4c0be_row88_col0, #T_4c0be_row88_col1, #T_4c0be_row89_col0, #T_4c0be_row89_col1, #T_4c0be_row90_col0, #T_4c0be_row90_col1, #T_4c0be_row91_col0, #T_4c0be_row91_col1, #T_4c0be_row92_col0, #T_4c0be_row92_col1, #T_4c0be_row93_col0, #T_4c0be_row93_col1, #T_4c0be_row94_col0, #T_4c0be_row94_col1, #T_4c0be_row95_col0, #T_4c0be_row95_col1, #T_4c0be_row96_col0, #T_4c0be_row96_col1, #T_4c0be_row97_col0, #T_4c0be_row97_col1, #T_4c0be_row98_col0, #T_4c0be_row98_col1, #T_4c0be_row99_col0, #T_4c0be_row99_col1, #T_4c0be_row100_col0, #T_4c0be_row100_col1, #T_4c0be_row101_col0, #T_4c0be_row101_col1, #T_4c0be_row102_col0, #T_4c0be_row102_col1, #T_4c0be_row103_col0, #T_4c0be_row103_col1, #T_4c0be_row104_col0, #T_4c0be_row104_col1, #T_4c0be_row105_col0, #T_4c0be_row105_col1, #T_4c0be_row106_col0, #T_4c0be_row106_col1, #T_4c0be_row107_col0, #T_4c0be_row107_col1, #T_4c0be_row108_col0, #T_4c0be_row108_col1, #T_4c0be_row109_col0, #T_4c0be_row109_col1, #T_4c0be_row110_col0, #T_4c0be_row110_col1, #T_4c0be_row111_col0, #T_4c0be_row111_col1, #T_4c0be_row112_col0, #T_4c0be_row112_col1, #T_4c0be_row113_col0, #T_4c0be_row113_col1, #T_4c0be_row114_col0, #T_4c0be_row114_col1, #T_4c0be_row115_col0, #T_4c0be_row115_col1, #T_4c0be_row116_col0, #T_4c0be_row116_col1, #T_4c0be_row117_col0, #T_4c0be_row117_col1, #T_4c0be_row118_col0, #T_4c0be_row118_col1, #T_4c0be_row119_col0, #T_4c0be_row119_col1, #T_4c0be_row120_col0, #T_4c0be_row120_col1, #T_4c0be_row121_col0, #T_4c0be_row121_col1, #T_4c0be_row122_col0, #T_4c0be_row122_col1, #T_4c0be_row123_col0, #T_4c0be_row123_col1, #T_4c0be_row124_col0, #T_4c0be_row124_col1, #T_4c0be_row125_col0, #T_4c0be_row125_col1, #T_4c0be_row126_col0, #T_4c0be_row126_col1, #T_4c0be_row127_col0, #T_4c0be_row127_col1, #T_4c0be_row128_col0, #T_4c0be_row128_col1, #T_4c0be_row129_col0, #T_4c0be_row129_col1, #T_4c0be_row130_col0, #T_4c0be_row130_col1, #T_4c0be_row131_col0, #T_4c0be_row131_col1, #T_4c0be_row132_col0, #T_4c0be_row132_col1, #T_4c0be_row133_col0, #T_4c0be_row133_col1, #T_4c0be_row134_col0, #T_4c0be_row134_col1, #T_4c0be_row135_col0, #T_4c0be_row135_col1, #T_4c0be_row136_col0, #T_4c0be_row136_col1, #T_4c0be_row137_col0, #T_4c0be_row137_col1, #T_4c0be_row138_col0, #T_4c0be_row138_col1, #T_4c0be_row139_col0, #T_4c0be_row139_col1, #T_4c0be_row140_col0, #T_4c0be_row140_col1, #T_4c0be_row141_col0, #T_4c0be_row141_col1, #T_4c0be_row142_col0, #T_4c0be_row142_col1, #T_4c0be_row143_col0, #T_4c0be_row143_col1, #T_4c0be_row144_col0, #T_4c0be_row144_col1, #T_4c0be_row145_col0, #T_4c0be_row145_col1, #T_4c0be_row146_col0, #T_4c0be_row146_col1, #T_4c0be_row147_col0, #T_4c0be_row147_col1, #T_4c0be_row148_col0, #T_4c0be_row148_col1, #T_4c0be_row149_col0, #T_4c0be_row149_col1, #T_4c0be_row150_col0, #T_4c0be_row150_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4c0be\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4c0be_level0_col0\" class=\"col_heading level0 col0\" >Model Name</th>\n",
       "      <th id=\"T_4c0be_level0_col1\" class=\"col_heading level0 col1\" >Service Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4c0be_row0_col0\" class=\"data row0 col0\" >Austism/chronos-hermes-13b-v2</td>\n",
       "      <td id=\"T_4c0be_row0_col1\" class=\"data row0 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4c0be_row1_col0\" class=\"data row1 col0\" >Gryphe/MythoMax-L2-13b</td>\n",
       "      <td id=\"T_4c0be_row1_col1\" class=\"data row1 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4c0be_row2_col0\" class=\"data row2 col0\" >Qwen/Qwen2-72B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row2_col1\" class=\"data row2 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4c0be_row3_col0\" class=\"data row3 col0\" >Qwen/Qwen2-7B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row3_col1\" class=\"data row3 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4c0be_row4_col0\" class=\"data row4 col0\" >Qwen/Qwen2.5-72B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row4_col1\" class=\"data row4 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4c0be_row5_col0\" class=\"data row5 col0\" >Sao10K/L3-70B-Euryale-v2.1</td>\n",
       "      <td id=\"T_4c0be_row5_col1\" class=\"data row5 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4c0be_row6_col0\" class=\"data row6 col0\" >Sao10K/L3.1-70B-Euryale-v2.2</td>\n",
       "      <td id=\"T_4c0be_row6_col1\" class=\"data row6 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4c0be_row7_col0\" class=\"data row7 col0\" >google/gemma-2-27b-it</td>\n",
       "      <td id=\"T_4c0be_row7_col1\" class=\"data row7 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4c0be_row8_col0\" class=\"data row8 col0\" >google/gemma-2-9b-it</td>\n",
       "      <td id=\"T_4c0be_row8_col1\" class=\"data row8 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4c0be_row9_col0\" class=\"data row9 col0\" >lizpreciatior/lzlv_70b_fp16_hf</td>\n",
       "      <td id=\"T_4c0be_row9_col1\" class=\"data row9 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_4c0be_row10_col0\" class=\"data row10 col0\" >meta-llama/Meta-Llama-3-70B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row10_col1\" class=\"data row10 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_4c0be_row11_col0\" class=\"data row11 col0\" >meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row11_col1\" class=\"data row11 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_4c0be_row12_col0\" class=\"data row12 col0\" >meta-llama/Meta-Llama-3.1-405B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row12_col1\" class=\"data row12 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_4c0be_row13_col0\" class=\"data row13 col0\" >meta-llama/Meta-Llama-3.1-70B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row13_col1\" class=\"data row13 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_4c0be_row14_col0\" class=\"data row14 col0\" >meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row14_col1\" class=\"data row14 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_4c0be_row15_col0\" class=\"data row15 col0\" >mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td id=\"T_4c0be_row15_col1\" class=\"data row15 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_4c0be_row16_col0\" class=\"data row16 col0\" >microsoft/Phi-3-medium-4k-instruct</td>\n",
       "      <td id=\"T_4c0be_row16_col1\" class=\"data row16 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_4c0be_row17_col0\" class=\"data row17 col0\" >microsoft/WizardLM-2-7B</td>\n",
       "      <td id=\"T_4c0be_row17_col1\" class=\"data row17 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_4c0be_row18_col0\" class=\"data row18 col0\" >microsoft/WizardLM-2-8x22B</td>\n",
       "      <td id=\"T_4c0be_row18_col1\" class=\"data row18 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_4c0be_row19_col0\" class=\"data row19 col0\" >mistralai/Mistral-Nemo-Instruct-2407</td>\n",
       "      <td id=\"T_4c0be_row19_col1\" class=\"data row19 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_4c0be_row20_col0\" class=\"data row20 col0\" >mistralai/Mixtral-8x7B-Instruct-v0.1</td>\n",
       "      <td id=\"T_4c0be_row20_col1\" class=\"data row20 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_4c0be_row21_col0\" class=\"data row21 col0\" >openbmb/MiniCPM-Llama3-V-2_5</td>\n",
       "      <td id=\"T_4c0be_row21_col1\" class=\"data row21 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_4c0be_row22_col0\" class=\"data row22 col0\" >openchat/openchat_3.5</td>\n",
       "      <td id=\"T_4c0be_row22_col1\" class=\"data row22 col1\" >deep_infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_4c0be_row23_col0\" class=\"data row23 col0\" >llama-3.1-sonar-huge-128k-online</td>\n",
       "      <td id=\"T_4c0be_row23_col1\" class=\"data row23 col1\" >perplexity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_4c0be_row24_col0\" class=\"data row24 col0\" >llama-3.1-sonar-large-128k-online</td>\n",
       "      <td id=\"T_4c0be_row24_col1\" class=\"data row24 col1\" >perplexity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_4c0be_row25_col0\" class=\"data row25 col0\" >llama-3.1-sonar-small-128k-online</td>\n",
       "      <td id=\"T_4c0be_row25_col1\" class=\"data row25 col1\" >perplexity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_4c0be_row26_col0\" class=\"data row26 col0\" >chatgpt-4o-latest</td>\n",
       "      <td id=\"T_4c0be_row26_col1\" class=\"data row26 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_4c0be_row27_col0\" class=\"data row27 col0\" >davinci--002</td>\n",
       "      <td id=\"T_4c0be_row27_col1\" class=\"data row27 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_4c0be_row28_col0\" class=\"data row28 col0\" >babbage-002</td>\n",
       "      <td id=\"T_4c0be_row28_col1\" class=\"data row28 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_4c0be_row29_col0\" class=\"data row29 col0\" >gpt-3.5-turbo</td>\n",
       "      <td id=\"T_4c0be_row29_col1\" class=\"data row29 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_4c0be_row30_col0\" class=\"data row30 col0\" >gpt-3.5-turbo-0125</td>\n",
       "      <td id=\"T_4c0be_row30_col1\" class=\"data row30 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_4c0be_row31_col0\" class=\"data row31 col0\" >gpt-3.5-turbo-0301</td>\n",
       "      <td id=\"T_4c0be_row31_col1\" class=\"data row31 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_4c0be_row32_col0\" class=\"data row32 col0\" >gpt-3.5-turbo-0613</td>\n",
       "      <td id=\"T_4c0be_row32_col1\" class=\"data row32 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_4c0be_row33_col0\" class=\"data row33 col0\" >gpt-3.5-turbo-1106</td>\n",
       "      <td id=\"T_4c0be_row33_col1\" class=\"data row33 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_4c0be_row34_col0\" class=\"data row34 col0\" >gpt-3.5-turbo-16k-0613</td>\n",
       "      <td id=\"T_4c0be_row34_col1\" class=\"data row34 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_4c0be_row35_col0\" class=\"data row35 col0\" >gpt-3.5-turbo-instruct</td>\n",
       "      <td id=\"T_4c0be_row35_col1\" class=\"data row35 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_4c0be_row36_col0\" class=\"data row36 col0\" >gpt-4</td>\n",
       "      <td id=\"T_4c0be_row36_col1\" class=\"data row36 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_4c0be_row37_col0\" class=\"data row37 col0\" >gpt-4-0125-preview</td>\n",
       "      <td id=\"T_4c0be_row37_col1\" class=\"data row37 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_4c0be_row38_col0\" class=\"data row38 col0\" >gpt-4-1106-preview</td>\n",
       "      <td id=\"T_4c0be_row38_col1\" class=\"data row38 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_4c0be_row39_col0\" class=\"data row39 col0\" >gpt-4-32k</td>\n",
       "      <td id=\"T_4c0be_row39_col1\" class=\"data row39 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_4c0be_row40_col0\" class=\"data row40 col0\" >gpt-4-turbo</td>\n",
       "      <td id=\"T_4c0be_row40_col1\" class=\"data row40 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_4c0be_row41_col0\" class=\"data row41 col0\" >gpt-4-turbo-2024-04-09</td>\n",
       "      <td id=\"T_4c0be_row41_col1\" class=\"data row41 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_4c0be_row42_col0\" class=\"data row42 col0\" >gpt-4-vision-preview</td>\n",
       "      <td id=\"T_4c0be_row42_col1\" class=\"data row42 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_4c0be_row43_col0\" class=\"data row43 col0\" >gpt-4o</td>\n",
       "      <td id=\"T_4c0be_row43_col1\" class=\"data row43 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_4c0be_row44_col0\" class=\"data row44 col0\" >gpt-4o-2024-05-13</td>\n",
       "      <td id=\"T_4c0be_row44_col1\" class=\"data row44 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_4c0be_row45_col0\" class=\"data row45 col0\" >gpt-4o-2024-08-06</td>\n",
       "      <td id=\"T_4c0be_row45_col1\" class=\"data row45 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_4c0be_row46_col0\" class=\"data row46 col0\" >gpt-4o-mini</td>\n",
       "      <td id=\"T_4c0be_row46_col1\" class=\"data row46 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_4c0be_row47_col0\" class=\"data row47 col0\" >gpt-4o-mini-2024-07-18</td>\n",
       "      <td id=\"T_4c0be_row47_col1\" class=\"data row47 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_4c0be_row48_col0\" class=\"data row48 col0\" >o1-mini</td>\n",
       "      <td id=\"T_4c0be_row48_col1\" class=\"data row48 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_4c0be_row49_col0\" class=\"data row49 col0\" >o1-mini-2024-09-12</td>\n",
       "      <td id=\"T_4c0be_row49_col1\" class=\"data row49 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_4c0be_row50_col0\" class=\"data row50 col0\" >o1-preview</td>\n",
       "      <td id=\"T_4c0be_row50_col1\" class=\"data row50 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_4c0be_row51_col0\" class=\"data row51 col0\" >o1-preview-2024-09-12</td>\n",
       "      <td id=\"T_4c0be_row51_col1\" class=\"data row51 col1\" >openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_4c0be_row52_col0\" class=\"data row52 col0\" >gemini-1.0-pro</td>\n",
       "      <td id=\"T_4c0be_row52_col1\" class=\"data row52 col1\" >google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_4c0be_row53_col0\" class=\"data row53 col0\" >gemini-1.5-flash</td>\n",
       "      <td id=\"T_4c0be_row53_col1\" class=\"data row53 col1\" >google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_4c0be_row54_col0\" class=\"data row54 col0\" >gemini-1.5-pro</td>\n",
       "      <td id=\"T_4c0be_row54_col1\" class=\"data row54 col1\" >google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_4c0be_row55_col0\" class=\"data row55 col0\" >gemini-pro</td>\n",
       "      <td id=\"T_4c0be_row55_col1\" class=\"data row55 col1\" >google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_4c0be_row56_col0\" class=\"data row56 col0\" >amazon.titan-text-express-v1</td>\n",
       "      <td id=\"T_4c0be_row56_col1\" class=\"data row56 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_4c0be_row57_col0\" class=\"data row57 col0\" >amazon.titan-text-lite-v1</td>\n",
       "      <td id=\"T_4c0be_row57_col1\" class=\"data row57 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_4c0be_row58_col0\" class=\"data row58 col0\" >anthropic.claude-3-5-sonnet-20240620-v1:0</td>\n",
       "      <td id=\"T_4c0be_row58_col1\" class=\"data row58 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_4c0be_row59_col0\" class=\"data row59 col0\" >anthropic.claude-3-haiku-20240307-v1:0</td>\n",
       "      <td id=\"T_4c0be_row59_col1\" class=\"data row59 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "      <td id=\"T_4c0be_row60_col0\" class=\"data row60 col0\" >anthropic.claude-3-opus-20240229-v1:0</td>\n",
       "      <td id=\"T_4c0be_row60_col1\" class=\"data row60 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "      <td id=\"T_4c0be_row61_col0\" class=\"data row61 col0\" >anthropic.claude-3-sonnet-20240229-v1:0</td>\n",
       "      <td id=\"T_4c0be_row61_col1\" class=\"data row61 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "      <td id=\"T_4c0be_row62_col0\" class=\"data row62 col0\" >anthropic.claude-instant-v1</td>\n",
       "      <td id=\"T_4c0be_row62_col1\" class=\"data row62 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
       "      <td id=\"T_4c0be_row63_col0\" class=\"data row63 col0\" >anthropic.claude-v2</td>\n",
       "      <td id=\"T_4c0be_row63_col1\" class=\"data row63 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
       "      <td id=\"T_4c0be_row64_col0\" class=\"data row64 col0\" >anthropic.claude-v2:1</td>\n",
       "      <td id=\"T_4c0be_row64_col1\" class=\"data row64 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row65\" class=\"row_heading level0 row65\" >65</th>\n",
       "      <td id=\"T_4c0be_row65_col0\" class=\"data row65 col0\" >cohere.command-light-text-v14</td>\n",
       "      <td id=\"T_4c0be_row65_col1\" class=\"data row65 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row66\" class=\"row_heading level0 row66\" >66</th>\n",
       "      <td id=\"T_4c0be_row66_col0\" class=\"data row66 col0\" >cohere.command-r-plus-v1:0</td>\n",
       "      <td id=\"T_4c0be_row66_col1\" class=\"data row66 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row67\" class=\"row_heading level0 row67\" >67</th>\n",
       "      <td id=\"T_4c0be_row67_col0\" class=\"data row67 col0\" >cohere.command-r-v1:0</td>\n",
       "      <td id=\"T_4c0be_row67_col1\" class=\"data row67 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row68\" class=\"row_heading level0 row68\" >68</th>\n",
       "      <td id=\"T_4c0be_row68_col0\" class=\"data row68 col0\" >cohere.command-text-v14</td>\n",
       "      <td id=\"T_4c0be_row68_col1\" class=\"data row68 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row69\" class=\"row_heading level0 row69\" >69</th>\n",
       "      <td id=\"T_4c0be_row69_col0\" class=\"data row69 col0\" >meta.llama3-1-405b-instruct-v1:0</td>\n",
       "      <td id=\"T_4c0be_row69_col1\" class=\"data row69 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row70\" class=\"row_heading level0 row70\" >70</th>\n",
       "      <td id=\"T_4c0be_row70_col0\" class=\"data row70 col0\" >meta.llama3-1-70b-instruct-v1:0</td>\n",
       "      <td id=\"T_4c0be_row70_col1\" class=\"data row70 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row71\" class=\"row_heading level0 row71\" >71</th>\n",
       "      <td id=\"T_4c0be_row71_col0\" class=\"data row71 col0\" >meta.llama3-1-8b-instruct-v1:0</td>\n",
       "      <td id=\"T_4c0be_row71_col1\" class=\"data row71 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row72\" class=\"row_heading level0 row72\" >72</th>\n",
       "      <td id=\"T_4c0be_row72_col0\" class=\"data row72 col0\" >meta.llama3-70b-instruct-v1:0</td>\n",
       "      <td id=\"T_4c0be_row72_col1\" class=\"data row72 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row73\" class=\"row_heading level0 row73\" >73</th>\n",
       "      <td id=\"T_4c0be_row73_col0\" class=\"data row73 col0\" >meta.llama3-8b-instruct-v1:0</td>\n",
       "      <td id=\"T_4c0be_row73_col1\" class=\"data row73 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row74\" class=\"row_heading level0 row74\" >74</th>\n",
       "      <td id=\"T_4c0be_row74_col0\" class=\"data row74 col0\" >mistral.mistral-7b-instruct-v0:2</td>\n",
       "      <td id=\"T_4c0be_row74_col1\" class=\"data row74 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row75\" class=\"row_heading level0 row75\" >75</th>\n",
       "      <td id=\"T_4c0be_row75_col0\" class=\"data row75 col0\" >mistral.mistral-large-2402-v1:0</td>\n",
       "      <td id=\"T_4c0be_row75_col1\" class=\"data row75 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row76\" class=\"row_heading level0 row76\" >76</th>\n",
       "      <td id=\"T_4c0be_row76_col0\" class=\"data row76 col0\" >mistral.mixtral-8x7b-instruct-v0:1</td>\n",
       "      <td id=\"T_4c0be_row76_col1\" class=\"data row76 col1\" >bedrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row77\" class=\"row_heading level0 row77\" >77</th>\n",
       "      <td id=\"T_4c0be_row77_col0\" class=\"data row77 col0\" >test</td>\n",
       "      <td id=\"T_4c0be_row77_col1\" class=\"data row77 col1\" >test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row78\" class=\"row_heading level0 row78\" >78</th>\n",
       "      <td id=\"T_4c0be_row78_col0\" class=\"data row78 col0\" >gemma-7b-it</td>\n",
       "      <td id=\"T_4c0be_row78_col1\" class=\"data row78 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row79\" class=\"row_heading level0 row79\" >79</th>\n",
       "      <td id=\"T_4c0be_row79_col0\" class=\"data row79 col0\" >gemma2-9b-it</td>\n",
       "      <td id=\"T_4c0be_row79_col1\" class=\"data row79 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row80\" class=\"row_heading level0 row80\" >80</th>\n",
       "      <td id=\"T_4c0be_row80_col0\" class=\"data row80 col0\" >llama-3.1-70b-versatile</td>\n",
       "      <td id=\"T_4c0be_row80_col1\" class=\"data row80 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row81\" class=\"row_heading level0 row81\" >81</th>\n",
       "      <td id=\"T_4c0be_row81_col0\" class=\"data row81 col0\" >llama-3.1-8b-instant</td>\n",
       "      <td id=\"T_4c0be_row81_col1\" class=\"data row81 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row82\" class=\"row_heading level0 row82\" >82</th>\n",
       "      <td id=\"T_4c0be_row82_col0\" class=\"data row82 col0\" >llama-guard-3-8b</td>\n",
       "      <td id=\"T_4c0be_row82_col1\" class=\"data row82 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row83\" class=\"row_heading level0 row83\" >83</th>\n",
       "      <td id=\"T_4c0be_row83_col0\" class=\"data row83 col0\" >llama3-70b-8192</td>\n",
       "      <td id=\"T_4c0be_row83_col1\" class=\"data row83 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row84\" class=\"row_heading level0 row84\" >84</th>\n",
       "      <td id=\"T_4c0be_row84_col0\" class=\"data row84 col0\" >llama3-8b-8192</td>\n",
       "      <td id=\"T_4c0be_row84_col1\" class=\"data row84 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row85\" class=\"row_heading level0 row85\" >85</th>\n",
       "      <td id=\"T_4c0be_row85_col0\" class=\"data row85 col0\" >llama3-groq-70b-8192-tool-use-preview</td>\n",
       "      <td id=\"T_4c0be_row85_col1\" class=\"data row85 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row86\" class=\"row_heading level0 row86\" >86</th>\n",
       "      <td id=\"T_4c0be_row86_col0\" class=\"data row86 col0\" >llama3-groq-8b-8192-tool-use-preview</td>\n",
       "      <td id=\"T_4c0be_row86_col1\" class=\"data row86 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row87\" class=\"row_heading level0 row87\" >87</th>\n",
       "      <td id=\"T_4c0be_row87_col0\" class=\"data row87 col0\" >mixtral-8x7b-32768</td>\n",
       "      <td id=\"T_4c0be_row87_col1\" class=\"data row87 col1\" >groq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row88\" class=\"row_heading level0 row88\" >88</th>\n",
       "      <td id=\"T_4c0be_row88_col0\" class=\"data row88 col0\" >azure:gpt-4o</td>\n",
       "      <td id=\"T_4c0be_row88_col1\" class=\"data row88 col1\" >azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row89\" class=\"row_heading level0 row89\" >89</th>\n",
       "      <td id=\"T_4c0be_row89_col0\" class=\"data row89 col0\" >azure:gpt-4o-mini</td>\n",
       "      <td id=\"T_4c0be_row89_col1\" class=\"data row89 col1\" >azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row90\" class=\"row_heading level0 row90\" >90</th>\n",
       "      <td id=\"T_4c0be_row90_col0\" class=\"data row90 col0\" >claude-3-5-sonnet-20240620</td>\n",
       "      <td id=\"T_4c0be_row90_col1\" class=\"data row90 col1\" >anthropic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row91\" class=\"row_heading level0 row91\" >91</th>\n",
       "      <td id=\"T_4c0be_row91_col0\" class=\"data row91 col0\" >claude-3-haiku-20240307</td>\n",
       "      <td id=\"T_4c0be_row91_col1\" class=\"data row91 col1\" >anthropic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row92\" class=\"row_heading level0 row92\" >92</th>\n",
       "      <td id=\"T_4c0be_row92_col0\" class=\"data row92 col0\" >claude-3-opus-20240229</td>\n",
       "      <td id=\"T_4c0be_row92_col1\" class=\"data row92 col1\" >anthropic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row93\" class=\"row_heading level0 row93\" >93</th>\n",
       "      <td id=\"T_4c0be_row93_col0\" class=\"data row93 col0\" >claude-3-sonnet-20240229</td>\n",
       "      <td id=\"T_4c0be_row93_col1\" class=\"data row93 col1\" >anthropic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row94\" class=\"row_heading level0 row94\" >94</th>\n",
       "      <td id=\"T_4c0be_row94_col0\" class=\"data row94 col0\" >meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo</td>\n",
       "      <td id=\"T_4c0be_row94_col1\" class=\"data row94 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row95\" class=\"row_heading level0 row95\" >95</th>\n",
       "      <td id=\"T_4c0be_row95_col0\" class=\"data row95 col0\" >mistralai/Mixtral-8x22B-Instruct-v0.1</td>\n",
       "      <td id=\"T_4c0be_row95_col1\" class=\"data row95 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row96\" class=\"row_heading level0 row96\" >96</th>\n",
       "      <td id=\"T_4c0be_row96_col0\" class=\"data row96 col0\" >meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo</td>\n",
       "      <td id=\"T_4c0be_row96_col1\" class=\"data row96 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row97\" class=\"row_heading level0 row97\" >97</th>\n",
       "      <td id=\"T_4c0be_row97_col0\" class=\"data row97 col0\" >meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo</td>\n",
       "      <td id=\"T_4c0be_row97_col1\" class=\"data row97 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row98\" class=\"row_heading level0 row98\" >98</th>\n",
       "      <td id=\"T_4c0be_row98_col0\" class=\"data row98 col0\" >Gryphe/MythoMax-L2-13b-Lite</td>\n",
       "      <td id=\"T_4c0be_row98_col1\" class=\"data row98 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row99\" class=\"row_heading level0 row99\" >99</th>\n",
       "      <td id=\"T_4c0be_row99_col0\" class=\"data row99 col0\" >Salesforce/Llama-Rank-V1</td>\n",
       "      <td id=\"T_4c0be_row99_col1\" class=\"data row99 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row100\" class=\"row_heading level0 row100\" >100</th>\n",
       "      <td id=\"T_4c0be_row100_col0\" class=\"data row100 col0\" >meta-llama/Meta-Llama-Guard-3-8B</td>\n",
       "      <td id=\"T_4c0be_row100_col1\" class=\"data row100 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row101\" class=\"row_heading level0 row101\" >101</th>\n",
       "      <td id=\"T_4c0be_row101_col0\" class=\"data row101 col0\" >meta-llama/Meta-Llama-3-70B-Instruct-Turbo</td>\n",
       "      <td id=\"T_4c0be_row101_col1\" class=\"data row101 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row102\" class=\"row_heading level0 row102\" >102</th>\n",
       "      <td id=\"T_4c0be_row102_col0\" class=\"data row102 col0\" >meta-llama/Meta-Llama-3-70B-Instruct-Lite</td>\n",
       "      <td id=\"T_4c0be_row102_col1\" class=\"data row102 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row103\" class=\"row_heading level0 row103\" >103</th>\n",
       "      <td id=\"T_4c0be_row103_col0\" class=\"data row103 col0\" >meta-llama/Meta-Llama-3-8B-Instruct-Lite</td>\n",
       "      <td id=\"T_4c0be_row103_col1\" class=\"data row103 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row104\" class=\"row_heading level0 row104\" >104</th>\n",
       "      <td id=\"T_4c0be_row104_col0\" class=\"data row104 col0\" >meta-llama/Meta-Llama-3-8B-Instruct-Turbo</td>\n",
       "      <td id=\"T_4c0be_row104_col1\" class=\"data row104 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row105\" class=\"row_heading level0 row105\" >105</th>\n",
       "      <td id=\"T_4c0be_row105_col0\" class=\"data row105 col0\" >meta-llama/Llama-3-70b-chat-hf</td>\n",
       "      <td id=\"T_4c0be_row105_col1\" class=\"data row105 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row106\" class=\"row_heading level0 row106\" >106</th>\n",
       "      <td id=\"T_4c0be_row106_col0\" class=\"data row106 col0\" >meta-llama/Llama-3-8b-chat-hf</td>\n",
       "      <td id=\"T_4c0be_row106_col1\" class=\"data row106 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row107\" class=\"row_heading level0 row107\" >107</th>\n",
       "      <td id=\"T_4c0be_row107_col0\" class=\"data row107 col0\" >Qwen/Qwen2-72B-Instruct</td>\n",
       "      <td id=\"T_4c0be_row107_col1\" class=\"data row107 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row108\" class=\"row_heading level0 row108\" >108</th>\n",
       "      <td id=\"T_4c0be_row108_col0\" class=\"data row108 col0\" >google/gemma-2-27b-it</td>\n",
       "      <td id=\"T_4c0be_row108_col1\" class=\"data row108 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row109\" class=\"row_heading level0 row109\" >109</th>\n",
       "      <td id=\"T_4c0be_row109_col0\" class=\"data row109 col0\" >google/gemma-2-9b-it</td>\n",
       "      <td id=\"T_4c0be_row109_col1\" class=\"data row109 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row110\" class=\"row_heading level0 row110\" >110</th>\n",
       "      <td id=\"T_4c0be_row110_col0\" class=\"data row110 col0\" >mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td id=\"T_4c0be_row110_col1\" class=\"data row110 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row111\" class=\"row_heading level0 row111\" >111</th>\n",
       "      <td id=\"T_4c0be_row111_col0\" class=\"data row111 col0\" >Qwen/Qwen1.5-110B-Chat</td>\n",
       "      <td id=\"T_4c0be_row111_col1\" class=\"data row111 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row112\" class=\"row_heading level0 row112\" >112</th>\n",
       "      <td id=\"T_4c0be_row112_col0\" class=\"data row112 col0\" >meta-llama/LlamaGuard-2-8b</td>\n",
       "      <td id=\"T_4c0be_row112_col1\" class=\"data row112 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row113\" class=\"row_heading level0 row113\" >113</th>\n",
       "      <td id=\"T_4c0be_row113_col0\" class=\"data row113 col0\" >microsoft/WizardLM-2-8x22B</td>\n",
       "      <td id=\"T_4c0be_row113_col1\" class=\"data row113 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row114\" class=\"row_heading level0 row114\" >114</th>\n",
       "      <td id=\"T_4c0be_row114_col0\" class=\"data row114 col0\" >togethercomputer/StripedHyena-Nous-7B</td>\n",
       "      <td id=\"T_4c0be_row114_col1\" class=\"data row114 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row115\" class=\"row_heading level0 row115\" >115</th>\n",
       "      <td id=\"T_4c0be_row115_col0\" class=\"data row115 col0\" >databricks/dbrx-instruct</td>\n",
       "      <td id=\"T_4c0be_row115_col1\" class=\"data row115 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row116\" class=\"row_heading level0 row116\" >116</th>\n",
       "      <td id=\"T_4c0be_row116_col0\" class=\"data row116 col0\" >deepseek-ai/deepseek-llm-67b-chat</td>\n",
       "      <td id=\"T_4c0be_row116_col1\" class=\"data row116 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row117\" class=\"row_heading level0 row117\" >117</th>\n",
       "      <td id=\"T_4c0be_row117_col0\" class=\"data row117 col0\" >google/gemma-2b-it</td>\n",
       "      <td id=\"T_4c0be_row117_col1\" class=\"data row117 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row118\" class=\"row_heading level0 row118\" >118</th>\n",
       "      <td id=\"T_4c0be_row118_col0\" class=\"data row118 col0\" >mistralai/Mistral-7B-Instruct-v0.2</td>\n",
       "      <td id=\"T_4c0be_row118_col1\" class=\"data row118 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row119\" class=\"row_heading level0 row119\" >119</th>\n",
       "      <td id=\"T_4c0be_row119_col0\" class=\"data row119 col0\" >mistralai/Mixtral-8x7B-Instruct-v0.1</td>\n",
       "      <td id=\"T_4c0be_row119_col1\" class=\"data row119 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row120\" class=\"row_heading level0 row120\" >120</th>\n",
       "      <td id=\"T_4c0be_row120_col0\" class=\"data row120 col0\" >mistralai/Mixtral-8x7B-v0.1</td>\n",
       "      <td id=\"T_4c0be_row120_col1\" class=\"data row120 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row121\" class=\"row_heading level0 row121\" >121</th>\n",
       "      <td id=\"T_4c0be_row121_col0\" class=\"data row121 col0\" >Qwen/Qwen1.5-72B-Chat</td>\n",
       "      <td id=\"T_4c0be_row121_col1\" class=\"data row121 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row122\" class=\"row_heading level0 row122\" >122</th>\n",
       "      <td id=\"T_4c0be_row122_col0\" class=\"data row122 col0\" >NousResearch/Nous-Hermes-2-Yi-34B</td>\n",
       "      <td id=\"T_4c0be_row122_col1\" class=\"data row122 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row123\" class=\"row_heading level0 row123\" >123</th>\n",
       "      <td id=\"T_4c0be_row123_col0\" class=\"data row123 col0\" >Meta-Llama/Llama-Guard-7b</td>\n",
       "      <td id=\"T_4c0be_row123_col1\" class=\"data row123 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row124\" class=\"row_heading level0 row124\" >124</th>\n",
       "      <td id=\"T_4c0be_row124_col0\" class=\"data row124 col0\" >NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO</td>\n",
       "      <td id=\"T_4c0be_row124_col1\" class=\"data row124 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row125\" class=\"row_heading level0 row125\" >125</th>\n",
       "      <td id=\"T_4c0be_row125_col0\" class=\"data row125 col0\" >mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td id=\"T_4c0be_row125_col1\" class=\"data row125 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row126\" class=\"row_heading level0 row126\" >126</th>\n",
       "      <td id=\"T_4c0be_row126_col0\" class=\"data row126 col0\" >mistralai/Mistral-7B-v0.1</td>\n",
       "      <td id=\"T_4c0be_row126_col1\" class=\"data row126 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row127\" class=\"row_heading level0 row127\" >127</th>\n",
       "      <td id=\"T_4c0be_row127_col0\" class=\"data row127 col0\" >meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td id=\"T_4c0be_row127_col1\" class=\"data row127 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row128\" class=\"row_heading level0 row128\" >128</th>\n",
       "      <td id=\"T_4c0be_row128_col0\" class=\"data row128 col0\" >meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td id=\"T_4c0be_row128_col1\" class=\"data row128 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row129\" class=\"row_heading level0 row129\" >129</th>\n",
       "      <td id=\"T_4c0be_row129_col0\" class=\"data row129 col0\" >meta-llama/Llama-2-70b-hf</td>\n",
       "      <td id=\"T_4c0be_row129_col1\" class=\"data row129 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row130\" class=\"row_heading level0 row130\" >130</th>\n",
       "      <td id=\"T_4c0be_row130_col0\" class=\"data row130 col0\" >codellama/CodeLlama-34b-Instruct-hf</td>\n",
       "      <td id=\"T_4c0be_row130_col1\" class=\"data row130 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row131\" class=\"row_heading level0 row131\" >131</th>\n",
       "      <td id=\"T_4c0be_row131_col0\" class=\"data row131 col0\" >upstage/SOLAR-10.7B-Instruct-v1.0</td>\n",
       "      <td id=\"T_4c0be_row131_col1\" class=\"data row131 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row132\" class=\"row_heading level0 row132\" >132</th>\n",
       "      <td id=\"T_4c0be_row132_col0\" class=\"data row132 col0\" >togethercomputer/m2-bert-80M-32k-retrieval</td>\n",
       "      <td id=\"T_4c0be_row132_col1\" class=\"data row132 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row133\" class=\"row_heading level0 row133\" >133</th>\n",
       "      <td id=\"T_4c0be_row133_col0\" class=\"data row133 col0\" >togethercomputer/m2-bert-80M-8k-retrieval</td>\n",
       "      <td id=\"T_4c0be_row133_col1\" class=\"data row133 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row134\" class=\"row_heading level0 row134\" >134</th>\n",
       "      <td id=\"T_4c0be_row134_col0\" class=\"data row134 col0\" >togethercomputer/m2-bert-80M-2k-retrieval</td>\n",
       "      <td id=\"T_4c0be_row134_col1\" class=\"data row134 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row135\" class=\"row_heading level0 row135\" >135</th>\n",
       "      <td id=\"T_4c0be_row135_col0\" class=\"data row135 col0\" >WhereIsAI/UAE-Large-V1</td>\n",
       "      <td id=\"T_4c0be_row135_col1\" class=\"data row135 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row136\" class=\"row_heading level0 row136\" >136</th>\n",
       "      <td id=\"T_4c0be_row136_col0\" class=\"data row136 col0\" >BAAI/bge-large-en-v1.5</td>\n",
       "      <td id=\"T_4c0be_row136_col1\" class=\"data row136 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row137\" class=\"row_heading level0 row137\" >137</th>\n",
       "      <td id=\"T_4c0be_row137_col0\" class=\"data row137 col0\" >BAAI/bge-base-en-v1.5</td>\n",
       "      <td id=\"T_4c0be_row137_col1\" class=\"data row137 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row138\" class=\"row_heading level0 row138\" >138</th>\n",
       "      <td id=\"T_4c0be_row138_col0\" class=\"data row138 col0\" >Gryphe/MythoMax-L2-13b</td>\n",
       "      <td id=\"T_4c0be_row138_col1\" class=\"data row138 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row139\" class=\"row_heading level0 row139\" >139</th>\n",
       "      <td id=\"T_4c0be_row139_col0\" class=\"data row139 col0\" >cursor/Llama-3-8b-hf</td>\n",
       "      <td id=\"T_4c0be_row139_col1\" class=\"data row139 col1\" >together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row140\" class=\"row_heading level0 row140\" >140</th>\n",
       "      <td id=\"T_4c0be_row140_col0\" class=\"data row140 col0\" >codestral-2405</td>\n",
       "      <td id=\"T_4c0be_row140_col1\" class=\"data row140 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row141\" class=\"row_heading level0 row141\" >141</th>\n",
       "      <td id=\"T_4c0be_row141_col0\" class=\"data row141 col0\" >mistral-embed</td>\n",
       "      <td id=\"T_4c0be_row141_col1\" class=\"data row141 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row142\" class=\"row_heading level0 row142\" >142</th>\n",
       "      <td id=\"T_4c0be_row142_col0\" class=\"data row142 col0\" >mistral-large-2407</td>\n",
       "      <td id=\"T_4c0be_row142_col1\" class=\"data row142 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row143\" class=\"row_heading level0 row143\" >143</th>\n",
       "      <td id=\"T_4c0be_row143_col0\" class=\"data row143 col0\" >mistral-medium-latest</td>\n",
       "      <td id=\"T_4c0be_row143_col1\" class=\"data row143 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row144\" class=\"row_heading level0 row144\" >144</th>\n",
       "      <td id=\"T_4c0be_row144_col0\" class=\"data row144 col0\" >mistral-small-2409</td>\n",
       "      <td id=\"T_4c0be_row144_col1\" class=\"data row144 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row145\" class=\"row_heading level0 row145\" >145</th>\n",
       "      <td id=\"T_4c0be_row145_col0\" class=\"data row145 col0\" >mistral-small-latest</td>\n",
       "      <td id=\"T_4c0be_row145_col1\" class=\"data row145 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row146\" class=\"row_heading level0 row146\" >146</th>\n",
       "      <td id=\"T_4c0be_row146_col0\" class=\"data row146 col0\" >open-mistral-7b</td>\n",
       "      <td id=\"T_4c0be_row146_col1\" class=\"data row146 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row147\" class=\"row_heading level0 row147\" >147</th>\n",
       "      <td id=\"T_4c0be_row147_col0\" class=\"data row147 col0\" >open-mistral-nemo-2407</td>\n",
       "      <td id=\"T_4c0be_row147_col1\" class=\"data row147 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row148\" class=\"row_heading level0 row148\" >148</th>\n",
       "      <td id=\"T_4c0be_row148_col0\" class=\"data row148 col0\" >open-mixtral-8x22b</td>\n",
       "      <td id=\"T_4c0be_row148_col1\" class=\"data row148 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row149\" class=\"row_heading level0 row149\" >149</th>\n",
       "      <td id=\"T_4c0be_row149_col0\" class=\"data row149 col0\" >open-mixtral-8x7b</td>\n",
       "      <td id=\"T_4c0be_row149_col1\" class=\"data row149 col1\" >mistral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4c0be_level0_row150\" class=\"row_heading level0 row150\" >150</th>\n",
       "      <td id=\"T_4c0be_row150_col0\" class=\"data row150 col0\" >pixtral-12b-2409</td>\n",
       "      <td id=\"T_4c0be_row150_col1\" class=\"data row150 col1\" >mistral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "PrettyList([['Austism/chronos-hermes-13b-v2', 'deep_infra'],\n",
       "            ['Gryphe/MythoMax-L2-13b', 'deep_infra'],\n",
       "            ['Qwen/Qwen2-72B-Instruct', 'deep_infra'],\n",
       "            ['Qwen/Qwen2-7B-Instruct', 'deep_infra'],\n",
       "            ['Qwen/Qwen2.5-72B-Instruct', 'deep_infra'],\n",
       "            ['Sao10K/L3-70B-Euryale-v2.1', 'deep_infra'],\n",
       "            ['Sao10K/L3.1-70B-Euryale-v2.2', 'deep_infra'],\n",
       "            ['google/gemma-2-27b-it', 'deep_infra'],\n",
       "            ['google/gemma-2-9b-it', 'deep_infra'],\n",
       "            ['lizpreciatior/lzlv_70b_fp16_hf', 'deep_infra'],\n",
       "            ['meta-llama/Meta-Llama-3-70B-Instruct', 'deep_infra'],\n",
       "            ['meta-llama/Meta-Llama-3-8B-Instruct', 'deep_infra'],\n",
       "            ['meta-llama/Meta-Llama-3.1-405B-Instruct', 'deep_infra'],\n",
       "            ['meta-llama/Meta-Llama-3.1-70B-Instruct', 'deep_infra'],\n",
       "            ['meta-llama/Meta-Llama-3.1-8B-Instruct', 'deep_infra'],\n",
       "            ['mistralai/Mistral-7B-Instruct-v0.3', 'deep_infra'],\n",
       "            ['microsoft/Phi-3-medium-4k-instruct', 'deep_infra'],\n",
       "            ['microsoft/WizardLM-2-7B', 'deep_infra'],\n",
       "            ['microsoft/WizardLM-2-8x22B', 'deep_infra'],\n",
       "            ['mistralai/Mistral-Nemo-Instruct-2407', 'deep_infra'],\n",
       "            ['mistralai/Mixtral-8x7B-Instruct-v0.1', 'deep_infra'],\n",
       "            ['openbmb/MiniCPM-Llama3-V-2_5', 'deep_infra'],\n",
       "            ['openchat/openchat_3.5', 'deep_infra'],\n",
       "            ['llama-3.1-sonar-huge-128k-online', 'perplexity'],\n",
       "            ['llama-3.1-sonar-large-128k-online', 'perplexity'],\n",
       "            ['llama-3.1-sonar-small-128k-online', 'perplexity'],\n",
       "            ['chatgpt-4o-latest', 'openai'],\n",
       "            ['davinci--002', 'openai'],\n",
       "            ['babbage-002', 'openai'],\n",
       "            ['gpt-3.5-turbo', 'openai'],\n",
       "            ['gpt-3.5-turbo-0125', 'openai'],\n",
       "            ['gpt-3.5-turbo-0301', 'openai'],\n",
       "            ['gpt-3.5-turbo-0613', 'openai'],\n",
       "            ['gpt-3.5-turbo-1106', 'openai'],\n",
       "            ['gpt-3.5-turbo-16k-0613', 'openai'],\n",
       "            ['gpt-3.5-turbo-instruct', 'openai'],\n",
       "            ['gpt-4', 'openai'],\n",
       "            ['gpt-4-0125-preview', 'openai'],\n",
       "            ['gpt-4-1106-preview', 'openai'],\n",
       "            ['gpt-4-32k', 'openai'],\n",
       "            ['gpt-4-turbo', 'openai'],\n",
       "            ['gpt-4-turbo-2024-04-09', 'openai'],\n",
       "            ['gpt-4-vision-preview', 'openai'],\n",
       "            ['gpt-4o', 'openai'],\n",
       "            ['gpt-4o-2024-05-13', 'openai'],\n",
       "            ['gpt-4o-2024-08-06', 'openai'],\n",
       "            ['gpt-4o-mini', 'openai'],\n",
       "            ['gpt-4o-mini-2024-07-18', 'openai'],\n",
       "            ['o1-mini', 'openai'],\n",
       "            ['o1-mini-2024-09-12', 'openai'],\n",
       "            ['o1-preview', 'openai'],\n",
       "            ['o1-preview-2024-09-12', 'openai'],\n",
       "            ['gemini-1.0-pro', 'google'],\n",
       "            ['gemini-1.5-flash', 'google'],\n",
       "            ['gemini-1.5-pro', 'google'],\n",
       "            ['gemini-pro', 'google'],\n",
       "            ['amazon.titan-text-express-v1', 'bedrock'],\n",
       "            ['amazon.titan-text-lite-v1', 'bedrock'],\n",
       "            ['anthropic.claude-3-5-sonnet-20240620-v1:0', 'bedrock'],\n",
       "            ['anthropic.claude-3-haiku-20240307-v1:0', 'bedrock'],\n",
       "            ['anthropic.claude-3-opus-20240229-v1:0', 'bedrock'],\n",
       "            ['anthropic.claude-3-sonnet-20240229-v1:0', 'bedrock'],\n",
       "            ['anthropic.claude-instant-v1', 'bedrock'],\n",
       "            ['anthropic.claude-v2', 'bedrock'],\n",
       "            ['anthropic.claude-v2:1', 'bedrock'],\n",
       "            ['cohere.command-light-text-v14', 'bedrock'],\n",
       "            ['cohere.command-r-plus-v1:0', 'bedrock'],\n",
       "            ['cohere.command-r-v1:0', 'bedrock'],\n",
       "            ['cohere.command-text-v14', 'bedrock'],\n",
       "            ['meta.llama3-1-405b-instruct-v1:0', 'bedrock'],\n",
       "            ['meta.llama3-1-70b-instruct-v1:0', 'bedrock'],\n",
       "            ['meta.llama3-1-8b-instruct-v1:0', 'bedrock'],\n",
       "            ['meta.llama3-70b-instruct-v1:0', 'bedrock'],\n",
       "            ['meta.llama3-8b-instruct-v1:0', 'bedrock'],\n",
       "            ['mistral.mistral-7b-instruct-v0:2', 'bedrock'],\n",
       "            ['mistral.mistral-large-2402-v1:0', 'bedrock'],\n",
       "            ['mistral.mixtral-8x7b-instruct-v0:1', 'bedrock'],\n",
       "            ['test', 'test'],\n",
       "            ['gemma-7b-it', 'groq'],\n",
       "            ['gemma2-9b-it', 'groq'],\n",
       "            ['llama-3.1-70b-versatile', 'groq'],\n",
       "            ['llama-3.1-8b-instant', 'groq'],\n",
       "            ['llama-guard-3-8b', 'groq'],\n",
       "            ['llama3-70b-8192', 'groq'],\n",
       "            ['llama3-8b-8192', 'groq'],\n",
       "            ['llama3-groq-70b-8192-tool-use-preview', 'groq'],\n",
       "            ['llama3-groq-8b-8192-tool-use-preview', 'groq'],\n",
       "            ['mixtral-8x7b-32768', 'groq'],\n",
       "            ['azure:gpt-4o', 'azure'],\n",
       "            ['azure:gpt-4o-mini', 'azure'],\n",
       "            ['claude-3-5-sonnet-20240620', 'anthropic'],\n",
       "            ['claude-3-haiku-20240307', 'anthropic'],\n",
       "            ['claude-3-opus-20240229', 'anthropic'],\n",
       "            ['claude-3-sonnet-20240229', 'anthropic'],\n",
       "            ['meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo', 'together'],\n",
       "            ['mistralai/Mixtral-8x22B-Instruct-v0.1', 'together'],\n",
       "            ['meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo', 'together'],\n",
       "            ['meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo', 'together'],\n",
       "            ['Gryphe/MythoMax-L2-13b-Lite', 'together'],\n",
       "            ['Salesforce/Llama-Rank-V1', 'together'],\n",
       "            ['meta-llama/Meta-Llama-Guard-3-8B', 'together'],\n",
       "            ['meta-llama/Meta-Llama-3-70B-Instruct-Turbo', 'together'],\n",
       "            ['meta-llama/Meta-Llama-3-70B-Instruct-Lite', 'together'],\n",
       "            ['meta-llama/Meta-Llama-3-8B-Instruct-Lite', 'together'],\n",
       "            ['meta-llama/Meta-Llama-3-8B-Instruct-Turbo', 'together'],\n",
       "            ['meta-llama/Llama-3-70b-chat-hf', 'together'],\n",
       "            ['meta-llama/Llama-3-8b-chat-hf', 'together'],\n",
       "            ['Qwen/Qwen2-72B-Instruct', 'together'],\n",
       "            ['google/gemma-2-27b-it', 'together'],\n",
       "            ['google/gemma-2-9b-it', 'together'],\n",
       "            ['mistralai/Mistral-7B-Instruct-v0.3', 'together'],\n",
       "            ['Qwen/Qwen1.5-110B-Chat', 'together'],\n",
       "            ['meta-llama/LlamaGuard-2-8b', 'together'],\n",
       "            ['microsoft/WizardLM-2-8x22B', 'together'],\n",
       "            ['togethercomputer/StripedHyena-Nous-7B', 'together'],\n",
       "            ['databricks/dbrx-instruct', 'together'],\n",
       "            ['deepseek-ai/deepseek-llm-67b-chat', 'together'],\n",
       "            ['google/gemma-2b-it', 'together'],\n",
       "            ['mistralai/Mistral-7B-Instruct-v0.2', 'together'],\n",
       "            ['mistralai/Mixtral-8x7B-Instruct-v0.1', 'together'],\n",
       "            ['mistralai/Mixtral-8x7B-v0.1', 'together'],\n",
       "            ['Qwen/Qwen1.5-72B-Chat', 'together'],\n",
       "            ['NousResearch/Nous-Hermes-2-Yi-34B', 'together'],\n",
       "            ['Meta-Llama/Llama-Guard-7b', 'together'],\n",
       "            ['NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', 'together'],\n",
       "            ['mistralai/Mistral-7B-Instruct-v0.1', 'together'],\n",
       "            ['mistralai/Mistral-7B-v0.1', 'together'],\n",
       "            ['meta-llama/Llama-2-13b-chat-hf', 'together'],\n",
       "            ['meta-llama/Llama-2-7b-chat-hf', 'together'],\n",
       "            ['meta-llama/Llama-2-70b-hf', 'together'],\n",
       "            ['codellama/CodeLlama-34b-Instruct-hf', 'together'],\n",
       "            ['upstage/SOLAR-10.7B-Instruct-v1.0', 'together'],\n",
       "            ['togethercomputer/m2-bert-80M-32k-retrieval', 'together'],\n",
       "            ['togethercomputer/m2-bert-80M-8k-retrieval', 'together'],\n",
       "            ['togethercomputer/m2-bert-80M-2k-retrieval', 'together'],\n",
       "            ['WhereIsAI/UAE-Large-V1', 'together'],\n",
       "            ['BAAI/bge-large-en-v1.5', 'together'],\n",
       "            ['BAAI/bge-base-en-v1.5', 'together'],\n",
       "            ['Gryphe/MythoMax-L2-13b', 'together'],\n",
       "            ['cursor/Llama-3-8b-hf', 'together'],\n",
       "            ['codestral-2405', 'mistral'],\n",
       "            ['mistral-embed', 'mistral'],\n",
       "            ['mistral-large-2407', 'mistral'],\n",
       "            ['mistral-medium-latest', 'mistral'],\n",
       "            ['mistral-small-2409', 'mistral'],\n",
       "            ['mistral-small-latest', 'mistral'],\n",
       "            ['open-mistral-7b', 'mistral'],\n",
       "            ['open-mistral-nemo-2407', 'mistral'],\n",
       "            ['open-mixtral-8x22b', 'mistral'],\n",
       "            ['open-mixtral-8x7b', 'mistral'],\n",
       "            ['pixtral-12b-2409', 'mistral']])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Model\n",
    "\n",
    "Model.available() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08673ee4-bf36-4277-88ca-820b8bd4ef69",
   "metadata": {},
   "source": [
    "To check the default model that will be used if no models are specified for a survey (e.g., as in the first example above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cc1db42-1546-4708-822c-33e69c5b2785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_645fc_row0_col0, #T_645fc_row0_col1, #T_645fc_row1_col0, #T_645fc_row1_col1, #T_645fc_row2_col0, #T_645fc_row2_col1, #T_645fc_row3_col0, #T_645fc_row3_col1, #T_645fc_row4_col0, #T_645fc_row4_col1, #T_645fc_row5_col0, #T_645fc_row5_col1, #T_645fc_row6_col0, #T_645fc_row6_col1, #T_645fc_row7_col0, #T_645fc_row7_col1, #T_645fc_row8_col0, #T_645fc_row8_col1, #T_645fc_row9_col0, #T_645fc_row9_col1, #T_645fc_row10_col0, #T_645fc_row10_col1, #T_645fc_row11_col0, #T_645fc_row11_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_645fc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_645fc_level0_col0\" class=\"col_heading level0 col0\" >Service Name</th>\n",
       "      <th id=\"T_645fc_level0_col1\" class=\"col_heading level0 col1\" >Local key?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_645fc_row0_col0\" class=\"data row0 col0\" >openai</td>\n",
       "      <td id=\"T_645fc_row0_col1\" class=\"data row0 col1\" >yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_645fc_row1_col0\" class=\"data row1 col0\" >anthropic</td>\n",
       "      <td id=\"T_645fc_row1_col1\" class=\"data row1 col1\" >yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_645fc_row2_col0\" class=\"data row2 col0\" >deep_infra</td>\n",
       "      <td id=\"T_645fc_row2_col1\" class=\"data row2 col1\" >yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_645fc_row3_col0\" class=\"data row3 col0\" >google</td>\n",
       "      <td id=\"T_645fc_row3_col1\" class=\"data row3 col1\" >yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_645fc_row4_col0\" class=\"data row4 col0\" >groq</td>\n",
       "      <td id=\"T_645fc_row4_col1\" class=\"data row4 col1\" >yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_645fc_row5_col0\" class=\"data row5 col0\" >bedrock</td>\n",
       "      <td id=\"T_645fc_row5_col1\" class=\"data row5 col1\" > </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_645fc_row6_col0\" class=\"data row6 col0\" >azure</td>\n",
       "      <td id=\"T_645fc_row6_col1\" class=\"data row6 col1\" > </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_645fc_row7_col0\" class=\"data row7 col0\" >ollama</td>\n",
       "      <td id=\"T_645fc_row7_col1\" class=\"data row7 col1\" > </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_645fc_row8_col0\" class=\"data row8 col0\" >test</td>\n",
       "      <td id=\"T_645fc_row8_col1\" class=\"data row8 col1\" >yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_645fc_row9_col0\" class=\"data row9 col0\" >together</td>\n",
       "      <td id=\"T_645fc_row9_col1\" class=\"data row9 col1\" > </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_645fc_row10_col0\" class=\"data row10 col0\" >perplexity</td>\n",
       "      <td id=\"T_645fc_row10_col1\" class=\"data row10 col1\" > </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_645fc_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_645fc_row11_col0\" class=\"data row11 col0\" >mistral</td>\n",
       "      <td id=\"T_645fc_row11_col1\" class=\"data row11 col1\" >yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "PrettyList([('openai', 'yes'),\n",
       "            ('anthropic', 'yes'),\n",
       "            ('deep_infra', 'yes'),\n",
       "            ('google', 'yes'),\n",
       "            ('groq', 'yes'),\n",
       "            ('bedrock', ' '),\n",
       "            ('azure', ' '),\n",
       "            ('ollama', ' '),\n",
       "            ('test', 'yes'),\n",
       "            ('together', ' '),\n",
       "            ('perplexity', ' '),\n",
       "            ('mistral', 'yes')])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Model.services()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2746b46-e526-45c0-a67d-cea66f19545d",
   "metadata": {},
   "source": [
    "(Note that the output may be different if the default model has changed since this page was last updated.)\n",
    "\n",
    "Here we select some models to use with our survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d64a20a2-3bd5-4db1-a469-711d222b3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import ModelList, Model\n",
    "\n",
    "models = ModelList(\n",
    "    Model(m) for m in [\"gpt-4o\", \"gemini-1.5-flash\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a23f1-405c-4554-b739-b64591566f0c",
   "metadata": {},
   "source": [
    "### Running a survey\n",
    "We add agents and models to a survey using the `by` method.\n",
    "Then we administer a survey the same way that we do an individual question, by calling the `run` method on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da64a02c-b17e-4067-92b1-3ab330f9f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnhorton/tools/edsl/edsl/agents/QuestionInstructionPromptBuilder.py:94: UserWarning: Question instructions still has variables: ['activity'].\n",
      "  warn(f\"Question instructions still has variables: {undefined_vars}.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msurvey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tools/edsl/edsl/jobs/Jobs.py:84\u001b[0m, in \u001b[0;36mwith_config.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m parameters \u001b[38;5;241m=\u001b[39m RunParameters(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m parameter_fields}\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m RunConfig(environment\u001b[38;5;241m=\u001b[39menvironment, parameters\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tools/edsl/edsl/jobs/Jobs.py:611\u001b[0m, in \u001b[0;36mJobs.run\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03mRuns the Job: conducts Interviews and returns their results.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m:param key_lookup: A KeyLookup object to manage API keys\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(config)\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_with_remote_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_job_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/asyncio/events.py:80\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/tools/edsl/edsl/jobs/Jobs.py:522\u001b[0m, in \u001b[0;36mJobs._execute_with_remote_cache\u001b[0;34m(self, run_job_async)\u001b[0m\n\u001b[1;32m    520\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mparameters)\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/tools/edsl/edsl/utilities/decorators.py:62\u001b[0m, in \u001b[0;36mjupyter_nb_handler.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# If the loop is running, schedule the coroutine and wait for the result\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(async_wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# If the loop is not running, run the coroutine to completion\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mrun(async_wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/selectors.py:561\u001b[0m, in \u001b[0;36mKqueueSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 561\u001b[0m     kev_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mcontrol(\u001b[38;5;28;01mNone\u001b[39;00m, max_ev, timeout)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exceptions were raised in 6 interviews.\n",
      "Exceptions were raised in the following interviews: [0, 1, 2, 3, 4, 5].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception report saved to /Users/johnhorton/tools/edsl/docs/notebooks/tmp62xncgd2.html\n",
      "Also see: https://docs.expectedparrot.com/en/latest/exceptions.html\n"
     ]
    }
   ],
   "source": [
    "results = survey.by(agents).by(models).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f989cea-65d4-43a5-9b0f-abd114aecb50",
   "metadata": {},
   "source": [
    "We can pass an expression to `filter()` the results and list the components to `sort_by()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dd3b76e-2c9a-4129-8927-f27f50dea1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_093d5_row0_col0, #T_093d5_row0_col1, #T_093d5_row1_col0, #T_093d5_row1_col1, #T_093d5_row2_col0, #T_093d5_row2_col1, #T_093d5_row3_col0, #T_093d5_row3_col1 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_093d5_row0_col2, #T_093d5_row0_col3, #T_093d5_row1_col2, #T_093d5_row1_col3, #T_093d5_row2_col2, #T_093d5_row2_col3, #T_093d5_row3_col2, #T_093d5_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_093d5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_093d5_level0_col0\" class=\"col_heading level0 col0\" >model.model</th>\n",
       "      <th id=\"T_093d5_level0_col1\" class=\"col_heading level0 col1\" >agent.persona</th>\n",
       "      <th id=\"T_093d5_level0_col2\" class=\"col_heading level0 col2\" >answer.enjoy</th>\n",
       "      <th id=\"T_093d5_level0_col3\" class=\"col_heading level0 col3\" >answer.favorite_place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_093d5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_093d5_row0_col0\" class=\"data row0 col0\" >gemini-1.5-flash</td>\n",
       "      <td id=\"T_093d5_row0_col1\" class=\"data row0 col1\" >mechanic</td>\n",
       "      <td id=\"T_093d5_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_093d5_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_093d5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_093d5_row1_col0\" class=\"data row1 col0\" >gpt-4o</td>\n",
       "      <td id=\"T_093d5_row1_col1\" class=\"data row1 col1\" >mechanic</td>\n",
       "      <td id=\"T_093d5_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_093d5_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_093d5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_093d5_row2_col0\" class=\"data row2 col0\" >gemini-1.5-flash</td>\n",
       "      <td id=\"T_093d5_row2_col1\" class=\"data row2 col1\" >sailor</td>\n",
       "      <td id=\"T_093d5_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_093d5_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_093d5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_093d5_row3_col0\" class=\"data row3 col0\" >gpt-4o</td>\n",
       "      <td id=\"T_093d5_row3_col1\" class=\"data row3 col1\" >sailor</td>\n",
       "      <td id=\"T_093d5_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_093d5_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "Dataset([{'model.model': ['gemini-1.5-flash', 'gpt-4o', 'gemini-1.5-flash', 'gpt-4o']}, {'agent.persona': ['mechanic', 'mechanic', 'sailor', 'sailor']}, {'answer.enjoy': [None, None, None, None]}, {'answer.favorite_place': [None, None, None, None]}])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    results\n",
    "    .filter(\"persona != 'artist'\")\n",
    "    .sort_by(\"persona\", \"model\")\n",
    "    .select(\"model\", \"persona\", \"enjoy\", \"favorite_place\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4939d-06f8-4b15-98eb-2bd17728d29d",
   "metadata": {},
   "source": [
    "## Example: Adding context to questions\n",
    "EDSL provides a variety of ways to add data or content to survey questions. \n",
    "These methods include:\n",
    "\n",
    "* [Piping](https://docs.expectedparrot.com/en/latest/surveys.html#id2) answers to questions into follow-on questions\n",
    "* [Adding \"memory\"](https://docs.expectedparrot.com/en/latest/surveys.html#question-memory) of prior questions and answers in a survey when presenting other questions to a model\n",
    "* [Parameterizing questions with data](https://docs.expectedparrot.com/en/latest/scenarios.html), e.g., content from PDFs, CSVs, docs, images or other sources that you want to add to questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54fa90-7246-4963-9590-7e112e89c23e",
   "metadata": {},
   "source": [
    "### Piping question answers\n",
    "Here we demonstrate how to pipe the answer to a question into the text of another question.\n",
    "This is done by using a placeholder `{{ <question_name>.answer }}` in the text of the follow-on question where the answer to the prior question is to be inserted when the survey is run.\n",
    "This causes the questions to be administered in the required order (survey questions are administered asynchronously by default).\n",
    "Learn more about [piping question answers](https://docs.expectedparrot.com/en/latest/surveys.html#id2).\n",
    "\n",
    "Here we insert the answer to a numerical question into the text of a follow-on yes/no question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db74b5b9-1523-4d6a-ac8f-5ccb65589922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import QuestionNumerical, QuestionYesNo, Survey\n",
    "\n",
    "q1 = QuestionNumerical(\n",
    "    question_name = \"random_number\",\n",
    "    question_text = \"Pick a random number between 1 and 1,000.\"\n",
    ")\n",
    "\n",
    "q2 = QuestionYesNo(\n",
    "    question_name = \"prime\",\n",
    "    question_text = \"Is this a prime number: {{ random_number.answer }}\"\n",
    ")\n",
    "\n",
    "survey = Survey([q1, q2])\n",
    "\n",
    "results = survey.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7ecb9-dc91-4df0-ade7-0498db29aeeb",
   "metadata": {},
   "source": [
    "We can check the `user_prompt` for the `prime` question to verify that that the answer to the `random_number` question was piped into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8aceca7-cfe4-4683-a101-40e280a536c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_9bd0a_row0_col0 {\n",
       "  text-align: left;\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_9bd0a_row0_col1, #T_9bd0a_row0_col2, #T_9bd0a_row0_col3 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9bd0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9bd0a_level0_col0\" class=\"col_heading level0 col0\" >answer.random_number</th>\n",
       "      <th id=\"T_9bd0a_level0_col1\" class=\"col_heading level0 col1\" >prompt.prime_user_prompt</th>\n",
       "      <th id=\"T_9bd0a_level0_col2\" class=\"col_heading level0 col2\" >answer.prime</th>\n",
       "      <th id=\"T_9bd0a_level0_col3\" class=\"col_heading level0 col3\" >comment.prime_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9bd0a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9bd0a_row0_col0\" class=\"data row0 col0\" >487</td>\n",
       "      <td id=\"T_9bd0a_row0_col1\" class=\"data row0 col1\" >\n",
       "Is this a prime number: 487\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.</td>\n",
       "      <td id=\"T_9bd0a_row0_col2\" class=\"data row0 col2\" >No</td>\n",
       "      <td id=\"T_9bd0a_row0_col3\" class=\"data row0 col3\" >487 is not a prime number because it can be divided by 1, 487, and also by 19 and 25.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "Dataset([{'answer.random_number': [487]}, {'prompt.prime_user_prompt': [Prompt(text=\"\"\"\n",
       "Is this a prime number: 487\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\"\"\")]}, {'answer.prime': ['No']}, {'comment.prime_comment': ['487 is not a prime number because it can be divided by 1, 487, and also by 19 and 25.']}])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.select(\"random_number\", \"prime_user_prompt\", \"prime\", \"prime_comment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9736aa-fda5-4eed-8917-ea0cbc723d5f",
   "metadata": {},
   "source": [
    "### Adding \"memory\" of questions and answers\n",
    "Here we instead add a \"memory\" of the first question and answer to the context of the second question.\n",
    "This is done by calling a memory rule and identifying the question(s) to add.\n",
    "Instead of just the answer, information about the full question and answer are presented with the follow-on question text, and no placeholder is used.\n",
    "Learn more about [question memory rules](https://docs.expectedparrot.com/en/latest/surveys.html#survey-rules-logic).\n",
    "\n",
    "Here we demonstrate the `add_targeted_memory` method (we could also use `set_full_memory_mode` or other memory rules):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "618109ac-ac2b-4989-82f9-25270b1426cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exceptions were raised in 1 interviews.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/files//Users/johnhorton/tools/edsl/docs/notebooks/tmp62j53vty.html\" target=\"_blank\">Open report to see details.</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\"\n",
       "            <iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html lang=&quot;en&quot;&gt;\n",
       "&lt;head&gt;\n",
       "    &lt;meta charset=&quot;UTF-8&quot;&gt;\n",
       "    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;\n",
       "    &lt;title&gt;Exception Details&lt;/title&gt;\n",
       "    &lt;style&gt;\n",
       "    body {\n",
       "    font-family: Arial, sans-serif;\n",
       "    line-height: 1.6;\n",
       "    background-color: #f9f9f9;\n",
       "    color: #333;\n",
       "    margin: 20px;\n",
       "}\n",
       "\n",
       ".interview {\n",
       "    font-size: 1.5em;\n",
       "    margin-bottom: 10px;\n",
       "    padding: 10px;\n",
       "    background-color: #e3f2fd;\n",
       "    border-left: 5px solid #2196f3;\n",
       "}\n",
       "\n",
       ".question {\n",
       "    font-size: 1.2em;\n",
       "    margin-bottom: 10px;\n",
       "    padding: 10px;\n",
       "    background-color: #fff9c4;\n",
       "    border-left: 5px solid #ffeb3b;\n",
       "}\n",
       "\n",
       ".exception-detail {\n",
       "    margin-bottom: 10px;\n",
       "    background-color: #ffebee;\n",
       "    border-left: 5px solid #f44336;\n",
       "}\n",
       "\n",
       ".exception-header {\n",
       "    padding: 10px;\n",
       "    cursor: pointer;\n",
       "    display: flex;\n",
       "    justify-content: space-between;\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       ".exception-content {\n",
       "    padding: 10px;\n",
       "    display: none;\n",
       "}\n",
       "\n",
       ".exception-content.show {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".question-detail {\n",
       "    border: 3px solid black;\n",
       "    padding: 10px;\n",
       "}\n",
       "\n",
       ".exception-exception {\n",
       "    font-weight: bold;\n",
       "    color: #d32f2f;\n",
       "}\n",
       "\n",
       ".exception-time,\n",
       ".exception-traceback {\n",
       "    font-style: italic;\n",
       "    color: #555;\n",
       "}\n",
       "\n",
       ".toggle-btn {\n",
       "    background: none;\n",
       "    border: none;\n",
       "    font-size: 1.2em;\n",
       "    cursor: pointer;\n",
       "    transition: transform 0.3s;\n",
       "}\n",
       "\n",
       ".toggle-btn.rotated {\n",
       "    transform: rotate(180deg);\n",
       "}\n",
       "    &lt;/style&gt;\n",
       "\n",
       "    &lt;script&gt;\n",
       "    document.addEventListener(&#x27;DOMContentLoaded&#x27;, function() {\n",
       "    const collapsibleSections = document.querySelectorAll(&#x27;.exception-detail, .raw-model-response&#x27;);\n",
       "\n",
       "    collapsibleSections.forEach(section =&gt; {\n",
       "        const header = section.querySelector(&#x27;.exception-header, .response-header&#x27;);\n",
       "        const content = section.querySelector(&#x27;.exception-content, .response-content&#x27;);\n",
       "        const toggleBtn = section.querySelector(&#x27;.toggle-btn&#x27;);\n",
       "\n",
       "        header.addEventListener(&#x27;click&#x27;, function() {\n",
       "            content.classList.toggle(&#x27;show&#x27;);\n",
       "            toggleBtn.classList.toggle(&#x27;rotated&#x27;);\n",
       "        });\n",
       "    });\n",
       "\n",
       "});\n",
       "\n",
       "function copyCode() {\n",
       "    const textarea = document.getElementById(&#x27;codeToCopy&#x27;);\n",
       "    textarea.select();\n",
       "    textarea.setSelectionRange(0, 99999); // For mobile devices\n",
       "    document.execCommand(&quot;copy&quot;);\n",
       "\n",
       "    // Optionally, you can display an alert or change the button text to indicate success\n",
       "    alert(&quot;Code copied to clipboard!&quot;);\n",
       "}\n",
       "\n",
       "    &lt;/script&gt;\n",
       "\n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    &lt;h1&gt;Overview&lt;/h1&gt;\n",
       "&lt;p&gt;There were 1 total interview(s). An &#x27;interview&#x27; is the result of one survey, taken by one agent, with one model, with one scenario.&lt;/p&gt;    \n",
       "The number of interviews with any exceptions was 1.&lt;/p&gt;\n",
       "&lt;p&gt;For advice on dealing with exceptions on Expected Parrot, \n",
       "see &lt;a href=&quot;https://docs.expectedparrot.com/en/latest/exceptions.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;\n",
       "    &lt;h2&gt;Exceptions by Type&lt;/h2&gt;\n",
       "&lt;table border=&quot;1&quot;&gt;\n",
       "    &lt;thead&gt;\n",
       "        &lt;tr&gt;\n",
       "            &lt;th&gt;Exception Type&lt;/th&gt;\n",
       "            &lt;th&gt;Number&lt;/th&gt;\n",
       "        &lt;/tr&gt;\n",
       "    &lt;/thead&gt;\n",
       "    &lt;tbody&gt;\n",
       "        \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;UnboundLocalError&lt;/td&gt;\n",
       "                &lt;td&gt;5&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "        \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;LanguageModelNoResponseError&lt;/td&gt;\n",
       "                &lt;td&gt;1&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "        \n",
       "    &lt;/tbody&gt;\n",
       "&lt;/table&gt;\n",
       "    &lt;h2&gt;Exceptions by Model&lt;/h2&gt;\n",
       "&lt;table border=&quot;1&quot;&gt;\n",
       "    &lt;thead&gt;\n",
       "        &lt;tr&gt;\n",
       "            &lt;th&gt;Model&lt;/th&gt;\n",
       "            &lt;th&gt;Number&lt;/th&gt;\n",
       "        &lt;/tr&gt;\n",
       "    &lt;/thead&gt;\n",
       "    &lt;tbody&gt;\n",
       "        \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;(&#x27;openai&#x27;, &#x27;gpt-4o&#x27;)&lt;/td&gt;\n",
       "                &lt;td&gt;1&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "        \n",
       "    &lt;/tbody&gt;\n",
       "&lt;/table&gt;\n",
       "\n",
       "&lt;h2&gt;Exceptions by Service&lt;/h2&gt;\n",
       "&lt;table border=&quot;1&quot;&gt;\n",
       "    &lt;thead&gt;\n",
       "        &lt;tr&gt;\n",
       "            &lt;th&gt;Service&lt;/th&gt;\n",
       "            &lt;th&gt;Number&lt;/th&gt;\n",
       "        &lt;/tr&gt;\n",
       "    &lt;/thead&gt;\n",
       "    &lt;tbody&gt;\n",
       "        \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;openai&lt;/td&gt;\n",
       "                &lt;td&gt;1&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "        \n",
       "    &lt;/tbody&gt;\n",
       "&lt;/table&gt;\n",
       "    &lt;h2&gt;Exceptions by Question Name&lt;/h2&gt;\n",
       "&lt;table border=&quot;1&quot;&gt;\n",
       "    &lt;thead&gt;\n",
       "        &lt;tr&gt;\n",
       "            &lt;th&gt;Question Name&lt;/th&gt;\n",
       "            &lt;th&gt;Number of Exceptions&lt;/th&gt;\n",
       "        &lt;/tr&gt;\n",
       "    &lt;/thead&gt;\n",
       "    &lt;tbody&gt;\n",
       "        \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;(&#x27;prime&#x27;, &#x27;yes_no&#x27;)&lt;/td&gt;\n",
       "                &lt;td&gt;6&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "        \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;(&#x27;random_number&#x27;, &#x27;numerical&#x27;)&lt;/td&gt;\n",
       "                &lt;td&gt;0&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "        \n",
       "    &lt;/tbody&gt;\n",
       "&lt;/table&gt;\n",
       "    \n",
       "\n",
       "    &lt;h1&gt;Showing all interviews&lt;/h1&gt;    \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "        &lt;div class=&quot;interview&quot;&gt;Interview: 0 &lt;/div&gt;\n",
       "        Model: gpt-4o\n",
       "        &lt;h1&gt;Failing questions&lt;/h1&gt;\n",
       "        \n",
       "        \n",
       "            &lt;div class=&quot;question&quot;&gt;question_name: prime&lt;/div&gt;\n",
       "\n",
       "\n",
       "&lt;h2&gt;Exception details&lt;/h2&gt;\n",
       "\n",
       "\n",
       "&lt;div class=&quot;exception-detail&quot;&gt;\n",
       "        &lt;div class=&quot;exception-header&quot;&gt;\n",
       "        &lt;span class=&quot;exception-exception&quot;&gt;Exception: UnboundLocalError(&quot;cannot access local variable &#x27;response&#x27; where it is not associated with a value&quot;)&lt;/span&gt;\n",
       "        &lt;button class=&quot;toggle-btn&quot;&gt;▼&lt;/button&gt;\n",
       "        &lt;/div&gt;\n",
       "        &lt;div class=&quot;exception-content&quot;&gt;\n",
       "        &lt;table border=&quot;1&quot;&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;th&gt;Key&lt;/th&gt;\n",
       "                &lt;th&gt;Value&lt;/th&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Interview ID (index in results)&lt;/td&gt;\n",
       "                &lt;td&gt;0&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question name (question_name)&lt;/td&gt;\n",
       "                &lt;td&gt;prime&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question type (question_type)&lt;/td&gt;\n",
       "                &lt;td&gt;yes_no&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Human-readable question&lt;/td&gt;\n",
       "                &lt;td&gt;\n",
       "        &lt;div id=&quot;prime&quot; class=&quot;survey_question&quot; data-type=&quot;yes_no&quot;&gt;\n",
       "            \n",
       "            &lt;p class=&quot;question_text&quot;&gt;Is the number you picked a prime number?&lt;/p&gt;\n",
       "            \n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;No&quot; name=&quot;prime&quot; value=&quot;No&quot;&gt;\n",
       "        &lt;label for=&quot;No&quot;&gt;\n",
       "        No\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;Yes&quot; name=&quot;prime&quot; value=&quot;Yes&quot;&gt;\n",
       "        &lt;label for=&quot;Yes&quot;&gt;\n",
       "        Yes\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "        \n",
       "        \n",
       "        &lt;/div&gt;\n",
       "        &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Scenario&lt;/td&gt;\n",
       "                &lt;td&gt;Scenario({&#x27;scenario_index&#x27;: 0})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Agent&lt;/td&gt;\n",
       "                &lt;td&gt;Agent(traits = {})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model name&lt;/td&gt;\n",
       "                &lt;td&gt;gpt-4o&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Inference service&lt;/td&gt;\n",
       "                &lt;td&gt;openai&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model parameters&lt;/td&gt;\n",
       "                &lt;td&gt;Model(model_name = &#x27;gpt-4o&#x27;, temperature = 0.5, max_tokens = 1000, top_p = 1, frequency_penalty = 0, presence_penalty = 0, logprobs = False, top_logprobs = 3)&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;User Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;\n",
       "Is the number you picked a prime number?\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\n",
       "        Before the question you are now answering, you already answered the following question(s):\n",
       "        \tQuestion: Pick a random number between 1 and 1,000.\n",
       "\tAnswer: 487&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;System Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Raw model response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Generated token string (at [&#x27;choices&#x27;, 0, &#x27;message&#x27;, &#x27;content&#x27;]) in raw response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "            &lt;td&gt;Code to (likely) reproduce the error&lt;/td&gt;\n",
       "            &lt;td&gt;\n",
       "                &lt;textarea id=&quot;codeToCopy&quot; rows=&quot;10&quot; cols=&quot;90&quot;&gt;from edsl import Question, Model, Scenario, Agent\n",
       "q = Question(&#x27;yes_no&#x27;, question_name = &quot;&quot;&quot;prime&quot;&quot;&quot;, question_text = &quot;&quot;&quot;Is the number you picked a prime number?&quot;&quot;&quot;, question_options = [&#x27;No&#x27;, &#x27;Yes&#x27;])\n",
       "scenario = Scenario({})\n",
       "agent = Agent(traits = {})\n",
       "m = Model(&#x27;gpt-4o&#x27;)\n",
       "results = q.by(m).by(agent).by(scenario).run()&lt;/textarea&gt;\n",
       "                &lt;button onclick=&quot;copyCode()&quot;&gt;Copy&lt;/button&gt;\n",
       "            &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "\n",
       "        &lt;/table&gt;\n",
       "\n",
       "        \n",
       "            \n",
       "\n",
       "            &lt;div class=&quot;exception-time&quot;&gt;Time: 2024-12-31T10:38:41.368262&lt;/div&gt;          \n",
       "            &lt;div class=&quot;exception-traceback&quot;&gt;Traceback: \n",
       "                &lt;text&gt;\n",
       "                &lt;pre&gt;Traceback (most recent call last):\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/AnswerQuestionFunctionConstructor.py&quot;, line 171, in attempt_answer\n",
       "    await invigilator.async_answer_question()\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 57, in async_answer_question\n",
       "    agent_response_dict = await self.async_get_agent_response()\n",
       "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 45, in async_get_agent_response\n",
       "    return await self.model.async_get_response(**params)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 460, in async_get_response\n",
       "    await self._async_get_intended_model_call_outcome(**params)\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 398, in _async_get_intended_model_call_outcome\n",
       "    response = await asyncio.wait_for(f(**params), timeout=TIMEOUT)\n",
       "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 479, in wait_for\n",
       "    return fut.result()\n",
       "           ^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/futures.py&quot;, line 203, in result\n",
       "    raise self._exception.with_traceback(self._exception_tb)\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 267, in __step\n",
       "    result = coro.send(None)\n",
       "             ^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/inference_services/OpenAIService.py&quot;, line 232, in async_execute_model_call\n",
       "    return response.model_dump()\n",
       "           ^^^^^^^^\n",
       "UnboundLocalError: cannot access local variable &#x27;response&#x27; where it is not associated with a value\n",
       "&lt;/pre&gt;\n",
       "                &lt;/text&gt;\n",
       "            &lt;/div&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "\n",
       "\n",
       "&lt;div class=&quot;exception-detail&quot;&gt;\n",
       "        &lt;div class=&quot;exception-header&quot;&gt;\n",
       "        &lt;span class=&quot;exception-exception&quot;&gt;Exception: UnboundLocalError(&quot;cannot access local variable &#x27;response&#x27; where it is not associated with a value&quot;)&lt;/span&gt;\n",
       "        &lt;button class=&quot;toggle-btn&quot;&gt;▼&lt;/button&gt;\n",
       "        &lt;/div&gt;\n",
       "        &lt;div class=&quot;exception-content&quot;&gt;\n",
       "        &lt;table border=&quot;1&quot;&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;th&gt;Key&lt;/th&gt;\n",
       "                &lt;th&gt;Value&lt;/th&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Interview ID (index in results)&lt;/td&gt;\n",
       "                &lt;td&gt;0&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question name (question_name)&lt;/td&gt;\n",
       "                &lt;td&gt;prime&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question type (question_type)&lt;/td&gt;\n",
       "                &lt;td&gt;yes_no&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Human-readable question&lt;/td&gt;\n",
       "                &lt;td&gt;\n",
       "        &lt;div id=&quot;prime&quot; class=&quot;survey_question&quot; data-type=&quot;yes_no&quot;&gt;\n",
       "            \n",
       "            &lt;p class=&quot;question_text&quot;&gt;Is the number you picked a prime number?&lt;/p&gt;\n",
       "            \n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;No&quot; name=&quot;prime&quot; value=&quot;No&quot;&gt;\n",
       "        &lt;label for=&quot;No&quot;&gt;\n",
       "        No\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;Yes&quot; name=&quot;prime&quot; value=&quot;Yes&quot;&gt;\n",
       "        &lt;label for=&quot;Yes&quot;&gt;\n",
       "        Yes\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "        \n",
       "        \n",
       "        &lt;/div&gt;\n",
       "        &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Scenario&lt;/td&gt;\n",
       "                &lt;td&gt;Scenario({&#x27;scenario_index&#x27;: 0})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Agent&lt;/td&gt;\n",
       "                &lt;td&gt;Agent(traits = {})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model name&lt;/td&gt;\n",
       "                &lt;td&gt;gpt-4o&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Inference service&lt;/td&gt;\n",
       "                &lt;td&gt;openai&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model parameters&lt;/td&gt;\n",
       "                &lt;td&gt;Model(model_name = &#x27;gpt-4o&#x27;, temperature = 0.5, max_tokens = 1000, top_p = 1, frequency_penalty = 0, presence_penalty = 0, logprobs = False, top_logprobs = 3)&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;User Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;\n",
       "Is the number you picked a prime number?\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\n",
       "        Before the question you are now answering, you already answered the following question(s):\n",
       "        \tQuestion: Pick a random number between 1 and 1,000.\n",
       "\tAnswer: 487&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;System Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Raw model response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Generated token string (at [&#x27;choices&#x27;, 0, &#x27;message&#x27;, &#x27;content&#x27;]) in raw response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "            &lt;td&gt;Code to (likely) reproduce the error&lt;/td&gt;\n",
       "            &lt;td&gt;\n",
       "                &lt;textarea id=&quot;codeToCopy&quot; rows=&quot;10&quot; cols=&quot;90&quot;&gt;from edsl import Question, Model, Scenario, Agent\n",
       "q = Question(&#x27;yes_no&#x27;, question_name = &quot;&quot;&quot;prime&quot;&quot;&quot;, question_text = &quot;&quot;&quot;Is the number you picked a prime number?&quot;&quot;&quot;, question_options = [&#x27;No&#x27;, &#x27;Yes&#x27;])\n",
       "scenario = Scenario({})\n",
       "agent = Agent(traits = {})\n",
       "m = Model(&#x27;gpt-4o&#x27;)\n",
       "results = q.by(m).by(agent).by(scenario).run()&lt;/textarea&gt;\n",
       "                &lt;button onclick=&quot;copyCode()&quot;&gt;Copy&lt;/button&gt;\n",
       "            &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "\n",
       "        &lt;/table&gt;\n",
       "\n",
       "        \n",
       "            \n",
       "\n",
       "            &lt;div class=&quot;exception-time&quot;&gt;Time: 2024-12-31T10:38:42.443561&lt;/div&gt;          \n",
       "            &lt;div class=&quot;exception-traceback&quot;&gt;Traceback: \n",
       "                &lt;text&gt;\n",
       "                &lt;pre&gt;Traceback (most recent call last):\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/AnswerQuestionFunctionConstructor.py&quot;, line 171, in attempt_answer\n",
       "    await invigilator.async_answer_question()\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 57, in async_answer_question\n",
       "    agent_response_dict = await self.async_get_agent_response()\n",
       "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 45, in async_get_agent_response\n",
       "    return await self.model.async_get_response(**params)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 460, in async_get_response\n",
       "    await self._async_get_intended_model_call_outcome(**params)\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 398, in _async_get_intended_model_call_outcome\n",
       "    response = await asyncio.wait_for(f(**params), timeout=TIMEOUT)\n",
       "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 479, in wait_for\n",
       "    return fut.result()\n",
       "           ^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/futures.py&quot;, line 203, in result\n",
       "    raise self._exception.with_traceback(self._exception_tb)\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 267, in __step\n",
       "    result = coro.send(None)\n",
       "             ^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/inference_services/OpenAIService.py&quot;, line 232, in async_execute_model_call\n",
       "    return response.model_dump()\n",
       "           ^^^^^^^^\n",
       "UnboundLocalError: cannot access local variable &#x27;response&#x27; where it is not associated with a value\n",
       "&lt;/pre&gt;\n",
       "                &lt;/text&gt;\n",
       "            &lt;/div&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "\n",
       "\n",
       "&lt;div class=&quot;exception-detail&quot;&gt;\n",
       "        &lt;div class=&quot;exception-header&quot;&gt;\n",
       "        &lt;span class=&quot;exception-exception&quot;&gt;Exception: UnboundLocalError(&quot;cannot access local variable &#x27;response&#x27; where it is not associated with a value&quot;)&lt;/span&gt;\n",
       "        &lt;button class=&quot;toggle-btn&quot;&gt;▼&lt;/button&gt;\n",
       "        &lt;/div&gt;\n",
       "        &lt;div class=&quot;exception-content&quot;&gt;\n",
       "        &lt;table border=&quot;1&quot;&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;th&gt;Key&lt;/th&gt;\n",
       "                &lt;th&gt;Value&lt;/th&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Interview ID (index in results)&lt;/td&gt;\n",
       "                &lt;td&gt;0&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question name (question_name)&lt;/td&gt;\n",
       "                &lt;td&gt;prime&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question type (question_type)&lt;/td&gt;\n",
       "                &lt;td&gt;yes_no&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Human-readable question&lt;/td&gt;\n",
       "                &lt;td&gt;\n",
       "        &lt;div id=&quot;prime&quot; class=&quot;survey_question&quot; data-type=&quot;yes_no&quot;&gt;\n",
       "            \n",
       "            &lt;p class=&quot;question_text&quot;&gt;Is the number you picked a prime number?&lt;/p&gt;\n",
       "            \n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;No&quot; name=&quot;prime&quot; value=&quot;No&quot;&gt;\n",
       "        &lt;label for=&quot;No&quot;&gt;\n",
       "        No\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;Yes&quot; name=&quot;prime&quot; value=&quot;Yes&quot;&gt;\n",
       "        &lt;label for=&quot;Yes&quot;&gt;\n",
       "        Yes\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "        \n",
       "        \n",
       "        &lt;/div&gt;\n",
       "        &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Scenario&lt;/td&gt;\n",
       "                &lt;td&gt;Scenario({&#x27;scenario_index&#x27;: 0})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Agent&lt;/td&gt;\n",
       "                &lt;td&gt;Agent(traits = {})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model name&lt;/td&gt;\n",
       "                &lt;td&gt;gpt-4o&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Inference service&lt;/td&gt;\n",
       "                &lt;td&gt;openai&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model parameters&lt;/td&gt;\n",
       "                &lt;td&gt;Model(model_name = &#x27;gpt-4o&#x27;, temperature = 0.5, max_tokens = 1000, top_p = 1, frequency_penalty = 0, presence_penalty = 0, logprobs = False, top_logprobs = 3)&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;User Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;\n",
       "Is the number you picked a prime number?\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\n",
       "        Before the question you are now answering, you already answered the following question(s):\n",
       "        \tQuestion: Pick a random number between 1 and 1,000.\n",
       "\tAnswer: 487&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;System Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Raw model response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Generated token string (at [&#x27;choices&#x27;, 0, &#x27;message&#x27;, &#x27;content&#x27;]) in raw response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "            &lt;td&gt;Code to (likely) reproduce the error&lt;/td&gt;\n",
       "            &lt;td&gt;\n",
       "                &lt;textarea id=&quot;codeToCopy&quot; rows=&quot;10&quot; cols=&quot;90&quot;&gt;from edsl import Question, Model, Scenario, Agent\n",
       "q = Question(&#x27;yes_no&#x27;, question_name = &quot;&quot;&quot;prime&quot;&quot;&quot;, question_text = &quot;&quot;&quot;Is the number you picked a prime number?&quot;&quot;&quot;, question_options = [&#x27;No&#x27;, &#x27;Yes&#x27;])\n",
       "scenario = Scenario({})\n",
       "agent = Agent(traits = {})\n",
       "m = Model(&#x27;gpt-4o&#x27;)\n",
       "results = q.by(m).by(agent).by(scenario).run()&lt;/textarea&gt;\n",
       "                &lt;button onclick=&quot;copyCode()&quot;&gt;Copy&lt;/button&gt;\n",
       "            &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "\n",
       "        &lt;/table&gt;\n",
       "\n",
       "        \n",
       "            \n",
       "\n",
       "            &lt;div class=&quot;exception-time&quot;&gt;Time: 2024-12-31T10:38:44.539648&lt;/div&gt;          \n",
       "            &lt;div class=&quot;exception-traceback&quot;&gt;Traceback: \n",
       "                &lt;text&gt;\n",
       "                &lt;pre&gt;Traceback (most recent call last):\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/AnswerQuestionFunctionConstructor.py&quot;, line 171, in attempt_answer\n",
       "    await invigilator.async_answer_question()\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 57, in async_answer_question\n",
       "    agent_response_dict = await self.async_get_agent_response()\n",
       "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 45, in async_get_agent_response\n",
       "    return await self.model.async_get_response(**params)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 460, in async_get_response\n",
       "    await self._async_get_intended_model_call_outcome(**params)\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 398, in _async_get_intended_model_call_outcome\n",
       "    response = await asyncio.wait_for(f(**params), timeout=TIMEOUT)\n",
       "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 479, in wait_for\n",
       "    return fut.result()\n",
       "           ^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/futures.py&quot;, line 203, in result\n",
       "    raise self._exception.with_traceback(self._exception_tb)\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 267, in __step\n",
       "    result = coro.send(None)\n",
       "             ^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/inference_services/OpenAIService.py&quot;, line 232, in async_execute_model_call\n",
       "    return response.model_dump()\n",
       "           ^^^^^^^^\n",
       "UnboundLocalError: cannot access local variable &#x27;response&#x27; where it is not associated with a value\n",
       "&lt;/pre&gt;\n",
       "                &lt;/text&gt;\n",
       "            &lt;/div&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "\n",
       "\n",
       "&lt;div class=&quot;exception-detail&quot;&gt;\n",
       "        &lt;div class=&quot;exception-header&quot;&gt;\n",
       "        &lt;span class=&quot;exception-exception&quot;&gt;Exception: UnboundLocalError(&quot;cannot access local variable &#x27;response&#x27; where it is not associated with a value&quot;)&lt;/span&gt;\n",
       "        &lt;button class=&quot;toggle-btn&quot;&gt;▼&lt;/button&gt;\n",
       "        &lt;/div&gt;\n",
       "        &lt;div class=&quot;exception-content&quot;&gt;\n",
       "        &lt;table border=&quot;1&quot;&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;th&gt;Key&lt;/th&gt;\n",
       "                &lt;th&gt;Value&lt;/th&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Interview ID (index in results)&lt;/td&gt;\n",
       "                &lt;td&gt;0&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question name (question_name)&lt;/td&gt;\n",
       "                &lt;td&gt;prime&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question type (question_type)&lt;/td&gt;\n",
       "                &lt;td&gt;yes_no&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Human-readable question&lt;/td&gt;\n",
       "                &lt;td&gt;\n",
       "        &lt;div id=&quot;prime&quot; class=&quot;survey_question&quot; data-type=&quot;yes_no&quot;&gt;\n",
       "            \n",
       "            &lt;p class=&quot;question_text&quot;&gt;Is the number you picked a prime number?&lt;/p&gt;\n",
       "            \n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;No&quot; name=&quot;prime&quot; value=&quot;No&quot;&gt;\n",
       "        &lt;label for=&quot;No&quot;&gt;\n",
       "        No\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;Yes&quot; name=&quot;prime&quot; value=&quot;Yes&quot;&gt;\n",
       "        &lt;label for=&quot;Yes&quot;&gt;\n",
       "        Yes\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "        \n",
       "        \n",
       "        &lt;/div&gt;\n",
       "        &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Scenario&lt;/td&gt;\n",
       "                &lt;td&gt;Scenario({&#x27;scenario_index&#x27;: 0})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Agent&lt;/td&gt;\n",
       "                &lt;td&gt;Agent(traits = {})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model name&lt;/td&gt;\n",
       "                &lt;td&gt;gpt-4o&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Inference service&lt;/td&gt;\n",
       "                &lt;td&gt;openai&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model parameters&lt;/td&gt;\n",
       "                &lt;td&gt;Model(model_name = &#x27;gpt-4o&#x27;, temperature = 0.5, max_tokens = 1000, top_p = 1, frequency_penalty = 0, presence_penalty = 0, logprobs = False, top_logprobs = 3)&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;User Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;\n",
       "Is the number you picked a prime number?\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\n",
       "        Before the question you are now answering, you already answered the following question(s):\n",
       "        \tQuestion: Pick a random number between 1 and 1,000.\n",
       "\tAnswer: 487&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;System Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Raw model response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Generated token string (at [&#x27;choices&#x27;, 0, &#x27;message&#x27;, &#x27;content&#x27;]) in raw response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "            &lt;td&gt;Code to (likely) reproduce the error&lt;/td&gt;\n",
       "            &lt;td&gt;\n",
       "                &lt;textarea id=&quot;codeToCopy&quot; rows=&quot;10&quot; cols=&quot;90&quot;&gt;from edsl import Question, Model, Scenario, Agent\n",
       "q = Question(&#x27;yes_no&#x27;, question_name = &quot;&quot;&quot;prime&quot;&quot;&quot;, question_text = &quot;&quot;&quot;Is the number you picked a prime number?&quot;&quot;&quot;, question_options = [&#x27;No&#x27;, &#x27;Yes&#x27;])\n",
       "scenario = Scenario({})\n",
       "agent = Agent(traits = {})\n",
       "m = Model(&#x27;gpt-4o&#x27;)\n",
       "results = q.by(m).by(agent).by(scenario).run()&lt;/textarea&gt;\n",
       "                &lt;button onclick=&quot;copyCode()&quot;&gt;Copy&lt;/button&gt;\n",
       "            &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "\n",
       "        &lt;/table&gt;\n",
       "\n",
       "        \n",
       "            \n",
       "\n",
       "            &lt;div class=&quot;exception-time&quot;&gt;Time: 2024-12-31T10:38:48.621712&lt;/div&gt;          \n",
       "            &lt;div class=&quot;exception-traceback&quot;&gt;Traceback: \n",
       "                &lt;text&gt;\n",
       "                &lt;pre&gt;Traceback (most recent call last):\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/AnswerQuestionFunctionConstructor.py&quot;, line 171, in attempt_answer\n",
       "    await invigilator.async_answer_question()\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 57, in async_answer_question\n",
       "    agent_response_dict = await self.async_get_agent_response()\n",
       "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 45, in async_get_agent_response\n",
       "    return await self.model.async_get_response(**params)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 460, in async_get_response\n",
       "    await self._async_get_intended_model_call_outcome(**params)\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 398, in _async_get_intended_model_call_outcome\n",
       "    response = await asyncio.wait_for(f(**params), timeout=TIMEOUT)\n",
       "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 479, in wait_for\n",
       "    return fut.result()\n",
       "           ^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/futures.py&quot;, line 203, in result\n",
       "    raise self._exception.with_traceback(self._exception_tb)\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 267, in __step\n",
       "    result = coro.send(None)\n",
       "             ^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/inference_services/OpenAIService.py&quot;, line 232, in async_execute_model_call\n",
       "    return response.model_dump()\n",
       "           ^^^^^^^^\n",
       "UnboundLocalError: cannot access local variable &#x27;response&#x27; where it is not associated with a value\n",
       "&lt;/pre&gt;\n",
       "                &lt;/text&gt;\n",
       "            &lt;/div&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "\n",
       "\n",
       "&lt;div class=&quot;exception-detail&quot;&gt;\n",
       "        &lt;div class=&quot;exception-header&quot;&gt;\n",
       "        &lt;span class=&quot;exception-exception&quot;&gt;Exception: UnboundLocalError(&quot;cannot access local variable &#x27;response&#x27; where it is not associated with a value&quot;)&lt;/span&gt;\n",
       "        &lt;button class=&quot;toggle-btn&quot;&gt;▼&lt;/button&gt;\n",
       "        &lt;/div&gt;\n",
       "        &lt;div class=&quot;exception-content&quot;&gt;\n",
       "        &lt;table border=&quot;1&quot;&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;th&gt;Key&lt;/th&gt;\n",
       "                &lt;th&gt;Value&lt;/th&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Interview ID (index in results)&lt;/td&gt;\n",
       "                &lt;td&gt;0&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question name (question_name)&lt;/td&gt;\n",
       "                &lt;td&gt;prime&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question type (question_type)&lt;/td&gt;\n",
       "                &lt;td&gt;yes_no&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Human-readable question&lt;/td&gt;\n",
       "                &lt;td&gt;\n",
       "        &lt;div id=&quot;prime&quot; class=&quot;survey_question&quot; data-type=&quot;yes_no&quot;&gt;\n",
       "            \n",
       "            &lt;p class=&quot;question_text&quot;&gt;Is the number you picked a prime number?&lt;/p&gt;\n",
       "            \n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;No&quot; name=&quot;prime&quot; value=&quot;No&quot;&gt;\n",
       "        &lt;label for=&quot;No&quot;&gt;\n",
       "        No\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;Yes&quot; name=&quot;prime&quot; value=&quot;Yes&quot;&gt;\n",
       "        &lt;label for=&quot;Yes&quot;&gt;\n",
       "        Yes\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "        \n",
       "        \n",
       "        &lt;/div&gt;\n",
       "        &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Scenario&lt;/td&gt;\n",
       "                &lt;td&gt;Scenario({&#x27;scenario_index&#x27;: 0})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Agent&lt;/td&gt;\n",
       "                &lt;td&gt;Agent(traits = {})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model name&lt;/td&gt;\n",
       "                &lt;td&gt;gpt-4o&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Inference service&lt;/td&gt;\n",
       "                &lt;td&gt;openai&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model parameters&lt;/td&gt;\n",
       "                &lt;td&gt;Model(model_name = &#x27;gpt-4o&#x27;, temperature = 0.5, max_tokens = 1000, top_p = 1, frequency_penalty = 0, presence_penalty = 0, logprobs = False, top_logprobs = 3)&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;User Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;\n",
       "Is the number you picked a prime number?\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\n",
       "        Before the question you are now answering, you already answered the following question(s):\n",
       "        \tQuestion: Pick a random number between 1 and 1,000.\n",
       "\tAnswer: 487&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;System Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Raw model response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Generated token string (at [&#x27;choices&#x27;, 0, &#x27;message&#x27;, &#x27;content&#x27;]) in raw response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "            &lt;td&gt;Code to (likely) reproduce the error&lt;/td&gt;\n",
       "            &lt;td&gt;\n",
       "                &lt;textarea id=&quot;codeToCopy&quot; rows=&quot;10&quot; cols=&quot;90&quot;&gt;from edsl import Question, Model, Scenario, Agent\n",
       "q = Question(&#x27;yes_no&#x27;, question_name = &quot;&quot;&quot;prime&quot;&quot;&quot;, question_text = &quot;&quot;&quot;Is the number you picked a prime number?&quot;&quot;&quot;, question_options = [&#x27;No&#x27;, &#x27;Yes&#x27;])\n",
       "scenario = Scenario({})\n",
       "agent = Agent(traits = {})\n",
       "m = Model(&#x27;gpt-4o&#x27;)\n",
       "results = q.by(m).by(agent).by(scenario).run()&lt;/textarea&gt;\n",
       "                &lt;button onclick=&quot;copyCode()&quot;&gt;Copy&lt;/button&gt;\n",
       "            &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "\n",
       "        &lt;/table&gt;\n",
       "\n",
       "        \n",
       "            \n",
       "\n",
       "            &lt;div class=&quot;exception-time&quot;&gt;Time: 2024-12-31T10:38:56.753101&lt;/div&gt;          \n",
       "            &lt;div class=&quot;exception-traceback&quot;&gt;Traceback: \n",
       "                &lt;text&gt;\n",
       "                &lt;pre&gt;Traceback (most recent call last):\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/AnswerQuestionFunctionConstructor.py&quot;, line 171, in attempt_answer\n",
       "    await invigilator.async_answer_question()\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 57, in async_answer_question\n",
       "    agent_response_dict = await self.async_get_agent_response()\n",
       "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/agents/Invigilator.py&quot;, line 45, in async_get_agent_response\n",
       "    return await self.model.async_get_response(**params)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 460, in async_get_response\n",
       "    await self._async_get_intended_model_call_outcome(**params)\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/language_models/LanguageModel.py&quot;, line 398, in _async_get_intended_model_call_outcome\n",
       "    response = await asyncio.wait_for(f(**params), timeout=TIMEOUT)\n",
       "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 479, in wait_for\n",
       "    return fut.result()\n",
       "           ^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/futures.py&quot;, line 203, in result\n",
       "    raise self._exception.with_traceback(self._exception_tb)\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 267, in __step\n",
       "    result = coro.send(None)\n",
       "             ^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/inference_services/OpenAIService.py&quot;, line 232, in async_execute_model_call\n",
       "    return response.model_dump()\n",
       "           ^^^^^^^^\n",
       "UnboundLocalError: cannot access local variable &#x27;response&#x27; where it is not associated with a value\n",
       "&lt;/pre&gt;\n",
       "                &lt;/text&gt;\n",
       "            &lt;/div&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "\n",
       "\n",
       "&lt;div class=&quot;exception-detail&quot;&gt;\n",
       "        &lt;div class=&quot;exception-header&quot;&gt;\n",
       "        &lt;span class=&quot;exception-exception&quot;&gt;Exception: LanguageModelNoResponseError(&quot;Language model did not return a response for question &#x27;prime.&#x27;&quot;)&lt;/span&gt;\n",
       "        &lt;button class=&quot;toggle-btn&quot;&gt;▼&lt;/button&gt;\n",
       "        &lt;/div&gt;\n",
       "        &lt;div class=&quot;exception-content&quot;&gt;\n",
       "        &lt;table border=&quot;1&quot;&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;th&gt;Key&lt;/th&gt;\n",
       "                &lt;th&gt;Value&lt;/th&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Interview ID (index in results)&lt;/td&gt;\n",
       "                &lt;td&gt;0&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question name (question_name)&lt;/td&gt;\n",
       "                &lt;td&gt;prime&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Question type (question_type)&lt;/td&gt;\n",
       "                &lt;td&gt;yes_no&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       " \n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Human-readable question&lt;/td&gt;\n",
       "                &lt;td&gt;\n",
       "        &lt;div id=&quot;prime&quot; class=&quot;survey_question&quot; data-type=&quot;yes_no&quot;&gt;\n",
       "            \n",
       "            &lt;p class=&quot;question_text&quot;&gt;Is the number you picked a prime number?&lt;/p&gt;\n",
       "            \n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;No&quot; name=&quot;prime&quot; value=&quot;No&quot;&gt;\n",
       "        &lt;label for=&quot;No&quot;&gt;\n",
       "        No\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "         \n",
       "        &lt;div&gt;\n",
       "        &lt;input type=&quot;radio&quot; id=&quot;Yes&quot; name=&quot;prime&quot; value=&quot;Yes&quot;&gt;\n",
       "        &lt;label for=&quot;Yes&quot;&gt;\n",
       "        Yes\n",
       "        \n",
       "        &lt;/label&gt;\n",
       "        &lt;/div&gt;\n",
       "        \n",
       "        \n",
       "        &lt;/div&gt;\n",
       "        &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Scenario&lt;/td&gt;\n",
       "                &lt;td&gt;Scenario({&#x27;scenario_index&#x27;: 0})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Agent&lt;/td&gt;\n",
       "                &lt;td&gt;Agent(traits = {})&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model name&lt;/td&gt;\n",
       "                &lt;td&gt;gpt-4o&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Inference service&lt;/td&gt;\n",
       "                &lt;td&gt;openai&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Model parameters&lt;/td&gt;\n",
       "                &lt;td&gt;Model(model_name = &#x27;gpt-4o&#x27;, temperature = 0.5, max_tokens = 1000, top_p = 1, frequency_penalty = 0, presence_penalty = 0, logprobs = False, top_logprobs = 3)&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;User Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;\n",
       "Is the number you picked a prime number?\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\n",
       "        Before the question you are now answering, you already answered the following question(s):\n",
       "        \tQuestion: Pick a random number between 1 and 1,000.\n",
       "\tAnswer: None&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;System Prompt&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;&lt;/pre&gt;&lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Raw model response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "                &lt;td&gt;Generated token string (at [&#x27;choices&#x27;, 0, &#x27;message&#x27;, &#x27;content&#x27;]) in raw response&lt;/td&gt;\n",
       "                &lt;td&gt;&lt;pre&gt;No raw model response available.&lt;/pre&gt;\n",
       "                &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "            &lt;tr&gt;\n",
       "            &lt;td&gt;Code to (likely) reproduce the error&lt;/td&gt;\n",
       "            &lt;td&gt;\n",
       "                &lt;textarea id=&quot;codeToCopy&quot; rows=&quot;10&quot; cols=&quot;90&quot;&gt;from edsl import Question, Model, Scenario, Agent\n",
       "q = Question(&#x27;yes_no&#x27;, question_name = &quot;&quot;&quot;prime&quot;&quot;&quot;, question_text = &quot;&quot;&quot;Is the number you picked a prime number?&quot;&quot;&quot;, question_options = [&#x27;No&#x27;, &#x27;Yes&#x27;])\n",
       "scenario = Scenario({})\n",
       "agent = Agent(traits = {})\n",
       "m = Model(&#x27;gpt-4o&#x27;)\n",
       "results = q.by(m).by(agent).by(scenario).run()&lt;/textarea&gt;\n",
       "                &lt;button onclick=&quot;copyCode()&quot;&gt;Copy&lt;/button&gt;\n",
       "            &lt;/td&gt;\n",
       "            &lt;/tr&gt;\n",
       "\n",
       "        &lt;/table&gt;\n",
       "\n",
       "        \n",
       "            \n",
       "\n",
       "            &lt;div class=&quot;exception-time&quot;&gt;Time: 2024-12-31T10:38:56.762070&lt;/div&gt;          \n",
       "            &lt;div class=&quot;exception-traceback&quot;&gt;Traceback: \n",
       "                &lt;text&gt;\n",
       "                &lt;pre&gt;Traceback (most recent call last):\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/interviews/Interview.py&quot;, line 315, in handle_task\n",
       "    result = task.result()\n",
       "             ^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/futures.py&quot;, line 203, in result\n",
       "    raise self._exception.with_traceback(self._exception_tb)\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py&quot;, line 267, in __step\n",
       "    result = coro.send(None)\n",
       "             ^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/tasks/QuestionTaskCreator.py&quot;, line 238, in _run_task_async\n",
       "    return await self._run_focal_task()\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/tasks/QuestionTaskCreator.py&quot;, line 144, in _run_focal_task\n",
       "    raise e\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/tasks/QuestionTaskCreator.py&quot;, line 138, in _run_focal_task\n",
       "    results = await self.answer_question_func(\n",
       "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/AnswerQuestionFunctionConstructor.py&quot;, line 217, in answer_question_and_record_task\n",
       "    return await attempt_answer()\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py&quot;, line 189, in async_wrapped\n",
       "    return await copy(fn, *args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py&quot;, line 111, in __call__\n",
       "    do = await self.iter(retry_state=retry_state)\n",
       "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py&quot;, line 153, in iter\n",
       "    result = await action(retry_state)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/tenacity/_utils.py&quot;, line 99, in inner\n",
       "    return call(*args, **kwargs)\n",
       "           ^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/tenacity/__init__.py&quot;, line 418, in exc_check\n",
       "    raise retry_exc.reraise()\n",
       "          ^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/tenacity/__init__.py&quot;, line 185, in reraise\n",
       "    raise self.last_attempt.result()\n",
       "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/concurrent/futures/_base.py&quot;, line 449, in result\n",
       "    return self.__get_result()\n",
       "           ^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/.pyenv/versions/3.11.0/lib/python3.11/concurrent/futures/_base.py&quot;, line 401, in __get_result\n",
       "    raise self._exception\n",
       "  File &quot;/Users/johnhorton/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/tenacity/asyncio/__init__.py&quot;, line 114, in __call__\n",
       "    result = await fn(*args, **kwargs)\n",
       "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "  File &quot;/Users/johnhorton/tools/edsl/edsl/jobs/AnswerQuestionFunctionConstructor.py&quot;, line 204, in attempt_answer\n",
       "    raise LanguageModelNoResponseError(\n",
       "edsl.exceptions.language_models.LanguageModelNoResponseError: Language model did not return a response for question &#x27;prime.&#x27;\n",
       "&lt;/pre&gt;\n",
       "                &lt;/text&gt;\n",
       "            &lt;/div&gt;\n",
       "        &lt;/div&gt;\n",
       "    &lt;/div&gt;\n",
       "\n",
       "\n",
       "        \n",
       "                \n",
       "\n",
       "    &lt;h1&gt;Performance Plot&lt;/h1&gt;\n",
       "\n",
       "&lt;/body&gt;\n",
       "&lt;/html&gt;\" style=\"width: 800px; height: 600px;\"></iframe>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Also see: https://docs.expectedparrot.com/en/latest/exceptions.html\n"
     ]
    }
   ],
   "source": [
    "from edsl import QuestionNumerical, QuestionYesNo, Survey\n",
    "\n",
    "q1 = QuestionNumerical(\n",
    "    question_name = \"random_number\",\n",
    "    question_text = \"Pick a random number between 1 and 1,000.\"\n",
    ")\n",
    "\n",
    "q2 = QuestionYesNo(\n",
    "    question_name = \"prime\",\n",
    "    question_text = \"Is the number you picked a prime number?\"\n",
    ")\n",
    "\n",
    "survey = Survey([q1, q2]).add_targeted_memory(q2, q1)\n",
    "\n",
    "results = survey.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b324e-0bee-459d-8b1b-9d554ec44ec3",
   "metadata": {},
   "source": [
    "We can again use the `user_prompt` to verify the context that was added to the follow-on question. To view the results in a long table, we can call the `table()` and `long()` methods to modify the default table view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c6f348e-4c89-46db-a6f6-26389246f69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"max-height: 500px; overflow-y: auto;\">\n",
       "                <style type=\"text/css\">\n",
       "#T_353b8_row0_col0, #T_353b8_row1_col0, #T_353b8_row2_col0, #T_353b8_row3_col0 {\n",
       "  text-align: left;\n",
       "  background-color: #fff7fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_353b8_row0_col1, #T_353b8_row0_col2, #T_353b8_row1_col1, #T_353b8_row1_col2, #T_353b8_row2_col1, #T_353b8_row2_col2, #T_353b8_row3_col1, #T_353b8_row3_col2 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_353b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_353b8_level0_col0\" class=\"col_heading level0 col0\" >row</th>\n",
       "      <th id=\"T_353b8_level0_col1\" class=\"col_heading level0 col1\" >key</th>\n",
       "      <th id=\"T_353b8_level0_col2\" class=\"col_heading level0 col2\" >value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_353b8_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_353b8_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_353b8_row0_col1\" class=\"data row0 col1\" >answer.random_number</td>\n",
       "      <td id=\"T_353b8_row0_col2\" class=\"data row0 col2\" >487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_353b8_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_353b8_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_353b8_row1_col1\" class=\"data row1 col1\" >prompt.prime_user_prompt</td>\n",
       "      <td id=\"T_353b8_row1_col2\" class=\"data row1 col2\" >\n",
       "Is the number you picked a prime number?\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\n",
       "        Before the question you are now answering, you already answered the following question(s):\n",
       "        \tQuestion: Pick a random number between 1 and 1,000.\n",
       "\tAnswer: None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_353b8_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_353b8_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_353b8_row2_col1\" class=\"data row2 col1\" >answer.prime</td>\n",
       "      <td id=\"T_353b8_row2_col2\" class=\"data row2 col2\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_353b8_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_353b8_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_353b8_row3_col1\" class=\"data row3 col1\" >comment.prime_comment</td>\n",
       "      <td id=\"T_353b8_row3_col2\" class=\"data row3 col2\" >Task failed with exception: Language model did not return a response for question 'prime.'.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "  row  key                       value\n",
       "-----  ------------------------  -------------------------------------------------------------------------------------------\n",
       "    0  answer.random_number      487\n",
       "    0  prompt.prime_user_prompt  Is the number you picked a prime number?\n",
       "\n",
       "    \n",
       "No\n",
       "    \n",
       "Yes\n",
       "    \n",
       "\n",
       "Only 1 option may be selected.\n",
       "Please respond with just your answer. \n",
       "\n",
       "\n",
       "After the answer, you can put a comment explaining your response.\n",
       "        Before the question you are now answering, you already answered the following question(s):\n",
       "        \tQuestion: Pick a random number between 1 and 1,000.\n",
       "\tAnswer: None\n",
       "    0  answer.prime\n",
       "    0  comment.prime_comment     Task failed with exception: Language model did not return a response for question 'prime.'."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.select(\"random_number\", \"prime_user_prompt\", \"prime\", \"prime_comment\").table().long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b9ad5-f511-4bb3-845c-9623897f90bc",
   "metadata": {},
   "source": [
    "*Related topic: Learn more about exploring and simulating \"randomness\" with AI agents and LLMs in [this notebook](https://docs.expectedparrot.com/en/latest/notebooks/random_numbers.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45e671-d63c-43bf-9a69-210aa171fa48",
   "metadata": {},
   "source": [
    "## Scenarios\n",
    "We can also add external data or content to survey questions.\n",
    "This can be useful when you want to efficiently create and administer multiple versions of questions at once, e.g., for conducting data labeling tasks.\n",
    "This is done by creating `Scenario` dictionaries for the data or content to be used with a survey, where the keys match `{{ placeholder }}` names used in question texts (or question options) and the values are the content to be added.\n",
    "Scenarios can also be used to [add metadata to survey results](https://docs.expectedparrot.com/en/latest/notebooks/adding_metadata.html), e.g., data sources or other information that you may want to include in the results for reference but not necessarily include in question texts.\n",
    "\n",
    "In the next example we revise the prior survey questions about reading to take a parameter for other activities that we may want to add to the questions, and create simple scenarios for some activities.\n",
    "EDSL provides methods for automatically generating scenarios from a variety of data sources, including PDFs, CSVs, docs, images, tables and dicts. \n",
    "We use the `from_list` method to convert a list of activities into scenarios.\n",
    "\n",
    "Then we demonstrate how to use scenarios to create multiple versions of our questions either (i) when constructing a survey or (ii) when running it:\n",
    "\n",
    "* In the latter case, the `by` method is used to add scenarios to a survey of questions with placeholders at the time that it is run (the same way that agents and models are added to a survey). This adds a `scenario` column to the results with a row for each answer to each question for each scenario.\n",
    "* In the former case, the `loop` method is used to create a list of versions of a question with the scenarios already added to it; when the questions are passed to a survey and it is run, the results include columns for each individual question; there is no `scenario` column and a single row for each agent's answers to all the questions.\n",
    "\n",
    "Learn more about [using scenarios](https://docs.expectedparrot.com/en/latest/scenarios.html).\n",
    "\n",
    "Here we create scenarios for a simple list of activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ca889fe-9dfd-4ef4-b324-16493b3e1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import ScenarioList, Scenario\n",
    "\n",
    "scenarios = ScenarioList.from_list(\"activity\", [\"reading\", \"running\", \"relaxing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c2951-93e3-4b40-83d0-d319ec14803a",
   "metadata": {},
   "source": [
    "### Adding scenarios using the `by` method\n",
    "Here we add the scenarios to the survey when we run it, together with any desired agents and models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0e3e7b3-36b3-4db6-b8fb-6f9abfbd3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import QuestionLinearScale, QuestionFreeText, Survey\n",
    "\n",
    "q_enjoy = QuestionLinearScale(\n",
    "    question_name = \"enjoy\",\n",
    "    question_text = \"On a scale from 1 to 5, how much do you enjoy {{ activity }}?\",\n",
    "    question_options = [1, 2, 3, 4, 5],\n",
    "    option_labels = {1:\"Not at all\", 5:\"Very much\"}\n",
    ")\n",
    "\n",
    "q_favorite_place = QuestionFreeText(\n",
    "    question_name = \"favorite_place\",\n",
    "    question_text = \"In a brief sentence, describe your favorite place for {{ activity }}.\"\n",
    ")\n",
    "\n",
    "survey = Survey([q_enjoy, q_favorite_place])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b10a27-e227-4502-b4c3-74e10e54a1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msurvey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscenarios\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m(\u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tools/edsl/edsl/jobs/Jobs.py:84\u001b[0m, in \u001b[0;36mwith_config.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m parameters \u001b[38;5;241m=\u001b[39m RunParameters(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m parameter_fields}\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m RunConfig(environment\u001b[38;5;241m=\u001b[39menvironment, parameters\u001b[38;5;241m=\u001b[39mparameters)\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tools/edsl/edsl/jobs/Jobs.py:611\u001b[0m, in \u001b[0;36mJobs.run\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03mRuns the Job: conducts Interviews and returns their results.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m:param key_lookup: A KeyLookup object to manage API keys\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(config)\n\u001b[0;32m--> 611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_with_remote_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_job_async\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:133\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m curr_task \u001b[38;5;241m=\u001b[39m curr_tasks\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# restore the current task\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m curr_task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/asyncio/events.py:80\u001b[0m, in \u001b[0;36mHandle._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/asyncio/tasks.py:267\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/tools/edsl/edsl/jobs/Jobs.py:522\u001b[0m, in \u001b[0;36mJobs._execute_with_remote_cache\u001b[0;34m(self, run_job_async)\u001b[0m\n\u001b[1;32m    520\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mparameters)\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 522\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/tools/edsl/edsl/utilities/decorators.py:62\u001b[0m, in \u001b[0;36mjupyter_nb_handler.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# If the loop is running, schedule the coroutine and wait for the result\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(async_wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# If the loop is not running, run the coroutine to completion\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mrun(async_wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/edsl-vI1bCg78-py3.11/lib/python3.11/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/selectors.py:561\u001b[0m, in \u001b[0;36mKqueueSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 561\u001b[0m     kev_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mcontrol(\u001b[38;5;28;01mNone\u001b[39;00m, max_ev, timeout)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "Error code: 401 - {'error': {'message': 'Incorrect API key provided: your_key*here. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exceptions were raised in 18 interviews.\n",
      "Exceptions were raised in the following interviews: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception report saved to /Users/johnhorton/tools/edsl/docs/notebooks/tmptgj65x6_.html\n",
      "Also see: https://docs.expectedparrot.com/en/latest/exceptions.html\n"
     ]
    }
   ],
   "source": [
    "results = survey.by(scenarios).by(agents).by(models).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f842a00-0069-43e6-ab2a-8dab6acf9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    results\n",
    "    .filter(\"model.model == 'gpt-4o'\")\n",
    "    .sort_by(\"activity\", \"persona\")\n",
    "    .select(\"activity\", \"persona\", \"enjoy\", \"favorite_place\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7d9fc-1aff-4ecc-af53-de85a5846f2f",
   "metadata": {},
   "source": [
    "### Adding scenarios using the `loop` method\n",
    "Here we add scenarios to questions when constructing a survey, as opposed to when running it.\n",
    "When we run the survey the results will include columns for each question and no `scenario` field. \n",
    "Note that we can also optionally use the scenario key in the question names (they are otherwise incremented by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b02a99-069f-4207-a6bc-6755705ea1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import QuestionLinearScale, QuestionFreeText\n",
    "\n",
    "q_enjoy = QuestionLinearScale(\n",
    "    question_name = \"enjoy_{{ activity }}\", # optional use of scenario key\n",
    "    question_text = \"On a scale from 1 to 5, how much do you enjoy {{ activity }}?\",\n",
    "    question_options = [1, 2, 3, 4, 5],\n",
    "    option_labels = {1:\"Not at all\", 5:\"Very much\"}\n",
    ")\n",
    "\n",
    "q_favorite_place = QuestionFreeText(\n",
    "    question_name = \"favorite_place_{{ activity }}\", # optional use of scenario key\n",
    "    question_text = \"In a brief sentence, describe your favorite place for {{ activity }}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa44ae7d-864d-4e6a-a5fc-e311e573f17b",
   "metadata": {},
   "source": [
    "Looping the scenarios to create lists of questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69c2a7-e8a2-4d59-bc66-ef82efee7464",
   "metadata": {},
   "outputs": [],
   "source": [
    "enjoy_questions = q_enjoy.loop(scenarios)\n",
    "enjoy_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5ad41-5e63-42b4-8ee8-a0591b67f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_place_questions = q_favorite_place.loop(scenarios)\n",
    "favorite_place_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6310b-bef0-4ec1-8d4b-da04e4228797",
   "metadata": {},
   "source": [
    "Combining the questions in a survey:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84d7a5-31c8-4e54-a1a0-7b3400677fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = Survey(questions = enjoy_questions + favorite_place_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab32a1-fe39-4593-bf65-f7cf83d56d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = survey.by(agents).by(models).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeb465f-2484-4b19-b09d-dbc159ce1142",
   "metadata": {},
   "source": [
    "We can see that there are additional question fields and no \"scenario\" field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c75551c-2e77-49e1-94c6-bec7b3f34db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd31a1-e28c-435c-bc36-f236c3435993",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    results\n",
    "    .filter(\"model.model == 'gpt-4o'\")\n",
    "    .sort_by(\"persona\")\n",
    "    .select(\"persona\", \"enjoy_reading\", \"enjoy_running\", \"enjoy_relaxing\", \"favorite_place_reading\", \"favorite_place_running\", \"favorite_place_relaxing\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f74b3a-7253-4798-9638-82ac925db122",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exploring `Results`\n",
    "EDSL comes with [built-in methods for analyzing and visualizing survey results](https://docs.expectedparrot.com/en/latest/language_models.html). \n",
    "For example, you can call the `to_pandas` method to convert results into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2cc32-015c-49bc-8e53-cc1c70f6d783",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = results.to_pandas(remove_prefix=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e783239-1b4c-44d2-8f1f-ef56a62bd25c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The `Results` object also supports SQL-like queries with the the `sql` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdca6c4-0ef6-4daa-ae4f-8b9bdd4a9043",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results.sql(\"\"\"\n",
    "select model, persona, enjoy_reading, favorite_place_reading\n",
    "from self\n",
    "order by 1,2,3\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e526c294-d9f9-43a1-bc9a-16c635c5f2df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Posting to the Coop\n",
    "The [Coop](https://www.expectedparrot.com/content/explore) is a platform for creating, storing and sharing LLM-based research.\n",
    "It is fully integrated with EDSL and accessible from your workspace or Coop account page.\n",
    "Learn more about [creating an account](https://www.expectedparrot.com/login) and [using the Coop](https://docs.expectedparrot.com/en/latest/coop.html).\n",
    "\n",
    "We can post any EDSL object to the Coop by call the `push` method on it, optionally passing a `description` and `visibility` status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9233b-5ddc-4850-8ec9-6dd2d6647ecc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "results.push(description = \"Starter tutorial sample survey results\", visibility=\"public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8002060-2836-4fdd-bfa4-9d011fd84de8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can also post this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75c830-7867-4831-b992-89e1b5e1eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl import Notebook\n",
    "\n",
    "notebook = Notebook(path=\"starter_tutorial.ipynb\")\n",
    "\n",
    "info = notebook.push(description=\"Starter Tutorial\", visibility=\"public\")\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e90364-e9f3-483d-b301-4ab5178dd151",
   "metadata": {},
   "source": [
    "To update an object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df857af0-4d0b-4b49-9271-e660080d8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook = Notebook(path=\"starter_tutorial.ipynb\") # resave\n",
    "\n",
    "notebook.patch(uuid = info[\"uuid\"], value = notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
