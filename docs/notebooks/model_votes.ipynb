{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d4d5c2583fc14fdb895e689f40ba6737",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Comparing model responses\n",
    "This notebook provides sample [EDSL](https://docs.expectedparrot.com/en/latest/) code for comparing content created by different language models and examining how models rate their own content versus content created by other models. \n",
    "\n",
    "In a series of steps we use surveys to prompt models to generate some content and then evaluate each piece of content, and then analyze the results as datasets.\n",
    "\n",
    "Before running this notebook please see details on [installing EDSL](https://docs.expectedparrot.com/en/latest/installation.html) and [getting started](https://docs.expectedparrot.com/en/latest/tutorial_getting_started.html) using the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "83ac608cf73d49f2a35d9cf45c2b7c75",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# ! pip install edsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating content\n",
    "We start by constructing a question that will prompt a language model to generate some content. EDSL comes with a variety of standard question types (multiple choice, free text, etc.) that we can select based on the desired format of the response. See [examples of all question types](https://docs.expectedparrot.com/en/latest/questions.html#question-type-classes). Here we use `QuestionFreeText` to generate some text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "1325605571cc41a194255b80b2fb2f87",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from edsl.questions import QuestionFreeText\n",
    "\n",
    "q_content = QuestionFreeText(\n",
    "    question_name = \"content\",\n",
    "    question_text = \"Draft a sentence summarizing best practices for conducting research with large language models.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting language models\n",
    "Next we can select language models to answer the question. We can check a current list of available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "4fa4d5aa948642b1972b84993e35f685",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 205,
    "execution_start": 1709310900433,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['01-ai/Yi-34B-Chat', 'deep_infra', 0],\n",
       " ['Austism/chronos-hermes-13b-v2', 'deep_infra', 1],\n",
       " ['Gryphe/MythoMax-L2-13b', 'deep_infra', 2],\n",
       " ['Gryphe/MythoMax-L2-13b-turbo', 'deep_infra', 3],\n",
       " ['HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1', 'deep_infra', 4],\n",
       " ['Phind/Phind-CodeLlama-34B-v2', 'deep_infra', 5],\n",
       " ['bigcode/starcoder2-15b', 'deep_infra', 6],\n",
       " ['bigcode/starcoder2-15b-instruct-v0.1', 'deep_infra', 7],\n",
       " ['claude-3-haiku-20240307', 'anthropic', 8],\n",
       " ['claude-3-opus-20240229', 'anthropic', 9],\n",
       " ['claude-3-sonnet-20240229', 'anthropic', 10],\n",
       " ['codellama/CodeLlama-34b-Instruct-hf', 'deep_infra', 11],\n",
       " ['codellama/CodeLlama-70b-Instruct-hf', 'deep_infra', 12],\n",
       " ['cognitivecomputations/dolphin-2.6-mixtral-8x7b', 'deep_infra', 13],\n",
       " ['databricks/dbrx-instruct', 'deep_infra', 14],\n",
       " ['deepinfra/airoboros-70b', 'deep_infra', 15],\n",
       " ['gemini-pro', 'google', 16],\n",
       " ['google/codegemma-7b-it', 'deep_infra', 17],\n",
       " ['google/gemma-1.1-7b-it', 'deep_infra', 18],\n",
       " ['gpt-3.5-turbo', 'openai', 19],\n",
       " ['gpt-3.5-turbo-0125', 'openai', 20],\n",
       " ['gpt-3.5-turbo-0301', 'openai', 21],\n",
       " ['gpt-3.5-turbo-0613', 'openai', 22],\n",
       " ['gpt-3.5-turbo-1106', 'openai', 23],\n",
       " ['gpt-3.5-turbo-16k', 'openai', 24],\n",
       " ['gpt-3.5-turbo-16k-0613', 'openai', 25],\n",
       " ['gpt-3.5-turbo-instruct', 'openai', 26],\n",
       " ['gpt-3.5-turbo-instruct-0914', 'openai', 27],\n",
       " ['gpt-4', 'openai', 28],\n",
       " ['gpt-4-0125-preview', 'openai', 29],\n",
       " ['gpt-4-0613', 'openai', 30],\n",
       " ['gpt-4-1106-preview', 'openai', 31],\n",
       " ['gpt-4-1106-vision-preview', 'openai', 32],\n",
       " ['gpt-4-turbo', 'openai', 33],\n",
       " ['gpt-4-turbo-2024-04-09', 'openai', 34],\n",
       " ['gpt-4-turbo-preview', 'openai', 35],\n",
       " ['gpt-4-vision-preview', 'openai', 36],\n",
       " ['gpt-4o', 'openai', 37],\n",
       " ['gpt-4o-2024-05-13', 'openai', 38],\n",
       " ['lizpreciatior/lzlv_70b_fp16_hf', 'deep_infra', 39],\n",
       " ['llava-hf/llava-1.5-7b-hf', 'deep_infra', 40],\n",
       " ['meta-llama/Llama-2-13b-chat-hf', 'deep_infra', 41],\n",
       " ['meta-llama/Llama-2-70b-chat-hf', 'deep_infra', 42],\n",
       " ['meta-llama/Llama-2-7b-chat-hf', 'deep_infra', 43],\n",
       " ['meta-llama/Meta-Llama-3-70B-Instruct', 'deep_infra', 44],\n",
       " ['meta-llama/Meta-Llama-3-8B-Instruct', 'deep_infra', 45],\n",
       " ['microsoft/WizardLM-2-7B', 'deep_infra', 46],\n",
       " ['microsoft/WizardLM-2-8x22B', 'deep_infra', 47],\n",
       " ['mistralai/Mistral-7B-Instruct-v0.1', 'deep_infra', 48],\n",
       " ['mistralai/Mistral-7B-Instruct-v0.2', 'deep_infra', 49],\n",
       " ['mistralai/Mixtral-8x22B-Instruct-v0.1', 'deep_infra', 50],\n",
       " ['mistralai/Mixtral-8x22B-v0.1', 'deep_infra', 51],\n",
       " ['mistralai/Mixtral-8x7B-Instruct-v0.1', 'deep_infra', 52],\n",
       " ['openchat/openchat_3.5', 'deep_infra', 53]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edsl import Model\n",
    "\n",
    "Model.available() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cc1f7bddab344d378e8ce81dfea70a69",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "We select models to use by creating `Model` objects that we add to our question when we run it. (If we do not specify a model, GPT 4 preview will be used by default.) Here we select 4 models to use with our question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "747d40bea4eb41b5a89d8b374216837e",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "models = [Model(m) for m in ('gpt-3.5-turbo',\n",
    "                             'gpt-4',\n",
    "                             'gpt-4o',\n",
    "                             'gemini-pro',\n",
    "                             'claude-3-sonnet-20240229')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating responses\n",
    "We generate responses to questions by passing them to a `Survey` object, adding the models, and then calling the `run` method. This produces a `Results` object with a `Result` for set of responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "724ca2c7a38f4164a225ed4a8dcc2b1f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "from edsl import Survey \n",
    "\n",
    "# Pass a list of one ore more questions to be administered together in the survey \n",
    "survey = Survey([q_content]) \n",
    "\n",
    "# Run the survey with the models\n",
    "results = survey.by(models).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results include information about all the components of the response that we can analyze. We can see a list of these components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent.agent_instruction',\n",
       " 'agent.agent_name',\n",
       " 'answer.content',\n",
       " 'iteration.iteration',\n",
       " 'model.frequency_penalty',\n",
       " 'model.logprobs',\n",
       " 'model.maxOutputTokens',\n",
       " 'model.max_tokens',\n",
       " 'model.model',\n",
       " 'model.presence_penalty',\n",
       " 'model.stopSequences',\n",
       " 'model.temperature',\n",
       " 'model.topK',\n",
       " 'model.topP',\n",
       " 'model.top_logprobs',\n",
       " 'model.top_p',\n",
       " 'prompt.content_system_prompt',\n",
       " 'prompt.content_user_prompt',\n",
       " 'question_options.content_question_options',\n",
       " 'question_text.content_question_text',\n",
       " 'question_type.content_question_type',\n",
       " 'raw_model_response.content_raw_model_response']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with results\n",
    "EDSL comes with [built-in methods for analyzing results](https://docs.expectedparrot.com/en/latest/results.html) in data tables, dataframes and other formats. For example, we can select and print individual components in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "c68d3be8bada402ea17184b978abfa70",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> model                    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> answer                                                                               </span>┃\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .model                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .content                                                                             </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> When conducting research with large language models, it is important to clearly      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> define research goals, use diverse datasets for training, evaluate model performance </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> across various metrics, and ensure ethical considerations are addressed throughout   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> the research process.                                                                </span>│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4                    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Best practices for conducting research with large language models include ensuring   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> data quality and diversity, understanding model limitations, applying appropriate    </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> evaluation metrics, ethical considerations, and ongoing monitoring for model         </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> performance and bias mitigation.                                                     </span>│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4o                   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Best practices for conducting research with large language models include ensuring   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> data privacy, maintaining transparency in methodology, validating results through    </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> peer review, and considering ethical implications of the research outcomes.          </span>│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro               </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> When conducting research with large language models, it's important to use diverse   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> and representative datasets, carefully evaluate model outputs, and consider          </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> potential biases and limitations.                                                    </span>│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-sonnet-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> When conducting research with large language models, it is important to carefully    </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> curate the training data to avoid biases, establish clear guidelines for responsible </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> and ethical use, rigorously evaluate the model's outputs for accuracy and potential  </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> harms, and transparently communicate the model's capabilities and limitations.       </span>│\n",
       "└──────────────────────────┴──────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mmodel                   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35manswer                                                                              \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m.model                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m.content                                                                            \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo           \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mWhen conducting research with large language models, it is important to clearly     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdefine research goals, use diverse datasets for training, evaluate model performance\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2macross various metrics, and ensure ethical considerations are addressed throughout  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mthe research process.                                                               \u001b[0m\u001b[2m \u001b[0m│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4                   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mBest practices for conducting research with large language models include ensuring  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdata quality and diversity, understanding model limitations, applying appropriate   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mevaluation metrics, ethical considerations, and ongoing monitoring for model        \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mperformance and bias mitigation.                                                    \u001b[0m\u001b[2m \u001b[0m│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4o                  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mBest practices for conducting research with large language models include ensuring  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdata privacy, maintaining transparency in methodology, validating results through   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mpeer review, and considering ethical implications of the research outcomes.         \u001b[0m\u001b[2m \u001b[0m│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgemini-pro              \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mWhen conducting research with large language models, it's important to use diverse  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mand representative datasets, carefully evaluate model outputs, and consider         \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mpotential biases and limitations.                                                   \u001b[0m\u001b[2m \u001b[0m│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mclaude-3-sonnet-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mWhen conducting research with large language models, it is important to carefully   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mcurate the training data to avoid biases, establish clear guidelines for responsible\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mand ethical use, rigorously evaluate the model's outputs for accuracy and potential \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mharms, and transparently communicate the model's capabilities and limitations.      \u001b[0m\u001b[2m \u001b[0m│\n",
       "└──────────────────────────┴──────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.select(\"model\", \"content\").print(format=\"rich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we access them as a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>When conducting research with large language m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>Best practices for conducting research with la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>Best practices for conducting research with la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>When conducting research with large language m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-3-sonnet-20240229</td>\n",
       "      <td>When conducting research with large language m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model                                            content\n",
       "0             gpt-3.5-turbo  When conducting research with large language m...\n",
       "1                     gpt-4  Best practices for conducting research with la...\n",
       "2                    gpt-4o  Best practices for conducting research with la...\n",
       "3                gemini-pro  When conducting research with large language m...\n",
       "4  claude-3-sonnet-20240229  When conducting research with large language m..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_content = results.to_pandas(remove_prefix=True)[[\"model\", \"content\"]]\n",
    "df_model_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating models\n",
    "We can use the models' responses as options to a new question prompting the models to select the best response. Here we isolate the responses to the original question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When conducting research with large language models, it is important to clearly define research goals, use diverse datasets for training, evaluate model performance across various metrics, and ensure ethical considerations are addressed throughout the research process.',\n",
       " 'Best practices for conducting research with large language models include ensuring data quality and diversity, understanding model limitations, applying appropriate evaluation metrics, ethical considerations, and ongoing monitoring for model performance and bias mitigation.',\n",
       " 'Best practices for conducting research with large language models include ensuring data privacy, maintaining transparency in methodology, validating results through peer review, and considering ethical implications of the research outcomes.',\n",
       " \"When conducting research with large language models, it's important to use diverse and representative datasets, carefully evaluate model outputs, and consider potential biases and limitations.\",\n",
       " \"When conducting research with large language models, it is important to carefully curate the training data to avoid biases, establish clear guidelines for responsible and ethical use, rigorously evaluate the model's outputs for accuracy and potential harms, and transparently communicate the model's capabilities and limitations.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_options = results.select(\"content\").to_list()\n",
    "content_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we use them as `question_options` to a new question prompting the models to vote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edsl.questions import QuestionMultipleChoice\n",
    "\n",
    "q_best = QuestionMultipleChoice(\n",
    "    question_name = \"best\",\n",
    "    question_text = \"\"\"Select the best response to this prompt:\n",
    "    'Draft a sentence summarizing best practices for conducting research with large language models'\"\"\",\n",
    "    question_options = content_options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = q_best.by(models).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> model                    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> answer                                                                               </span>┃\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .model                   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> .best                                                                                </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-3.5-turbo            </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> When conducting research with large language models, it is important to carefully    </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> curate the training data to avoid biases, establish clear guidelines for responsible </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> and ethical use, rigorously evaluate the model's outputs for accuracy and potential  </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> harms, and transparently communicate the model's capabilities and limitations.       </span>│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4                    </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Best practices for conducting research with large language models include ensuring   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> data quality and diversity, understanding model limitations, applying appropriate    </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> evaluation metrics, ethical considerations, and ongoing monitoring for model         </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> performance and bias mitigation.                                                     </span>│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gpt-4o                   </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Best practices for conducting research with large language models include ensuring   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> data quality and diversity, understanding model limitations, applying appropriate    </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> evaluation metrics, ethical considerations, and ongoing monitoring for model         </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> performance and bias mitigation.                                                     </span>│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> gemini-pro               </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> When conducting research with large language models, it is important to clearly      </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> define research goals, use diverse datasets for training, evaluate model performance </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> across various metrics, and ensure ethical considerations are addressed throughout   </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> the research process.                                                                </span>│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> claude-3-sonnet-20240229 </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> When conducting research with large language models, it is important to carefully    </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> curate the training data to avoid biases, establish clear guidelines for responsible </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> and ethical use, rigorously evaluate the model's outputs for accuracy and potential  </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                          </span>│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> harms, and transparently communicate the model's capabilities and limitations.       </span>│\n",
       "└──────────────────────────┴──────────────────────────────────────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35mmodel                   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35manswer                                                                              \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m.model                  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m.best                                                                               \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-3.5-turbo           \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mWhen conducting research with large language models, it is important to carefully   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mcurate the training data to avoid biases, establish clear guidelines for responsible\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mand ethical use, rigorously evaluate the model's outputs for accuracy and potential \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mharms, and transparently communicate the model's capabilities and limitations.      \u001b[0m\u001b[2m \u001b[0m│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4                   \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mBest practices for conducting research with large language models include ensuring  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdata quality and diversity, understanding model limitations, applying appropriate   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mevaluation metrics, ethical considerations, and ongoing monitoring for model        \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mperformance and bias mitigation.                                                    \u001b[0m\u001b[2m \u001b[0m│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgpt-4o                  \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mBest practices for conducting research with large language models include ensuring  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdata quality and diversity, understanding model limitations, applying appropriate   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mevaluation metrics, ethical considerations, and ongoing monitoring for model        \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mperformance and bias mitigation.                                                    \u001b[0m\u001b[2m \u001b[0m│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mgemini-pro              \u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mWhen conducting research with large language models, it is important to clearly     \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mdefine research goals, use diverse datasets for training, evaluate model performance\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2macross various metrics, and ensure ethical considerations are addressed throughout  \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mthe research process.                                                               \u001b[0m\u001b[2m \u001b[0m│\n",
       "├──────────────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│\u001b[2m \u001b[0m\u001b[2mclaude-3-sonnet-20240229\u001b[0m\u001b[2m \u001b[0m│\u001b[2m \u001b[0m\u001b[2mWhen conducting research with large language models, it is important to carefully   \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mcurate the training data to avoid biases, establish clear guidelines for responsible\u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mand ethical use, rigorously evaluate the model's outputs for accuracy and potential \u001b[0m\u001b[2m \u001b[0m│\n",
       "│\u001b[2m                          \u001b[0m│\u001b[2m \u001b[0m\u001b[2mharms, and transparently communicate the model's capabilities and limitations.      \u001b[0m\u001b[2m \u001b[0m│\n",
       "└──────────────────────────┴──────────────────────────────────────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_results.select(\"model\", \"best\").print(format=\"rich\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing results\n",
    "Here we merge our results datasets to get a quick tally of votes for each model's content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>When conducting research with large language m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>Best practices for conducting research with la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>Best practices for conducting research with la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>When conducting research with large language m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude-3-sonnet-20240229</td>\n",
       "      <td>When conducting research with large language m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model                                               best\n",
       "0             gpt-3.5-turbo  When conducting research with large language m...\n",
       "1                     gpt-4  Best practices for conducting research with la...\n",
       "2                    gpt-4o  Best practices for conducting research with la...\n",
       "3                gemini-pro  When conducting research with large language m...\n",
       "4  claude-3-sonnet-20240229  When conducting research with large language m..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_content = best_results.to_pandas(remove_prefix=True)\n",
    "df_best_content = df_best_content[[\"model\", \"best\"]]\n",
    "df_best_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge these new results to see which models did best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model                                     Voters  Votes\n",
      "0  claude-3-sonnet-20240229  [gpt-3.5-turbo, claude-3-sonnet-20240229]      2\n",
      "3                     gpt-4                            [gpt-4, gpt-4o]      2\n",
      "2             gpt-3.5-turbo                               [gemini-pro]      1\n",
      "1                gemini-pro                                         []      0\n",
      "4                    gpt-4o                                         []      0\n"
     ]
    }
   ],
   "source": [
    "df_merged = df_model_content.merge(df_best_content, left_on='content', right_on='best', how='outer')\n",
    "\n",
    "df_aggregated = df_merged.groupby(df_merged['model_x']).agg({\n",
    "    'model_y': lambda x: list(x.dropna()),  \n",
    "}).reset_index()\n",
    "\n",
    "df_aggregated['Votes'] = df_aggregated['model_y'].apply(len)\n",
    "df_aggregated.columns = ['Model', 'Voters', 'Votes']\n",
    "df_aggregated = df_aggregated.sort_values(by='Votes', ascending=False)\n",
    "\n",
    "print(df_aggregated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure(figsize=(10, 6))  \n",
    "colors = ['green', 'red', 'blue', 'yellow', 'turquoise']  \n",
    "plt.bar(df_aggregated['Model'], df_aggregated['Votes'], color=colors)  \n",
    "plt.xlabel('Model')  \n",
    "plt.ylabel('Votes')  \n",
    "plt.title('Votes by model')  \n",
    "x_positions = range(len(df_aggregated['Model']))  \n",
    "plt.xticks(x_positions, [label.upper() for label in df_aggregated['Model']], rotation=0)  \n",
    "plt.gca().yaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6d1e666ba52649708894044c2a755567",
  "deepnote_persisted_session": {
   "createdAt": "2024-03-01T17:07:23.650Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
