.. _results:

Results
=======
A `Results` object is the result of running a survey. 
It is a list of individual `Result` objects, each of which represents a response to a `Survey` for each combination of `Agent`, `Model` and `Scenario` objects that were used with the survey.
For example, the `Results` of a survey administered to 2 agents and 2 models (with no question scenarios) will contain 4 individual `Result` objects.
If the survey questions are parameterized with 2 scenarios then 8 `Result` objects are generated.

A `Results` object is not typically instantiated directly, but is returned by calling the `run()` method of a survey after optionally specifying agents, models and scenarios. 
To inspect the form of an example `Results` we can call the `example()` method (it is long -- we show it at the end of this page):

.. code-block:: python

   from edsl import Results

   example_results = Results.example()


<i>Note: You must have API keys set up to generate results. Please see the :ref:`api_keys` section for instructions on storing your keys.</i>

For purposes of demonstrating how to unpack and interact with results, we'll use the following code to generate results for a simple survey.
Note that specifying agent traits, scenarios (question parameter values) and language models is optional, and we include those steps here for illustrative purposes:

.. code-block:: python

   # Create questions
   from edsl.questions import QuestionLinearScale, QuestionFreeText, QuestionYesNo

   q1 = QuestionLinearScale(
      question_name = "important",
      question_text = "How much do you care about {{ topic }}?",
      question_options = [0,1,2,3,4,5],
      option_labels = {0:"Not at all", 5:"A lot"}
   )

   q2 = QuestionFreeText(
      question_name = "feel",
      question_text = "How do you feel about {{ topic }}?"
   )

   q3 = QuestionYesNo(
      question_name = "read",
      question_text = "Have you read any books about {{ topic }}?"
   )

   # Optionally parameterize the questions with scenarios
   from edsl import Scenario

   scenarios = [Scenario({"topic": t}) for t in ["climate change", "data privacy"]]

   # Optionally create agents with traits
   from edsl import Agent

   agents = [Agent(traits = {"persona": p}) for p in ["student", "celebrity"]]

   # Optionally specify language models
   from edsl import Model

   models = [Model(model) for model in ['gpt-4-0125-preview', 'gpt-3.5-turbo']]

   # Create a survey with the questions
   from edsl import Survey

   survey = Survey([q1, q2, q3])

   # Run the survey with the scenarios, agents and models
   results = survey.by(scenarios).by(agents).by(models).run()


For more details on each of the above steps, please see the relevant sections of the docs.


Result objects 
^^^^^^^^^^^^^^
We can check the number of `Result` objects created by inspecting the length of the `Results`:

.. code-block:: python

   len(results)

This will count 2 (scenarios) x 2 (agents) x 2 (models) = 8 `Result` objects:

.. code-block:: text

   8


Generating multiple results
^^^^^^^^^^^^^^^^^^^^^^^^^^^
If we want to generate multiple results for a survey--i.e., more than 1 result for each combination of `Agent`, `Model` and `Scenario` objects used--we can pass the desired number of iterations when calling the `run()` method.
For example, the following code will generate 3 results for our survey (n=3):

.. code-block:: python

   results = survey.by(scenarios).by(agents).by(models).run(n=3)


We can verify that the number of `Result` objects created is now 24 = 3 iterations x 2 scenarios x 2 agents x 2 models:

.. code-block:: python

   len(results)

.. code-block:: text

   24


We can readily inspect a result:

.. code-block:: python

   results[0]

.. code-block:: text
   

We can use the `rich_print` method to display the `Result` object in a more readable format:

.. code-block:: python

   results[0].rich_print()

.. code-block:: text


Results columns
^^^^^^^^^^^^^^^
Results contain components that can be accessed and analyzed individually or collectively.
We can see a list of these components by calling the `columns` method:

.. code-block:: python

   results.columns()


The following list will be returned for the results generated by the above code:

.. code-block:: text

   ['agent.agent_name',
   'agent.persona',
   'answer.feel',
   'answer.important',
   'answer.important_comment',
   'answer.read',
   'answer.read_comment',
   'iteration.iteration',
   'model.frequency_penalty',
   'model.logprobs',
   'model.max_tokens',
   'model.model',
   'model.presence_penalty',
   'model.temperature',
   'model.top_logprobs',
   'model.top_p',
   'prompt.feel_system_prompt',
   'prompt.feel_user_prompt',
   'prompt.important_system_prompt',
   'prompt.important_user_prompt',
   'prompt.read_system_prompt',
   'prompt.read_user_prompt',
   'question_options.feel_question_options',
   'question_options.important_question_options',
   'question_options.read_question_options',
   'question_text.feel_question_text',
   'question_text.important_question_text',
   'question_text.read_question_text',
   'question_type.feel_question_type',
   'question_type.important_question_type',
   'question_type.read_question_type',
   'raw_model_response.feel_raw_model_response',
   'raw_model_response.important_raw_model_response',
   'raw_model_response.read_raw_model_response',
   'scenario.topic']


The columns include information about each *agent*, *model* and corresponding *prompts* that were used to simulate an *answer* to each *question* and *scenario* in the survey, together with each *raw model response*.
If the survey was run multiple times (`run(n=<integer>)`) then the `iteration.iteration` column will show the iteration number for each result.

*Agent* information:

* **agent.agent_name**: This field is always included in any `Results` object. It contains a unique identifier for each `Agent` that can be specified when an agent is is created (`Agent(name=<name>, traits={<traits_dict>})`). If not specified, it is added automatically when results are generated (in the form `Agent_0`, etc.).
* **agent.persona**: Each of the `traits` that we pass to an agent is represented in a column of the results. Our example code created a "persona" trait for each agent, so our results include a "persona" column for this information. Note that the keys for the traits dictionary should be a valid Python keys.

*Answer* information:

* **answer.feel**: Agent responses to the `feel` question.
* **answer.important**: Agent responses to the `important` question.
* **answer.important_comment**: Agent commentary on reponses to the `important` question.
A comment field is automatically included for every question in a survey other than free text questions, to allow the agent to optionally provide additional information about its response to the question.
* **answer.read**: Agent responses to the `read` question.
* **answer.read_comment**: Agent commentary on responses to the `read` question.

*Iteration* information:
The `iteration` column shows the number of the run (`run(n=<integer>)`) for the combination of components used (scenarios, agents and models).

*Model* information:
Each of `model` columns is a modifiable parameter of the models used to generate the responses.

* **model.frequency_penalty**: The frequency penalty for the model.
* **model.max_tokens**: The maximum number of tokens for the model.
* **model.model**: The model used.
* **model.presence_penalty**: The presence penalty for the model.
* **model.temperature**: The temperature for the model.
* **model.top_p**: The top p for the model.
* **model.use_cache**: Whether the model uses cache.

*Prompt* information:

* **prompt.feel_system_prompt**: The system prompt for the `feel` question.
* **prompt.feel_user_prompt**: The user prompt for the `feel` question.
* **prompt.important_system_prompt**: The system prompt for the `important` question.
* **prompt.important_user_prompt**: The user prompt for the `important` question.
* **prompt.read_system_prompt**: The system prompt for the `read` question.
* **prompt.read_user_prompt**: The user prompt for the `read` question.
For more details about prompts, please see the :ref:`prompts` section.

*Question* information:

* **question_options.feel_question_options**: The options for the `feel` question, if any.
* **question_options.important_question_options**: The options for the `important` question, if any.
* **question_options.read_question_options**: The options for the `read` question, if any.
* **question_text.feel_question_text**: The text of the `feel` question.
* **question_text.important_question_text**: The text of the `important` question.
* **question_text.read_question_text**: The text of the `read` question.
* **question_type.feel_question_type**: The type of the `feel` question.
* **question_type.important_question_type**: The type of the `important` question.
* **question_type.read_question_type**: The type of the `read` question.

*Raw model response* information:

* **raw_model_response.feel_raw_model_response**: The raw model response for the `feel` question.
* **raw_model_response.important_raw_model_response**: The raw model response for the `important` question.
* **raw_model_response.read_raw_model_response**: The raw model response for the `read` question.

*Scenario* information:

* **scenario.topic**: The values provided for the "topic" scenario for the questions.


Creating tables by selecting and printing
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Each of these columns can be accessed directly by calling the `select()` method, and then printed by appending the `print()` method.
For example, the following code will print a table showing the answers for `read` and `important` together with `model`, `persona` and `topic` columns
(because the column names are unique we can drop the `model`, `agent`, `scenario` and `answer` prefixes when selecting them):

.. code-block:: python

   results.select("model", "persona", "topic", "read", "important").print()


The following table will be printed:

.. code-block:: text

   ┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
   ┃ model              ┃ agent     ┃ scenario       ┃ answer ┃ answer     ┃
   ┃ .model             ┃ .persona  ┃ .topic         ┃ .read  ┃ .important ┃
   ┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
   │ gpt-4-0125-preview │ student   │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ student   │ climate change │ Yes    │ 3          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ student   │ data privacy   │ Yes    │ 4          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ student   │ data privacy   │ Yes    │ 4          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ celebrity │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ celebrity │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ celebrity │ data privacy   │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ celebrity │ data privacy   │ Yes    │ 4          │
   └────────────────────┴───────────┴────────────────┴────────┴────────────┘


We can sort the columns by calling the `sort_by` method and passing it the column name to sort by:

.. code-block:: python

   (results
   .sort_by("model", reverse=False)
   .select("model", "persona", "topic", "read", "important")
   .print(format="rich")
   )

.. code-block:: text
   
   ┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
   ┃ model              ┃ agent     ┃ scenario       ┃ answer ┃ answer     ┃
   ┃ .model             ┃ .persona  ┃ .topic         ┃ .read  ┃ .important ┃
   ┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
   │ gpt-3.5-turbo      │ student   │ climate change │ Yes    │ 3          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ student   │ data privacy   │ Yes    │ 4          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ celebrity │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ celebrity │ data privacy   │ Yes    │ 4          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ student   │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ student   │ data privacy   │ Yes    │ 4          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ celebrity │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ celebrity │ data privacy   │ Yes    │ 5          │
   └────────────────────┴───────────┴────────────────┴────────┴────────────┘


The `sort_by` method can be applied multiple times:

.. code-block:: python

   (results
   .sort_by("model", reverse=False)
   .sort_by("persona", reverse=True)
   .select("model", "persona", "topic", "read", "important")
   .print(format="rich")
   )

.. code-block:: text

   ┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
   ┃ model              ┃ agent     ┃ scenario       ┃ answer ┃ answer     ┃
   ┃ .model             ┃ .persona  ┃ .topic         ┃ .read  ┃ .important ┃
   ┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
   │ gpt-3.5-turbo      │ student   │ climate change │ Yes    │ 3          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ student   │ data privacy   │ Yes    │ 4          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ student   │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ student   │ data privacy   │ Yes    │ 4          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ celebrity │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-3.5-turbo      │ celebrity │ data privacy   │ Yes    │ 4          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ celebrity │ climate change │ Yes    │ 5          │
   ├────────────────────┼───────────┼────────────────┼────────┼────────────┤
   │ gpt-4-0125-preview │ celebrity │ data privacy   │ Yes    │ 5          │
   └────────────────────┴───────────┴────────────────┴────────┴────────────┘


We can also add some table labels by passing a dictionary to the `pretty_labels` argument of the `print` method
(note that we do need to include the column prefixes when specifying the table labels, as shown below):

.. code-block:: python

   (results
   .sort_by("model", reverse=False)
   .sort_by("persona", reverse=True)
   .select("model", "persona", "topic", "read", "important")
   .print(pretty_labels={
      "model.model": "LLM", 
      "agent.persona": "Agent", 
      "scenario.topic": "Topic", 
      "answer.read": q3.question_text,
      "answer.important": q1.question_text
      }, format="rich")
   )

.. code-block:: text
   
   ┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓
   ┃                    ┃           ┃                ┃ Have you read any books ┃ How much do you care ┃
   ┃ LLM                ┃ Agent     ┃ Topic          ┃ about {{ topic }}?      ┃ about {{ topic }}?   ┃
   ┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩
   │ gpt-3.5-turbo      │ student   │ climate change │ Yes                     │ 3                    │
   ├────────────────────┼───────────┼────────────────┼─────────────────────────┼──────────────────────┤
   │ gpt-3.5-turbo      │ student   │ data privacy   │ Yes                     │ 4                    │
   ├────────────────────┼───────────┼────────────────┼─────────────────────────┼──────────────────────┤
   │ gpt-4-0125-preview │ student   │ climate change │ Yes                     │ 5                    │
   ├────────────────────┼───────────┼────────────────┼─────────────────────────┼──────────────────────┤
   │ gpt-4-0125-preview │ student   │ data privacy   │ Yes                     │ 4                    │
   ├────────────────────┼───────────┼────────────────┼─────────────────────────┼──────────────────────┤
   │ gpt-3.5-turbo      │ celebrity │ climate change │ Yes                     │ 5                    │
   ├────────────────────┼───────────┼────────────────┼─────────────────────────┼──────────────────────┤
   │ gpt-3.5-turbo      │ celebrity │ data privacy   │ Yes                     │ 4                    │
   ├────────────────────┼───────────┼────────────────┼─────────────────────────┼──────────────────────┤
   │ gpt-4-0125-preview │ celebrity │ climate change │ Yes                     │ 5                    │
   ├────────────────────┼───────────┼────────────────┼─────────────────────────┼──────────────────────┤
   │ gpt-4-0125-preview │ celebrity │ data privacy   │ Yes                     │ 5                    │
   └────────────────────┴───────────┴────────────────┴─────────────────────────┴──────────────────────┘


Filtering
^^^^^^^^^
Results can be filtered by using the `filter` method and passing it a logical expression identifying the results that should be selected.
For example, the following code will filter results where the answer to `yesterday` is "Good" and then just print the `yesterday_comment` and `tomorrow` columns:

.. code-block:: python

   (results
   .filter("yesterday == 'Good'")
   .select("yesterday_comment", "tomorrow")
   .print()
   )

.. code-block:: text

   ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
   ┃ answer                                                 ┃ answer                                                 ┃
   ┃ .yesterday_comment                                     ┃ .tomorrow                                              ┃
   ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
   │ I felt good yesterday morning, thank you for asking!   │ I expect to feel happy and refreshed tomorrow morning, │
   │                                                        │ ready to start a new day with enthusiasm and           │
   │                                                        │ positivity!                                            │
   ├────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────┤
   │ I woke up feeling refreshed and ready to take on the   │ I expect to feel refreshed and ready to tackle the day │
   │ day!                                                   │ with a positive attitude tomorrow morning!             │
   ├────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────┤
   │ I felt good yesterday evening. I had a productive day  │ I expect to feel happy and content tomorrow evening.   │
   │ and was able to help many users with their questions.  │                                                        │
   │ I am looking forward to continuing to assist users     │                                                        │
   │ today!                                                 │                                                        │
   ├────────────────────────────────────────────────────────┼────────────────────────────────────────────────────────┤
   │ I'm always happy, so yesterday evening was great!      │ I expect to feel content and fulfilled tomorrow        │
   │                                                        │ evening, with a sense of accomplishment from a         │
   │                                                        │ productive day. I will have had a chance to help many  │
   │                                                        │ people and make a positive impact in their lives,      │
   │                                                        │ which will give me a feeling of purpose and            │
   │                                                        │ satisfaction. I will also have had time to relax and   │
   │                                                        │ unwind, enjoying the company of my loved ones and      │
   │                                                        │ engaging in activities that bring me joy. Overall, I   │
   │                                                        │ am looking forward to a wonderful tomorrow evening!    │
   └────────────────────────────────────────────────────────┴────────────────────────────────────────────────────────┘

Interacting via SQL
^^^^^^^^^^^^^^^^^^^
We can also interact with the results via SQL using the `sql` method.

.. code-block:: python

   results.sql("select data_type, key, value from self where data_type = 'answer' limit 3", shape="long")



Exporting to other formats
^^^^^^^^^^^^^^^^^^^^^^^^^^
We can also export results to other formats, such as pandas DataFrames or CSV files.
The `to_pandas` method will return a pandas DataFrame:

.. code-block:: python

   results.to_pandas()

For example, here we use it to inspect the first set of (default) prompts used in the results:

.. code-block:: python

   results.to_pandas()[["prompt.tomorrow_user_prompt", "prompt.tomorrow_system_prompt"]].iloc[0]

.. code-block:: text

   prompt.tomorrow_user_prompt    {'text': 'You are being asked the following question: How do you expect to feel tomorrow morning?\nReturn a valid JSON formatted like this:\n{"answer": "<put free text answer here>"}', 'class_name': 'FreeText'}
   prompt.tomorrow_system_prompt  {'text': "You are answering questions as if you were a human. Do not break character. You are an agent with the following persona:\n{'status': 'happy'}", 'class_name': 'AgentInstruction'}
   Name: 0, dtype: object


The `to_csv` method will write the results to a CSV file:

.. code-block:: python

   results.to_pandas().to_csv("results.csv")

The `to_json` method will write the results to a JSON file:

.. code-block:: python

   results.to_pandas().to_json("results.json")



Result class
------------
.. automodule:: edsl.results.Result
   :members: rich_print, 
   :inherited-members:
   :exclude-members: 
   :undoc-members:
   :special-members: __init__

Results class
-------------
.. automodule:: edsl.results.Results
   :members:
   :inherited-members:
   :exclude-members: append, clear, copy, count, extend, index, insert, pop, remove, reverse, sort, known_data_types, Mixins, main
   :undoc-members:
   :special-members: __init__

